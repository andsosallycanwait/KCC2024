Namespace(dev_file='/home/nilu/SpanBERT/dev_processed_data.json', do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, eval_batch_size=8, eval_metric='f1', eval_per_epoch=10, eval_test=True, fp16=False, gradient_accumulation_steps=1, learning_rate=None, loss_scale=0, max_answer_length=30, max_query_length=64, max_seq_length=384, model='bert-base-cased', n_best_size=20, no_cuda=False, num_train_epochs=20, output_dir='/home/nilu/SpanBERT', seed=42, test_file='/home/nilu/SpanBERT/test_processed_data.json', train_batch_size=32, train_file='/home/nilu/SpanBERT/train_processed_data.json', train_mode='random_sorted', verbose_logging=False, version_2_with_negative=False, warmup_proportion=0.1)
*** Example ***
unique_id: 1000000000
example_index: 0
doc_span_index: 0
tokens: [CLS] How can I avoid lump ##s in the cake ? [SEP] Milk won ' t help you - it ' s mostly water , and g ##lut ##en develops from flour ( more accurately , specific proteins in flour ) and water . The way to reduce g ##lut ##en development is to incorporate more fat into the batter . Li ##pid ##s are h ##ydro ##phobic and will prevent further h ##yd ##ration of the g ##lut ##eni ##n . Using a lower - protein flour will also help . If you ' re not already using cake flour , the reason it ' s called cake flour is because of the lower protein content . That being said , have you actually tried leaving the batter coarse ? Just because the batter is lump ##y does not mean that the cake will have big lump ##s . The entire mixture is wet , so unless you leave huge lump ##s of dry flour in the batter , you won ' t end up with a lump ##y cake . There ' s a difference between " don ' t over ##mi ##x " and " don ' t mix " - you ' re supposed to mix enough to incorporate , just don ' t try ho ##mo ##gen ##ize it . [SEP]
token_to_orig_map: 12:0 13:1 14:1 15:1 16:2 17:3 18:4 19:5 20:5 21:5 22:6 23:7 24:7 25:8 26:9 27:9 28:9 29:10 30:11 31:12 32:13 33:13 34:14 35:14 36:15 37:16 38:17 39:18 40:18 41:19 42:20 43:20 44:20 45:21 46:22 47:23 48:24 49:24 50:24 51:25 52:26 53:27 54:28 55:29 56:30 57:31 58:32 59:33 60:33 61:34 62:34 63:34 64:35 65:36 66:36 67:36 68:37 69:38 70:39 71:40 72:41 73:41 74:41 75:42 76:43 77:44 78:44 79:44 80:44 81:44 82:44 83:45 84:46 85:46 86:46 87:47 88:48 89:49 90:50 91:50 92:51 93:52 94:52 95:52 96:53 97:54 98:55 99:56 100:57 101:57 102:58 103:59 104:60 105:60 106:60 107:61 108:62 109:63 110:64 111:65 112:66 113:67 114:68 115:69 116:70 117:70 118:70 119:71 120:72 121:72 122:73 123:74 124:75 125:76 126:77 127:78 128:79 129:80 130:80 131:81 132:82 133:83 134:84 135:85 136:86 137:86 138:87 139:88 140:89 141:90 142:91 143:92 144:93 145:94 146:95 147:96 148:96 149:96 150:97 151:98 152:99 153:100 154:101 155:101 156:102 157:103 158:104 159:105 160:106 161:107 162:107 163:108 164:109 165:110 166:111 167:112 168:113 169:113 170:114 171:115 172:115 173:115 174:116 175:117 176:118 177:119 178:120 179:120 180:121 181:121 182:122 183:122 184:122 185:123 186:124 187:125 188:126 189:126 190:126 191:126 192:127 193:127 194:127 195:127 196:128 197:129 198:129 199:129 200:129 201:130 202:130 203:131 204:132 205:132 206:132 207:133 208:134 209:135 210:136 211:137 212:138 213:138 214:139 215:140 216:140 217:140 218:141 219:142 220:142 221:142 222:142 223:143 224:143
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True
input_ids: 101 1731 1169 146 3644 16401 1116 1107 1103 10851 136 102 18165 1281 112 189 1494 1128 118 1122 112 188 2426 1447 117 1105 176 25937 1424 11926 1121 15068 113 1167 14702 117 2747 7865 1107 15068 114 1105 1447 119 1109 1236 1106 4851 176 25937 1424 1718 1110 1106 13639 1167 7930 1154 1103 27584 119 5255 25786 1116 1132 177 19694 22050 1105 1209 3843 1748 177 19429 6108 1104 1103 176 25937 21462 1179 119 7993 170 2211 118 4592 15068 1209 1145 1494 119 1409 1128 112 1231 1136 1640 1606 10851 15068 117 1103 2255 1122 112 188 1270 10851 15068 1110 1272 1104 1103 2211 4592 3438 119 1337 1217 1163 117 1138 1128 2140 1793 2128 1103 27584 23137 136 2066 1272 1103 27584 1110 16401 1183 1674 1136 1928 1115 1103 10851 1209 1138 1992 16401 1116 119 1109 2072 7759 1110 4375 117 1177 4895 1128 1817 3321 16401 1116 1104 3712 15068 1107 1103 27584 117 1128 1281 112 189 1322 1146 1114 170 16401 1183 10851 119 1247 112 188 170 3719 1206 107 1274 112 189 1166 3080 1775 107 1105 107 1274 112 189 5495 107 118 1128 112 1231 3155 1106 5495 1536 1106 13639 117 1198 1274 112 189 2222 16358 3702 4915 3708 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000001
example_index: 1
doc_span_index: 0
tokens: [CLS] No , I haven ' t . I ' ll try that next . Is it safe to add more milk into the batter ? [SEP] Milk won ' t help you - it ' s mostly water , and g ##lut ##en develops from flour ( more accurately , specific proteins in flour ) and water . The way to reduce g ##lut ##en development is to incorporate more fat into the batter . Li ##pid ##s are h ##ydro ##phobic and will prevent further h ##yd ##ration of the g ##lut ##eni ##n . Using a lower - protein flour will also help . If you ' re not already using cake flour , the reason it ' s called cake flour is because of the lower protein content . That being said , have you actually tried leaving the batter coarse ? Just because the batter is lump ##y does not mean that the cake will have big lump ##s . The entire mixture is wet , so unless you leave huge lump ##s of dry flour in the batter , you won ' t end up with a lump ##y cake . There ' s a difference between " don ' t over ##mi ##x " and " don ' t mix " - you ' re supposed to mix enough to incorporate , just don ' t try ho ##mo ##gen ##ize it . [SEP]
token_to_orig_map: 27:0 28:1 29:1 30:1 31:2 32:3 33:4 34:5 35:5 36:5 37:6 38:7 39:7 40:8 41:9 42:9 43:9 44:10 45:11 46:12 47:13 48:13 49:14 50:14 51:15 52:16 53:17 54:18 55:18 56:19 57:20 58:20 59:20 60:21 61:22 62:23 63:24 64:24 65:24 66:25 67:26 68:27 69:28 70:29 71:30 72:31 73:32 74:33 75:33 76:34 77:34 78:34 79:35 80:36 81:36 82:36 83:37 84:38 85:39 86:40 87:41 88:41 89:41 90:42 91:43 92:44 93:44 94:44 95:44 96:44 97:44 98:45 99:46 100:46 101:46 102:47 103:48 104:49 105:50 106:50 107:51 108:52 109:52 110:52 111:53 112:54 113:55 114:56 115:57 116:57 117:58 118:59 119:60 120:60 121:60 122:61 123:62 124:63 125:64 126:65 127:66 128:67 129:68 130:69 131:70 132:70 133:70 134:71 135:72 136:72 137:73 138:74 139:75 140:76 141:77 142:78 143:79 144:80 145:80 146:81 147:82 148:83 149:84 150:85 151:86 152:86 153:87 154:88 155:89 156:90 157:91 158:92 159:93 160:94 161:95 162:96 163:96 164:96 165:97 166:98 167:99 168:100 169:101 170:101 171:102 172:103 173:104 174:105 175:106 176:107 177:107 178:108 179:109 180:110 181:111 182:112 183:113 184:113 185:114 186:115 187:115 188:115 189:116 190:117 191:118 192:119 193:120 194:120 195:121 196:121 197:122 198:122 199:122 200:123 201:124 202:125 203:126 204:126 205:126 206:126 207:127 208:127 209:127 210:127 211:128 212:129 213:129 214:129 215:129 216:130 217:130 218:131 219:132 220:132 221:132 222:133 223:134 224:135 225:136 226:137 227:138 228:138 229:139 230:140 231:140 232:140 233:141 234:142 235:142 236:142 237:142 238:143 239:143
token_is_max_context: 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True
input_ids: 101 1302 117 146 3983 112 189 119 146 112 1325 2222 1115 1397 119 2181 1122 2914 1106 5194 1167 6831 1154 1103 27584 136 102 18165 1281 112 189 1494 1128 118 1122 112 188 2426 1447 117 1105 176 25937 1424 11926 1121 15068 113 1167 14702 117 2747 7865 1107 15068 114 1105 1447 119 1109 1236 1106 4851 176 25937 1424 1718 1110 1106 13639 1167 7930 1154 1103 27584 119 5255 25786 1116 1132 177 19694 22050 1105 1209 3843 1748 177 19429 6108 1104 1103 176 25937 21462 1179 119 7993 170 2211 118 4592 15068 1209 1145 1494 119 1409 1128 112 1231 1136 1640 1606 10851 15068 117 1103 2255 1122 112 188 1270 10851 15068 1110 1272 1104 1103 2211 4592 3438 119 1337 1217 1163 117 1138 1128 2140 1793 2128 1103 27584 23137 136 2066 1272 1103 27584 1110 16401 1183 1674 1136 1928 1115 1103 10851 1209 1138 1992 16401 1116 119 1109 2072 7759 1110 4375 117 1177 4895 1128 1817 3321 16401 1116 1104 3712 15068 1107 1103 27584 117 1128 1281 112 189 1322 1146 1114 170 16401 1183 10851 119 1247 112 188 170 3719 1206 107 1274 112 189 1166 3080 1775 107 1105 107 1274 112 189 5495 107 118 1128 112 1231 3155 1106 5495 1536 1106 13639 117 1198 1274 112 189 2222 16358 3702 4915 3708 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000002
example_index: 2
doc_span_index: 0
tokens: [CLS] Is bacon fat supposed to con ##ge ##al at room temperature ? [SEP] To answer what I think is the question ( you put all of the g ##rease into a container and there ' s a residue at the top ) , bacon dripping ##s are not 100 % fat . There are also solid pieces of bacon in there and other " imp ##uri ##ties " from the cu ##ring process . When rendering bacon fat , you should line the container with a paper towel first ( or cheese ##cloth if you have it ) . Po ##ur the bacon dripping ##s onto the paper towel and the fat will drain out the bottom ; the solid ##s will be left behind and you can di ##sp ##ose of them . You ' ll be left with ( mostly ) pure fat . The rendered fat will most definitely con ##ge ##al ; the vessel , once cooled , should contain only a solid , off - white substance . [SEP]
token_to_orig_map: 14:0 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:8 24:9 25:10 26:11 27:12 28:13 29:13 30:14 31:15 32:16 33:17 34:18 35:18 36:18 37:19 38:20 39:21 40:22 41:23 42:23 43:23 44:24 45:25 46:25 47:26 48:27 49:28 50:28 51:29 52:29 53:30 54:31 55:32 56:33 57:34 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:41 66:41 67:41 68:41 69:42 70:43 71:44 72:44 73:45 74:45 75:45 76:46 77:47 78:48 79:48 80:49 81:50 82:51 83:52 84:53 85:54 86:55 87:56 88:57 89:58 90:59 91:59 92:60 93:60 94:61 95:62 96:63 97:64 98:64 99:64 100:65 101:65 102:66 103:67 104:68 105:68 106:69 107:70 108:71 109:72 110:73 111:74 112:75 113:76 114:77 115:78 116:79 117:80 118:80 119:81 120:82 121:82 122:83 123:84 124:85 125:86 126:87 127:88 128:89 129:90 130:90 131:90 132:91 133:92 134:92 135:93 136:93 137:93 138:94 139:95 140:96 141:97 142:97 143:97 144:98 145:99 146:99 147:99 148:100 149:101 150:102 151:103 152:104 153:105 154:105 155:105 156:105 157:106 158:107 159:107 160:108 161:109 162:109 163:110 164:111 165:112 166:113 167:114 168:114 169:115 170:115 171:115 172:116 173:116
token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True
input_ids: 101 2181 20503 7930 3155 1106 14255 2176 1348 1120 1395 4143 136 102 1706 2590 1184 146 1341 1110 1103 2304 113 1128 1508 1155 1104 1103 176 15691 1154 170 12461 1105 1175 112 188 170 24456 1120 1103 1499 114 117 20503 15224 1116 1132 1136 1620 110 7930 119 1247 1132 1145 4600 3423 1104 20503 1107 1175 1105 1168 107 24034 8212 4338 107 1121 1103 16408 3384 1965 119 1332 15171 20503 7930 117 1128 1431 1413 1103 12461 1114 170 2526 10166 1148 113 1137 9553 25940 1191 1128 1138 1122 114 119 18959 2149 1103 20503 15224 1116 2135 1103 2526 10166 1105 1103 7930 1209 13734 1149 1103 3248 132 1103 4600 1116 1209 1129 1286 1481 1105 1128 1169 4267 20080 6787 1104 1172 119 1192 112 1325 1129 1286 1114 113 2426 114 5805 7930 119 1109 10029 7930 1209 1211 5397 14255 2176 1348 132 1103 5832 117 1517 13289 117 1431 4651 1178 170 4600 117 1228 118 1653 9556 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000003
example_index: 3
doc_span_index: 0
tokens: [CLS] Mine always has a semi - liquid at the top , is this bad ? [SEP] To answer what I think is the question ( you put all of the g ##rease into a container and there ' s a residue at the top ) , bacon dripping ##s are not 100 % fat . There are also solid pieces of bacon in there and other " imp ##uri ##ties " from the cu ##ring process . When rendering bacon fat , you should line the container with a paper towel first ( or cheese ##cloth if you have it ) . Po ##ur the bacon dripping ##s onto the paper towel and the fat will drain out the bottom ; the solid ##s will be left behind and you can di ##sp ##ose of them . You ' ll be left with ( mostly ) pure fat . The rendered fat will most definitely con ##ge ##al ; the vessel , once cooled , should contain only a solid , off - white substance . [SEP]
token_to_orig_map: 17:0 18:1 19:2 20:3 21:4 22:5 23:6 24:7 25:8 26:8 27:9 28:10 29:11 30:12 31:13 32:13 33:14 34:15 35:16 36:17 37:18 38:18 39:18 40:19 41:20 42:21 43:22 44:23 45:23 46:23 47:24 48:25 49:25 50:26 51:27 52:28 53:28 54:29 55:29 56:30 57:31 58:32 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:41 69:41 70:41 71:41 72:42 73:43 74:44 75:44 76:45 77:45 78:45 79:46 80:47 81:48 82:48 83:49 84:50 85:51 86:52 87:53 88:54 89:55 90:56 91:57 92:58 93:59 94:59 95:60 96:60 97:61 98:62 99:63 100:64 101:64 102:64 103:65 104:65 105:66 106:67 107:68 108:68 109:69 110:70 111:71 112:72 113:73 114:74 115:75 116:76 117:77 118:78 119:79 120:80 121:80 122:81 123:82 124:82 125:83 126:84 127:85 128:86 129:87 130:88 131:89 132:90 133:90 134:90 135:91 136:92 137:92 138:93 139:93 140:93 141:94 142:95 143:96 144:97 145:97 146:97 147:98 148:99 149:99 150:99 151:100 152:101 153:102 154:103 155:104 156:105 157:105 158:105 159:105 160:106 161:107 162:107 163:108 164:109 165:109 166:110 167:111 168:112 169:113 170:114 171:114 172:115 173:115 174:115 175:116 176:116
token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True
input_ids: 101 9139 1579 1144 170 3533 118 6161 1120 1103 1499 117 1110 1142 2213 136 102 1706 2590 1184 146 1341 1110 1103 2304 113 1128 1508 1155 1104 1103 176 15691 1154 170 12461 1105 1175 112 188 170 24456 1120 1103 1499 114 117 20503 15224 1116 1132 1136 1620 110 7930 119 1247 1132 1145 4600 3423 1104 20503 1107 1175 1105 1168 107 24034 8212 4338 107 1121 1103 16408 3384 1965 119 1332 15171 20503 7930 117 1128 1431 1413 1103 12461 1114 170 2526 10166 1148 113 1137 9553 25940 1191 1128 1138 1122 114 119 18959 2149 1103 20503 15224 1116 2135 1103 2526 10166 1105 1103 7930 1209 13734 1149 1103 3248 132 1103 4600 1116 1209 1129 1286 1481 1105 1128 1169 4267 20080 6787 1104 1172 119 1192 112 1325 1129 1286 1114 113 2426 114 5805 7930 119 1109 10029 7930 1209 1211 5397 14255 2176 1348 132 1103 5832 117 1517 13289 117 1431 4651 1178 170 4600 117 1228 118 1653 9556 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000004
example_index: 4
doc_span_index: 0
tokens: [CLS] Is it safe to microwave P ##yre ##x containers immediately after removing them from the freeze ##r and removing the plastic lid ? [SEP] It not huge , it ' s just the difference from freeze ##r to room temperature you are worrying about ##E . g . - 20 ##Â ##° ##C to 20 ##Â ##° ##C , is A 40 ##Â ##° ##C shift . The shift was going to be 20 ##Â ##° ##C to 100 + Â ##° ##C anyway . There is no physical reasons why this would be anymore stress ##ful ##F ##rom room temperature you are raising it 80 ##Â ##° ##C , from frozen you are raising it 120 ##Â ##° ##C . Not a problem in the normal temperature range for glass ##T ##he freezing temperature of water ( most common item in food ) has no relation to the freezing temperature of glass etc ##P ##yre ##x and other glasses can be damaged if one part of them is instantly heated or cooled by a 100 ##Â ##° ##C or so [SEP]
token_to_orig_map: 25:0 26:1 27:2 28:2 29:3 30:3 31:3 32:4 33:5 34:6 35:7 36:8 37:8 38:9 39:10 40:11 41:12 42:13 43:14 44:15 45:15 46:15 47:15 48:15 49:16 50:16 51:16 52:16 53:16 54:17 55:18 56:18 57:18 58:18 59:18 60:19 61:20 62:21 63:21 64:21 65:21 66:22 67:22 68:23 69:24 70:25 71:26 72:27 73:28 74:29 75:29 76:29 77:29 78:30 79:31 80:31 81:31 82:31 83:31 84:32 85:32 86:33 87:34 88:35 89:36 90:37 91:38 92:39 93:40 94:41 95:42 96:43 97:43 98:43 99:43 100:44 101:45 102:46 103:47 104:48 105:49 106:50 107:50 108:50 109:50 110:50 111:51 112:52 113:53 114:54 115:55 116:56 117:57 118:57 119:57 120:57 121:57 122:58 123:59 124:60 125:61 126:62 127:63 128:64 129:65 130:66 131:67 132:67 133:67 134:68 135:69 136:70 137:71 138:72 139:72 140:73 141:74 142:75 143:76 144:76 145:77 146:78 147:79 148:80 149:81 150:82 151:83 152:84 153:85 154:86 155:86 156:86 157:86 158:87 159:88 160:89 161:90 162:91 163:92 164:93 165:94 166:95 167:96 168:97 169:98 170:99 171:100 172:101 173:102 174:103 175:104 176:105 177:105 178:105 179:105 180:106 181:107
token_is_max_context: 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True
input_ids: 101 2181 1122 2914 1106 21865 153 10930 1775 17769 2411 1170 9305 1172 1121 1103 16020 1197 1105 9305 1103 5828 14753 136 102 1135 1136 3321 117 1122 112 188 1198 1103 3719 1121 16020 1197 1106 1395 4143 1128 1132 16569 1164 2036 119 176 119 118 1406 28181 7259 1658 1106 1406 28181 7259 1658 117 1110 138 1969 28181 7259 1658 5212 119 1109 5212 1108 1280 1106 1129 1406 28181 7259 1658 1106 1620 116 228 7259 1658 4050 119 1247 1110 1185 2952 3672 1725 1142 1156 1129 4169 6600 2365 2271 16071 1395 4143 1128 1132 5920 1122 2908 28181 7259 1658 117 1121 7958 1128 1132 5920 1122 5356 28181 7259 1658 119 1753 170 2463 1107 1103 2999 4143 2079 1111 2525 1942 4638 13543 4143 1104 1447 113 1211 1887 8926 1107 2094 114 1144 1185 6796 1106 1103 13543 4143 1104 2525 3576 2101 10930 1775 1105 1168 7537 1169 1129 4938 1191 1141 1226 1104 1172 1110 6677 9511 1137 13289 1118 170 1620 28181 7259 1658 1137 1177 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000005
example_index: 5
doc_span_index: 0
tokens: [CLS] How can I use a gas stove to hard b ##oil some eggs ? [SEP] I agree with @ j ##wen ##ting , 5 - 7 minutes in boiling water is the way to go . Remember to always put the eggs in cold water , if you put them in hot water you risk cracking the shell , especially if eggs are cold . Also , to avoid premature cracking of the shell , that may leave some egg white leaking out , add a spoon of vine ##gar ( should work with lemon juice too ) to the water . [SEP]
token_to_orig_map: 16:0 17:1 18:2 19:3 20:3 21:3 22:3 23:3 24:4 25:4 26:4 27:5 28:6 29:7 30:8 31:9 32:10 33:11 34:12 35:13 36:13 37:13 38:14 39:15 40:16 41:17 42:18 43:19 44:20 45:21 46:21 47:22 48:23 49:24 50:25 51:26 52:27 53:28 54:29 55:30 56:31 57:32 58:33 59:33 60:34 61:35 62:36 63:37 64:38 65:38 66:38 67:38 68:39 69:40 70:41 71:42 72:43 73:44 74:45 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:53 84:53 85:54 86:55 87:56 88:57 89:58 90:58 91:59 92:59 93:60 94:61 95:62 96:63 97:64 98:64 99:65 100:66 101:67 102:67
token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True
input_ids: 101 1731 1169 146 1329 170 3245 18362 1106 1662 171 20708 1199 6471 136 102 146 5340 1114 137 179 10781 1916 117 126 118 128 1904 1107 17913 1447 1110 1103 1236 1106 1301 119 9498 1106 1579 1508 1103 6471 1107 2504 1447 117 1191 1128 1508 1172 1107 2633 1447 1128 3187 17254 1103 5963 117 2108 1191 6471 1132 2504 119 2907 117 1106 3644 24505 17254 1104 1103 5963 117 1115 1336 1817 1199 9069 1653 27742 1149 117 5194 170 19184 1104 23230 5526 113 1431 1250 1114 22782 12362 1315 114 1106 1103 1447 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000006
example_index: 6
doc_span_index: 0
tokens: [CLS] ok . once the water is boiling , should I turn down the heat on the stove ? [SEP] I agree with @ j ##wen ##ting , 5 - 7 minutes in boiling water is the way to go . Remember to always put the eggs in cold water , if you put them in hot water you risk cracking the shell , especially if eggs are cold . Also , to avoid premature cracking of the shell , that may leave some egg white leaking out , add a spoon of vine ##gar ( should work with lemon juice too ) to the water . [SEP]
token_to_orig_map: 20:0 21:1 22:2 23:3 24:3 25:3 26:3 27:3 28:4 29:4 30:4 31:5 32:6 33:7 34:8 35:9 36:10 37:11 38:12 39:13 40:13 41:13 42:14 43:15 44:16 45:17 46:18 47:19 48:20 49:21 50:21 51:22 52:23 53:24 54:25 55:26 56:27 57:28 58:29 59:30 60:31 61:32 62:33 63:33 64:34 65:35 66:36 67:37 68:38 69:38 70:38 71:38 72:39 73:40 74:41 75:42 76:43 77:44 78:45 79:45 80:46 81:47 82:48 83:49 84:50 85:51 86:52 87:53 88:53 89:54 90:55 91:56 92:57 93:58 94:58 95:59 96:59 97:60 98:61 99:62 100:63 101:64 102:64 103:65 104:66 105:67 106:67
token_is_max_context: 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True
input_ids: 101 21534 119 1517 1103 1447 1110 17913 117 1431 146 1885 1205 1103 3208 1113 1103 18362 136 102 146 5340 1114 137 179 10781 1916 117 126 118 128 1904 1107 17913 1447 1110 1103 1236 1106 1301 119 9498 1106 1579 1508 1103 6471 1107 2504 1447 117 1191 1128 1508 1172 1107 2633 1447 1128 3187 17254 1103 5963 117 2108 1191 6471 1132 2504 119 2907 117 1106 3644 24505 17254 1104 1103 5963 117 1115 1336 1817 1199 9069 1653 27742 1149 117 5194 170 19184 1104 23230 5526 113 1431 1250 1114 22782 12362 1315 114 1106 1103 1447 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000007
example_index: 7
doc_span_index: 0
tokens: [CLS] Can I sue C ##lar ##ified butter for gum ##bo r ##oux ? # # # Can I use clarified butter for gum ##bo r ##oux instead of regular butter ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 33:0 34:1 35:1 36:2 37:3 38:4 39:5 40:6 41:7 42:7 43:8 44:9 45:10 46:11 47:12 48:13 49:14 50:15 51:16 52:17 53:18 54:19 55:20 56:21 57:21 58:22 59:23 60:24 61:25 62:26 63:26 64:27 65:28 66:29 67:30 68:31 69:32 70:33 71:34 72:35 73:36 74:37 75:38 76:39 77:40 78:41 79:41 80:42 81:43 82:43 83:44 84:45 85:46 86:47 87:48 88:49 89:50 90:51 91:52 92:53 93:54 94:55 95:56 96:57 97:58 98:59 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:66 107:67 108:68 109:69 110:70 111:71 112:72 113:73 114:74 115:75 116:76 117:77 118:77 119:78 120:79 121:80 122:81 123:82 124:83 125:84 126:85 127:86 128:87 129:88 130:89 131:90 132:91 133:92 134:93 135:93 136:93 137:94 138:95 139:96 140:96 141:97 142:98 143:98 144:99 145:99 146:100 147:100 148:101 149:102 150:103 151:104 152:105 153:106 154:107 155:108 156:109 157:110 158:111 159:111 160:112 161:112 162:112 163:113 164:114 165:115 166:115 167:116 168:117 169:118 170:119 171:120 172:121 173:122 174:122 175:123 176:124 177:125 178:126 179:127 180:127 181:127 182:127 183:128 184:128 185:128 186:128 187:128 188:129 189:130 190:131 191:132 192:133 193:134 194:135 195:136 196:137 197:138 198:138 199:138 200:138 201:138 202:138 203:139 204:140 205:141 206:142 207:142 208:142 209:143 210:144 211:145 212:146 213:147 214:148 215:148 216:148 217:149 218:150 219:150 220:150 221:151 222:152 223:153 224:154 225:155 226:155
token_is_max_context: 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True
input_ids: 101 2825 146 25762 140 5815 6202 13742 1111 19956 4043 187 24060 136 108 108 108 2825 146 1329 22484 13742 1111 19956 4043 187 24060 1939 1104 2366 13742 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000008
example_index: 8
doc_span_index: 0
tokens: [CLS] Could something bad happen by using clarified butter instead of regular butter ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 15:0 16:1 17:1 18:2 19:3 20:4 21:5 22:6 23:7 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:19 37:20 38:21 39:21 40:22 41:23 42:24 43:25 44:26 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:37 57:38 58:39 59:40 60:41 61:41 62:42 63:43 64:43 65:44 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:65 87:66 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:74 97:75 98:76 99:77 100:77 101:78 102:79 103:80 104:81 105:82 106:83 107:84 108:85 109:86 110:87 111:88 112:89 113:90 114:91 115:92 116:93 117:93 118:93 119:94 120:95 121:96 122:96 123:97 124:98 125:98 126:99 127:99 128:100 129:100 130:101 131:102 132:103 133:104 134:105 135:106 136:107 137:108 138:109 139:110 140:111 141:111 142:112 143:112 144:112 145:113 146:114 147:115 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:122 156:122 157:123 158:124 159:125 160:126 161:127 162:127 163:127 164:127 165:128 166:128 167:128 168:128 169:128 170:129 171:130 172:131 173:132 174:133 175:134 176:135 177:136 178:137 179:138 180:138 181:138 182:138 183:138 184:138 185:139 186:140 187:141 188:142 189:142 190:142 191:143 192:144 193:145 194:146 195:147 196:148 197:148 198:148 199:149 200:150 201:150 202:150 203:151 204:152 205:153 206:154 207:155 208:155
token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True
input_ids: 101 7426 1380 2213 3333 1118 1606 22484 13742 1939 1104 2366 13742 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000009
example_index: 9
doc_span_index: 0
tokens: [CLS] What if I use a little regular butter mixed with the clarified butter ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 16:0 17:1 18:1 19:2 20:3 21:4 22:5 23:6 24:7 25:7 26:8 27:9 28:10 29:11 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:21 40:21 41:22 42:23 43:24 44:25 45:26 46:26 47:27 48:28 49:29 50:30 51:31 52:32 53:33 54:34 55:35 56:36 57:37 58:38 59:39 60:40 61:41 62:41 63:42 64:43 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:61 84:62 85:63 86:64 87:65 88:66 89:66 90:67 91:68 92:69 93:70 94:71 95:72 96:73 97:74 98:75 99:76 100:77 101:77 102:78 103:79 104:80 105:81 106:82 107:83 108:84 109:85 110:86 111:87 112:88 113:89 114:90 115:91 116:92 117:93 118:93 119:93 120:94 121:95 122:96 123:96 124:97 125:98 126:98 127:99 128:99 129:100 130:100 131:101 132:102 133:103 134:104 135:105 136:106 137:107 138:108 139:109 140:110 141:111 142:111 143:112 144:112 145:112 146:113 147:114 148:115 149:115 150:116 151:117 152:118 153:119 154:120 155:121 156:122 157:122 158:123 159:124 160:125 161:126 162:127 163:127 164:127 165:127 166:128 167:128 168:128 169:128 170:128 171:129 172:130 173:131 174:132 175:133 176:134 177:135 178:136 179:137 180:138 181:138 182:138 183:138 184:138 185:138 186:139 187:140 188:141 189:142 190:142 191:142 192:143 193:144 194:145 195:146 196:147 197:148 198:148 199:148 200:149 201:150 202:150 203:150 204:151 205:152 206:153 207:154 208:155 209:155
token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True
input_ids: 101 1327 1191 146 1329 170 1376 2366 13742 3216 1114 1103 22484 13742 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000010
example_index: 10
doc_span_index: 0
tokens: [CLS] Should I substitute something other than clarified butter like oil ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 13:0 14:1 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:7 23:8 24:9 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:21 38:22 39:23 40:24 41:25 42:26 43:26 44:27 45:28 46:29 47:30 48:31 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:43 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:54 74:55 75:56 76:57 77:58 78:59 79:60 80:61 81:62 82:63 83:64 84:65 85:66 86:66 87:67 88:68 89:69 90:70 91:71 92:72 93:73 94:74 95:75 96:76 97:77 98:77 99:78 100:79 101:80 102:81 103:82 104:83 105:84 106:85 107:86 108:87 109:88 110:89 111:90 112:91 113:92 114:93 115:93 116:93 117:94 118:95 119:96 120:96 121:97 122:98 123:98 124:99 125:99 126:100 127:100 128:101 129:102 130:103 131:104 132:105 133:106 134:107 135:108 136:109 137:110 138:111 139:111 140:112 141:112 142:112 143:113 144:114 145:115 146:115 147:116 148:117 149:118 150:119 151:120 152:121 153:122 154:122 155:123 156:124 157:125 158:126 159:127 160:127 161:127 162:127 163:128 164:128 165:128 166:128 167:128 168:129 169:130 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:138 179:138 180:138 181:138 182:138 183:139 184:140 185:141 186:142 187:142 188:142 189:143 190:144 191:145 192:146 193:147 194:148 195:148 196:148 197:149 198:150 199:150 200:150 201:151 202:152 203:153 204:154 205:155 206:155
token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True
input_ids: 101 9743 146 7359 1380 1168 1190 22484 13742 1176 2949 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000011
example_index: 11
doc_span_index: 0
tokens: [CLS] Can I use clarified butter for gum ##bo r ##oux ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 13:0 14:1 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:7 23:8 24:9 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:21 38:22 39:23 40:24 41:25 42:26 43:26 44:27 45:28 46:29 47:30 48:31 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:43 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:54 74:55 75:56 76:57 77:58 78:59 79:60 80:61 81:62 82:63 83:64 84:65 85:66 86:66 87:67 88:68 89:69 90:70 91:71 92:72 93:73 94:74 95:75 96:76 97:77 98:77 99:78 100:79 101:80 102:81 103:82 104:83 105:84 106:85 107:86 108:87 109:88 110:89 111:90 112:91 113:92 114:93 115:93 116:93 117:94 118:95 119:96 120:96 121:97 122:98 123:98 124:99 125:99 126:100 127:100 128:101 129:102 130:103 131:104 132:105 133:106 134:107 135:108 136:109 137:110 138:111 139:111 140:112 141:112 142:112 143:113 144:114 145:115 146:115 147:116 148:117 149:118 150:119 151:120 152:121 153:122 154:122 155:123 156:124 157:125 158:126 159:127 160:127 161:127 162:127 163:128 164:128 165:128 166:128 167:128 168:129 169:130 170:131 171:132 172:133 173:134 174:135 175:136 176:137 177:138 178:138 179:138 180:138 181:138 182:138 183:139 184:140 185:141 186:142 187:142 188:142 189:143 190:144 191:145 192:146 193:147 194:148 195:148 196:148 197:149 198:150 199:150 200:150 201:151 202:152 203:153 204:154 205:155 206:155
token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True
input_ids: 101 2825 146 1329 22484 13742 1111 19956 4043 187 24060 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000012
example_index: 12
doc_span_index: 0
tokens: [CLS] What is the difference between butter and clarified butter ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 12:0 13:1 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:7 22:8 23:9 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:17 32:18 33:19 34:20 35:21 36:21 37:22 38:23 39:24 40:25 41:26 42:26 43:27 44:28 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:41 59:42 60:43 61:43 62:44 63:45 64:46 65:47 66:48 67:49 68:50 69:51 70:52 71:53 72:54 73:55 74:56 75:57 76:58 77:59 78:60 79:61 80:62 81:63 82:64 83:65 84:66 85:66 86:67 87:68 88:69 89:70 90:71 91:72 92:73 93:74 94:75 95:76 96:77 97:77 98:78 99:79 100:80 101:81 102:82 103:83 104:84 105:85 106:86 107:87 108:88 109:89 110:90 111:91 112:92 113:93 114:93 115:93 116:94 117:95 118:96 119:96 120:97 121:98 122:98 123:99 124:99 125:100 126:100 127:101 128:102 129:103 130:104 131:105 132:106 133:107 134:108 135:109 136:110 137:111 138:111 139:112 140:112 141:112 142:113 143:114 144:115 145:115 146:116 147:117 148:118 149:119 150:120 151:121 152:122 153:122 154:123 155:124 156:125 157:126 158:127 159:127 160:127 161:127 162:128 163:128 164:128 165:128 166:128 167:129 168:130 169:131 170:132 171:133 172:134 173:135 174:136 175:137 176:138 177:138 178:138 179:138 180:138 181:138 182:139 183:140 184:141 185:142 186:142 187:142 188:143 189:144 190:145 191:146 192:147 193:148 194:148 195:148 196:149 197:150 198:150 199:150 200:151 201:152 202:153 203:154 204:155 205:155
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True
input_ids: 101 1327 1110 1103 3719 1206 13742 1105 22484 13742 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000013
example_index: 13
doc_span_index: 0
tokens: [CLS] What could go wrong by using clarified butter ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 11:0 12:1 13:1 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:21 36:22 37:23 38:24 39:25 40:26 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:33 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:41 58:42 59:43 60:43 61:44 62:45 63:46 64:47 65:48 66:49 67:50 68:51 69:52 70:53 71:54 72:55 73:56 74:57 75:58 76:59 77:60 78:61 79:62 80:63 81:64 82:65 83:66 84:66 85:67 86:68 87:69 88:70 89:71 90:72 91:73 92:74 93:75 94:76 95:77 96:77 97:78 98:79 99:80 100:81 101:82 102:83 103:84 104:85 105:86 106:87 107:88 108:89 109:90 110:91 111:92 112:93 113:93 114:93 115:94 116:95 117:96 118:96 119:97 120:98 121:98 122:99 123:99 124:100 125:100 126:101 127:102 128:103 129:104 130:105 131:106 132:107 133:108 134:109 135:110 136:111 137:111 138:112 139:112 140:112 141:113 142:114 143:115 144:115 145:116 146:117 147:118 148:119 149:120 150:121 151:122 152:122 153:123 154:124 155:125 156:126 157:127 158:127 159:127 160:127 161:128 162:128 163:128 164:128 165:128 166:129 167:130 168:131 169:132 170:133 171:134 172:135 173:136 174:137 175:138 176:138 177:138 178:138 179:138 180:138 181:139 182:140 183:141 184:142 185:142 186:142 187:143 188:144 189:145 190:146 191:147 192:148 193:148 194:148 195:149 196:150 197:150 198:150 199:151 200:152 201:153 202:154 203:155 204:155
token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True
input_ids: 101 1327 1180 1301 2488 1118 1606 22484 13742 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000014
example_index: 14
doc_span_index: 0
tokens: [CLS] What ' s the best way to store the clarified butter ? [SEP] Most chef ##s use clarified butter for almost everything . It is never in recipes probably because it is not common in home kitchen ##s and a lot more expensive . Easy to make your own and then you can store in fridge for a week . Restaurant kitchen ##s usually make a bowl for the day and then have it next to the stove where it stays liquid and easy to use . Different types of sauce of course need different type of butter . Generally clarified butter can be used in any sauce that is using butter as a thick ##ener ; all cream ( or God for ##bid milk ) sauce ##s made with standard butter as there would be milk protein anyway ; em ##ul ##sions with egg yo ##lk are in fact better with clarified butter . The exception would be " be ##ur ##re b ##lan ##c " : as it is a butter sauce with no other em ##ul ##si ##fie ##r , it uses the non - fat milk protein to help the em ##ul ##sion stay together . Happy cooking and enjoy the taste ! [SEP]
token_to_orig_map: 14:0 15:1 16:1 17:2 18:3 19:4 20:5 21:6 22:7 23:7 24:8 25:9 26:10 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:19 36:20 37:21 38:21 39:22 40:23 41:24 42:25 43:26 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:41 61:42 62:43 63:43 64:44 65:45 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:54 75:55 76:56 77:57 78:58 79:59 80:60 81:61 82:62 83:63 84:64 85:65 86:66 87:66 88:67 89:68 90:69 91:70 92:71 93:72 94:73 95:74 96:75 97:76 98:77 99:77 100:78 101:79 102:80 103:81 104:82 105:83 106:84 107:85 108:86 109:87 110:88 111:89 112:90 113:91 114:92 115:93 116:93 117:93 118:94 119:95 120:96 121:96 122:97 123:98 124:98 125:99 126:99 127:100 128:100 129:101 130:102 131:103 132:104 133:105 134:106 135:107 136:108 137:109 138:110 139:111 140:111 141:112 142:112 143:112 144:113 145:114 146:115 147:115 148:116 149:117 150:118 151:119 152:120 153:121 154:122 155:122 156:123 157:124 158:125 159:126 160:127 161:127 162:127 163:127 164:128 165:128 166:128 167:128 168:128 169:129 170:130 171:131 172:132 173:133 174:134 175:135 176:136 177:137 178:138 179:138 180:138 181:138 182:138 183:138 184:139 185:140 186:141 187:142 188:142 189:142 190:143 191:144 192:145 193:146 194:147 195:148 196:148 197:148 198:149 199:150 200:150 201:150 202:151 203:152 204:153 205:154 206:155 207:155
token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True
input_ids: 101 1327 112 188 1103 1436 1236 1106 2984 1103 22484 13742 136 102 2082 13628 1116 1329 22484 13742 1111 1593 1917 119 1135 1110 1309 1107 23492 1930 1272 1122 1110 1136 1887 1107 1313 3119 1116 1105 170 1974 1167 5865 119 12167 1106 1294 1240 1319 1105 1173 1128 1169 2984 1107 18243 1111 170 1989 119 17925 3119 1116 1932 1294 170 7329 1111 1103 1285 1105 1173 1138 1122 1397 1106 1103 18362 1187 1122 12543 6161 1105 3123 1106 1329 119 14380 3322 1104 14313 1104 1736 1444 1472 2076 1104 13742 119 15559 22484 13742 1169 1129 1215 1107 1251 14313 1115 1110 1606 13742 1112 170 3528 24475 132 1155 7081 113 1137 1875 1111 14598 6831 114 14313 1116 1189 1114 2530 13742 1112 1175 1156 1129 6831 4592 4050 132 9712 4654 14971 1114 9069 26063 10493 1132 1107 1864 1618 1114 22484 13742 119 1109 5856 1156 1129 107 1129 2149 1874 171 4371 1665 107 131 1112 1122 1110 170 13742 14313 1114 1185 1168 9712 4654 5053 17569 1197 117 1122 2745 1103 1664 118 7930 6831 4592 1106 1494 1103 9712 4654 8427 2215 1487 119 8325 8739 1105 5548 1103 5080 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000015
example_index: 15
doc_span_index: 0
tokens: [CLS] What is a good way to drain to ##fu in a hurry ? [SEP] My time pressed to ##fu draining method is the microwave . You slice it into the size pieces you wa ##n then there are two different ways I have used : 1 ) Micro ##wave it for about two minutes . Water leak ##s out onto the plate , which you drain then microwave it for a couple more minutes . Keep doing this until it stops leaking out water . 2 ) Micro ##wave once for three minutes then place over a co ##lander to rain . The multiple time method works slightly better ( more through draining ) but once plus draining is easier . [SEP]
token_to_orig_map: 15:0 16:1 17:2 18:3 19:3 20:4 21:5 22:6 23:7 24:8 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:17 36:18 37:19 38:20 39:21 40:22 41:23 42:24 43:25 44:26 45:26 46:26 47:26 48:27 49:27 50:28 51:29 52:30 53:31 54:32 55:32 56:33 57:34 58:34 59:35 60:36 61:37 62:38 63:38 64:39 65:40 66:41 67:42 68:43 69:44 70:45 71:46 72:47 73:48 74:49 75:49 76:50 77:51 78:52 79:53 80:54 81:55 82:56 83:57 84:58 85:58 86:59 87:59 88:60 89:60 90:61 91:62 92:63 93:64 94:65 95:66 96:67 97:68 98:69 99:69 100:70 101:71 102:71 103:72 104:73 105:74 106:75 107:76 108:77 109:78 110:79 111:79 112:80 113:81 114:81 115:82 116:83 117:84 118:85 119:86 120:87 121:87
token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True
input_ids: 101 1327 1110 170 1363 1236 1106 13734 1106 14703 1107 170 10275 136 102 1422 1159 3691 1106 14703 21892 3442 1110 1103 21865 119 1192 16346 1122 1154 1103 2060 3423 1128 20049 1179 1173 1175 1132 1160 1472 3242 146 1138 1215 131 122 114 27730 17159 1122 1111 1164 1160 1904 119 4434 19299 1116 1149 2135 1103 4885 117 1134 1128 13734 1173 21865 1122 1111 170 2337 1167 1904 119 7947 1833 1142 1235 1122 6260 27742 1149 1447 119 123 114 27730 17159 1517 1111 1210 1904 1173 1282 1166 170 1884 21077 1106 4458 119 1109 2967 1159 3442 1759 2776 1618 113 1167 1194 21892 114 1133 1517 4882 21892 1110 5477 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000016
example_index: 16
doc_span_index: 0
tokens: [CLS] Is there another way to drain it ? [SEP] My time pressed to ##fu draining method is the microwave . You slice it into the size pieces you wa ##n then there are two different ways I have used : 1 ) Micro ##wave it for about two minutes . Water leak ##s out onto the plate , which you drain then microwave it for a couple more minutes . Keep doing this until it stops leaking out water . 2 ) Micro ##wave once for three minutes then place over a co ##lander to rain . The multiple time method works slightly better ( more through draining ) but once plus draining is easier . [SEP]
token_to_orig_map: 10:0 11:1 12:2 13:3 14:3 15:4 16:5 17:6 18:7 19:8 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:26 41:26 42:26 43:27 44:27 45:28 46:29 47:30 48:31 49:32 50:32 51:33 52:34 53:34 54:35 55:36 56:37 57:38 58:38 59:39 60:40 61:41 62:42 63:43 64:44 65:45 66:46 67:47 68:48 69:49 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:57 79:58 80:58 81:59 82:59 83:60 84:60 85:61 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:69 95:70 96:71 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:78 105:79 106:79 107:80 108:81 109:81 110:82 111:83 112:84 113:85 114:86 115:87 116:87
token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True
input_ids: 101 2181 1175 1330 1236 1106 13734 1122 136 102 1422 1159 3691 1106 14703 21892 3442 1110 1103 21865 119 1192 16346 1122 1154 1103 2060 3423 1128 20049 1179 1173 1175 1132 1160 1472 3242 146 1138 1215 131 122 114 27730 17159 1122 1111 1164 1160 1904 119 4434 19299 1116 1149 2135 1103 4885 117 1134 1128 13734 1173 21865 1122 1111 170 2337 1167 1904 119 7947 1833 1142 1235 1122 6260 27742 1149 1447 119 123 114 27730 17159 1517 1111 1210 1904 1173 1282 1166 170 1884 21077 1106 4458 119 1109 2967 1159 3442 1759 2776 1618 113 1167 1194 21892 114 1133 1517 4882 21892 1110 5477 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000017
example_index: 17
doc_span_index: 0
tokens: [CLS] Hi , I ##m interested in learning how to drain to ##fu , do you have any suggestions [SEP] My time pressed to ##fu draining method is the microwave . You slice it into the size pieces you wa ##n then there are two different ways I have used : 1 ) Micro ##wave it for about two minutes . Water leak ##s out onto the plate , which you drain then microwave it for a couple more minutes . Keep doing this until it stops leaking out water . 2 ) Micro ##wave once for three minutes then place over a co ##lander to rain . The multiple time method works slightly better ( more through draining ) but once plus draining is easier . [SEP]
token_to_orig_map: 20:0 21:1 22:2 23:3 24:3 25:4 26:5 27:6 28:7 29:8 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:17 41:18 42:19 43:20 44:21 45:22 46:23 47:24 48:25 49:26 50:26 51:26 52:26 53:27 54:27 55:28 56:29 57:30 58:31 59:32 60:32 61:33 62:34 63:34 64:35 65:36 66:37 67:38 68:38 69:39 70:40 71:41 72:42 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:49 81:50 82:51 83:52 84:53 85:54 86:55 87:56 88:57 89:58 90:58 91:59 92:59 93:60 94:60 95:61 96:62 97:63 98:64 99:65 100:66 101:67 102:68 103:69 104:69 105:70 106:71 107:71 108:72 109:73 110:74 111:75 112:76 113:77 114:78 115:79 116:79 117:80 118:81 119:81 120:82 121:83 122:84 123:85 124:86 125:87 126:87
token_is_max_context: 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True
input_ids: 101 8790 117 146 1306 3888 1107 3776 1293 1106 13734 1106 14703 117 1202 1128 1138 1251 17241 102 1422 1159 3691 1106 14703 21892 3442 1110 1103 21865 119 1192 16346 1122 1154 1103 2060 3423 1128 20049 1179 1173 1175 1132 1160 1472 3242 146 1138 1215 131 122 114 27730 17159 1122 1111 1164 1160 1904 119 4434 19299 1116 1149 2135 1103 4885 117 1134 1128 13734 1173 21865 1122 1111 170 2337 1167 1904 119 7947 1833 1142 1235 1122 6260 27742 1149 1447 119 123 114 27730 17159 1517 1111 1210 1904 1173 1282 1166 170 1884 21077 1106 4458 119 1109 2967 1159 3442 1759 2776 1618 113 1167 1194 21892 114 1133 1517 4882 21892 1110 5477 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000018
example_index: 18
doc_span_index: 0
tokens: [CLS] please tell me about your microwave method [SEP] My time pressed to ##fu draining method is the microwave . You slice it into the size pieces you wa ##n then there are two different ways I have used : 1 ) Micro ##wave it for about two minutes . Water leak ##s out onto the plate , which you drain then microwave it for a couple more minutes . Keep doing this until it stops leaking out water . 2 ) Micro ##wave once for three minutes then place over a co ##lander to rain . The multiple time method works slightly better ( more through draining ) but once plus draining is easier . [SEP]
token_to_orig_map: 9:0 10:1 11:2 12:3 13:3 14:4 15:5 16:6 17:7 18:8 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:17 30:18 31:19 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:26 40:26 41:26 42:27 43:27 44:28 45:29 46:30 47:31 48:32 49:32 50:33 51:34 52:34 53:35 54:36 55:37 56:38 57:38 58:39 59:40 60:41 61:42 62:43 63:44 64:45 65:46 66:47 67:48 68:49 69:49 70:50 71:51 72:52 73:53 74:54 75:55 76:56 77:57 78:58 79:58 80:59 81:59 82:60 83:60 84:61 85:62 86:63 87:64 88:65 89:66 90:67 91:68 92:69 93:69 94:70 95:71 96:71 97:72 98:73 99:74 100:75 101:76 102:77 103:78 104:79 105:79 106:80 107:81 108:81 109:82 110:83 111:84 112:85 113:86 114:87 115:87
token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True
input_ids: 101 4268 1587 1143 1164 1240 21865 3442 102 1422 1159 3691 1106 14703 21892 3442 1110 1103 21865 119 1192 16346 1122 1154 1103 2060 3423 1128 20049 1179 1173 1175 1132 1160 1472 3242 146 1138 1215 131 122 114 27730 17159 1122 1111 1164 1160 1904 119 4434 19299 1116 1149 2135 1103 4885 117 1134 1128 13734 1173 21865 1122 1111 170 2337 1167 1904 119 7947 1833 1142 1235 1122 6260 27742 1149 1447 119 123 114 27730 17159 1517 1111 1210 1904 1173 1282 1166 170 1884 21077 1106 4458 119 1109 2967 1159 3442 1759 2776 1618 113 1167 1194 21892 114 1133 1517 4882 21892 1110 5477 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000019
example_index: 19
doc_span_index: 0
tokens: [CLS] Ok great , which method is the quick ##est ? [SEP] My time pressed to ##fu draining method is the microwave . You slice it into the size pieces you wa ##n then there are two different ways I have used : 1 ) Micro ##wave it for about two minutes . Water leak ##s out onto the plate , which you drain then microwave it for a couple more minutes . Keep doing this until it stops leaking out water . 2 ) Micro ##wave once for three minutes then place over a co ##lander to rain . The multiple time method works slightly better ( more through draining ) but once plus draining is easier . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:3 16:3 17:4 18:5 19:6 20:7 21:8 22:8 23:9 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:17 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:26 43:26 44:26 45:27 46:27 47:28 48:29 49:30 50:31 51:32 52:32 53:33 54:34 55:34 56:35 57:36 58:37 59:38 60:38 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:58 83:59 84:59 85:60 86:60 87:61 88:62 89:63 90:64 91:65 92:66 93:67 94:68 95:69 96:69 97:70 98:71 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:79 109:80 110:81 111:81 112:82 113:83 114:84 115:85 116:86 117:87 118:87
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True
input_ids: 101 23330 1632 117 1134 3442 1110 1103 3613 2556 136 102 1422 1159 3691 1106 14703 21892 3442 1110 1103 21865 119 1192 16346 1122 1154 1103 2060 3423 1128 20049 1179 1173 1175 1132 1160 1472 3242 146 1138 1215 131 122 114 27730 17159 1122 1111 1164 1160 1904 119 4434 19299 1116 1149 2135 1103 4885 117 1134 1128 13734 1173 21865 1122 1111 170 2337 1167 1904 119 7947 1833 1142 1235 1122 6260 27742 1149 1447 119 123 114 27730 17159 1517 1111 1210 1904 1173 1282 1166 170 1884 21077 1106 4458 119 1109 2967 1159 3442 1759 2776 1618 113 1167 1194 21892 114 1133 1517 4882 21892 1110 5477 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
***** Dev *****
  Num orig examples = 662
  Num split examples = 662
  Batch size = 8
*** Example ***
unique_id: 1000000000
example_index: 0
doc_span_index: 0
tokens: [CLS] T ##ip ##s for g ##rill ##ing duck legs ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:2 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:20 37:21 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:31 49:32 50:33 51:34 52:34 53:35 54:35 55:35 56:36 57:37 58:38 59:39 60:40 61:40 62:41 63:41 64:42 65:43 66:44 67:45 68:45 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:56 82:57 83:58 84:59 85:59 86:59 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:68 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:84 115:84 116:85 117:85 118:85 119:86 120:87 121:88 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:99 137:100 138:101 139:102 140:103 141:103 142:104 143:105 144:106 145:107 146:108 147:109 148:110 149:110 150:111 151:112 152:113 153:114 154:115 155:116 156:117 157:118 158:119 159:120 160:121 161:122 162:122 163:123 164:124 165:125 166:126 167:127 168:127 169:128 170:129 171:130 172:131 173:131 174:131
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True
input_ids: 101 157 9717 1116 1111 176 11071 1158 13520 2584 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 12
end_position: 24
answer: I think g ##rill ##ing is probably a bad plan for duck legs
*** Example ***
unique_id: 1000000001
example_index: 1
doc_span_index: 0
tokens: [CLS] What makes you say that ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 8:0 9:1 10:2 11:2 12:2 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:31 45:32 46:33 47:34 48:34 49:35 50:35 51:35 52:36 53:37 54:38 55:39 56:40 57:40 58:41 59:41 60:42 61:43 62:44 63:45 64:45 65:45 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:54 75:55 76:56 77:56 78:57 79:58 80:59 81:59 82:59 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:70 95:71 96:72 97:73 98:74 99:75 100:76 101:77 102:77 103:78 104:79 105:80 106:81 107:82 108:83 109:84 110:84 111:84 112:85 113:85 114:85 115:86 116:87 117:88 118:88 119:89 120:89 121:89 122:90 123:91 124:91 125:92 126:93 127:94 128:95 129:96 130:97 131:98 132:99 133:100 134:101 135:102 136:103 137:103 138:104 139:105 140:106 141:107 142:108 143:109 144:110 145:110 146:111 147:112 148:113 149:114 150:115 151:116 152:117 153:118 154:119 155:120 156:121 157:122 158:122 159:123 160:124 161:125 162:126 163:127 164:127 165:128 166:129 167:130 168:131 169:131 170:131
token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True
input_ids: 101 1327 2228 1128 1474 1115 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 22
end_position: 49
answer: the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them
*** Example ***
unique_id: 1000000002
example_index: 2
doc_span_index: 0
tokens: [CLS] How long should I con ##fit or bra ##ise them ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 13:0 14:1 15:2 16:2 17:2 18:3 19:4 20:5 21:6 22:7 23:8 24:9 25:10 26:10 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:19 36:20 37:20 38:21 39:22 40:23 41:24 42:25 43:26 44:27 45:28 46:29 47:30 48:31 49:31 50:32 51:33 52:34 53:34 54:35 55:35 56:35 57:36 58:37 59:38 60:39 61:40 62:40 63:41 64:41 65:42 66:43 67:44 68:45 69:45 70:45 71:46 72:47 73:48 74:49 75:50 76:51 77:52 78:53 79:54 80:55 81:56 82:56 83:57 84:58 85:59 86:59 87:59 88:60 89:61 90:62 91:63 92:63 93:64 94:65 95:66 96:67 97:68 98:69 99:70 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:77 108:78 109:79 110:80 111:81 112:82 113:83 114:84 115:84 116:84 117:85 118:85 119:85 120:86 121:87 122:88 123:88 124:89 125:89 126:89 127:90 128:91 129:91 130:92 131:93 132:94 133:95 134:96 135:97 136:98 137:99 138:100 139:101 140:102 141:103 142:103 143:104 144:105 145:106 146:107 147:108 148:109 149:110 150:110 151:111 152:112 153:113 154:114 155:115 156:116 157:117 158:118 159:119 160:120 161:121 162:122 163:122 164:123 165:124 166:125 167:126 168:127 169:127 170:128 171:129 172:130 173:131 174:131 175:131
token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True
input_ids: 101 1731 1263 1431 146 14255 14067 1137 12418 4862 1172 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 56
end_position: 80
answer: If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first
*** Example ***
unique_id: 1000000003
example_index: 3
doc_span_index: 0
tokens: [CLS] At what temperature ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 6:0 7:1 8:2 9:2 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:19 29:20 30:20 31:21 32:22 33:23 34:24 35:25 36:26 37:27 38:28 39:29 40:30 41:31 42:31 43:32 44:33 45:34 46:34 47:35 48:35 49:35 50:36 51:37 52:38 53:39 54:40 55:40 56:41 57:41 58:42 59:43 60:44 61:45 62:45 63:45 64:46 65:47 66:48 67:49 68:50 69:51 70:52 71:53 72:54 73:55 74:56 75:56 76:57 77:58 78:59 79:59 80:59 81:60 82:61 83:62 84:63 85:63 86:64 87:65 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:74 97:75 98:76 99:77 100:77 101:78 102:79 103:80 104:81 105:82 106:83 107:84 108:84 109:84 110:85 111:85 112:85 113:86 114:87 115:88 116:88 117:89 118:89 119:89 120:90 121:91 122:91 123:92 124:93 125:94 126:95 127:96 128:97 129:98 130:99 131:100 132:101 133:102 134:103 135:103 136:104 137:105 138:106 139:107 140:108 141:109 142:110 143:110 144:111 145:112 146:113 147:114 148:115 149:116 150:117 151:118 152:119 153:120 154:121 155:122 156:122 157:123 158:124 159:125 160:126 161:127 162:127 163:128 164:129 165:130 166:131 167:131 168:131
token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True
input_ids: 101 1335 1184 4143 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 66
end_position: 67
answer: 200 degrees
*** Example ***
unique_id: 1000000004
example_index: 4
doc_span_index: 0
tokens: [CLS] Are there any other steps ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 8:0 9:1 10:2 11:2 12:2 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:31 45:32 46:33 47:34 48:34 49:35 50:35 51:35 52:36 53:37 54:38 55:39 56:40 57:40 58:41 59:41 60:42 61:43 62:44 63:45 64:45 65:45 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:54 75:55 76:56 77:56 78:57 79:58 80:59 81:59 82:59 83:60 84:61 85:62 86:63 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:70 95:71 96:72 97:73 98:74 99:75 100:76 101:77 102:77 103:78 104:79 105:80 106:81 107:82 108:83 109:84 110:84 111:84 112:85 113:85 114:85 115:86 116:87 117:88 118:88 119:89 120:89 121:89 122:90 123:91 124:91 125:92 126:93 127:94 128:95 129:96 130:97 131:98 132:99 133:100 134:101 135:102 136:103 137:103 138:104 139:105 140:106 141:107 142:108 143:109 144:110 145:110 146:111 147:112 148:113 149:114 150:115 151:116 152:117 153:118 154:119 155:120 156:121 157:122 158:122 159:123 160:124 161:125 162:126 163:127 164:127 165:128 166:129 167:130 168:131 169:131 170:131
token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True
input_ids: 101 2372 1175 1251 1168 3343 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 89
end_position: 101
answer: then resting them in the fridge for a day or so in oil
*** Example ***
unique_id: 1000000005
example_index: 5
doc_span_index: 0
tokens: [CLS] What a ##bo ##uy the g ##rill ##ing process ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:2 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:20 37:21 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:31 49:32 50:33 51:34 52:34 53:35 54:35 55:35 56:36 57:37 58:38 59:39 60:40 61:40 62:41 63:41 64:42 65:43 66:44 67:45 68:45 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:56 82:57 83:58 84:59 85:59 86:59 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:68 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:84 115:84 116:85 117:85 118:85 119:86 120:87 121:88 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:99 137:100 138:101 139:102 140:103 141:103 142:104 143:105 144:106 145:107 146:108 147:109 148:110 149:110 150:111 151:112 152:113 153:114 154:115 155:116 156:117 157:118 158:119 159:120 160:121 161:122 162:122 163:123 164:124 165:125 166:126 167:127 168:127 169:128 170:129 171:130 172:131 173:131 174:131
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True
input_ids: 101 1327 170 4043 20257 1103 176 11071 1158 1965 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 129
end_position: 167
answer: cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin
*** Example ***
unique_id: 1000000006
example_index: 6
doc_span_index: 0
tokens: [CLS] T ##ip ##s for g ##rill ##ing duck legs ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:2 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:20 37:21 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:31 49:32 50:33 51:34 52:34 53:35 54:35 55:35 56:36 57:37 58:38 59:39 60:40 61:40 62:41 63:41 64:42 65:43 66:44 67:45 68:45 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:56 82:57 83:58 84:59 85:59 86:59 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:68 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:84 115:84 116:85 117:85 118:85 119:86 120:87 121:88 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:99 137:100 138:101 139:102 140:103 141:103 142:104 143:105 144:106 145:107 146:108 147:109 148:110 149:110 150:111 151:112 152:113 153:114 154:115 155:116 156:117 157:118 158:119 159:120 160:121 161:122 162:122 163:123 164:124 165:125 166:126 167:127 168:127 169:128 170:129 171:130 172:131 173:131 174:131
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True
input_ids: 101 157 9717 1116 1111 176 11071 1158 13520 2584 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 12
end_position: 24
answer: I think g ##rill ##ing is probably a bad plan for duck legs
*** Example ***
unique_id: 1000000007
example_index: 7
doc_span_index: 0
tokens: [CLS] What would you recommend as a cooking method to make the meat tender ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 16:0 17:1 18:2 19:2 20:2 21:3 22:4 23:5 24:6 25:7 26:8 27:9 28:10 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:20 41:21 42:22 43:23 44:24 45:25 46:26 47:27 48:28 49:29 50:30 51:31 52:31 53:32 54:33 55:34 56:34 57:35 58:35 59:35 60:36 61:37 62:38 63:39 64:40 65:40 66:41 67:41 68:42 69:43 70:44 71:45 72:45 73:45 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:53 82:54 83:55 84:56 85:56 86:57 87:58 88:59 89:59 90:59 91:60 92:61 93:62 94:63 95:63 96:64 97:65 98:66 99:67 100:68 101:69 102:70 103:71 104:72 105:73 106:74 107:75 108:76 109:77 110:77 111:78 112:79 113:80 114:81 115:82 116:83 117:84 118:84 119:84 120:85 121:85 122:85 123:86 124:87 125:88 126:88 127:89 128:89 129:89 130:90 131:91 132:91 133:92 134:93 135:94 136:95 137:96 138:97 139:98 140:99 141:100 142:101 143:102 144:103 145:103 146:104 147:105 148:106 149:107 150:108 151:109 152:110 153:110 154:111 155:112 156:113 157:114 158:115 159:116 160:117 161:118 162:119 163:120 164:121 165:122 166:122 167:123 168:124 169:125 170:126 171:127 172:127 173:128 174:129 175:130 176:131 177:131 178:131
token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True
input_ids: 101 1327 1156 1128 18029 1112 170 8739 3442 1106 1294 1103 6092 8886 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 42
end_position: 57
answer: duck legs are tough enough you probably want to con ##fit them or bra ##ise them
*** Example ***
unique_id: 1000000008
example_index: 8
doc_span_index: 0
tokens: [CLS] How long should they be bra ##ised for ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 11:0 12:1 13:2 14:2 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:17 32:18 33:19 34:20 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:31 48:32 49:33 50:34 51:34 52:35 53:35 54:35 55:36 56:37 57:38 58:39 59:40 60:40 61:41 62:41 63:42 64:43 65:44 66:45 67:45 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:56 81:57 82:58 83:59 84:59 85:59 86:60 87:61 88:62 89:63 90:63 91:64 92:65 93:66 94:67 95:68 96:69 97:70 98:71 99:72 100:73 101:74 102:75 103:76 104:77 105:77 106:78 107:79 108:80 109:81 110:82 111:83 112:84 113:84 114:84 115:85 116:85 117:85 118:86 119:87 120:88 121:88 122:89 123:89 124:89 125:90 126:91 127:91 128:92 129:93 130:94 131:95 132:96 133:97 134:98 135:99 136:100 137:101 138:102 139:103 140:103 141:104 142:105 143:106 144:107 145:108 146:109 147:110 148:110 149:111 150:112 151:113 152:114 153:115 154:116 155:117 156:118 157:119 158:120 159:121 160:122 161:122 162:123 163:124 164:125 165:126 166:127 167:127 168:128 169:129 170:130 171:131 172:131 173:131
token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True
input_ids: 101 1731 1263 1431 1152 1129 12418 3673 1111 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 63
end_position: 77
answer: I would suggest con ##fit ##ing them at 200 degrees for three or four hours
*** Example ***
unique_id: 1000000009
example_index: 9
doc_span_index: 0
tokens: [CLS] T ##ip ##s for g ##rill ##ing duck legs ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:2 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:20 37:21 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:31 49:32 50:33 51:34 52:34 53:35 54:35 55:35 56:36 57:37 58:38 59:39 60:40 61:40 62:41 63:41 64:42 65:43 66:44 67:45 68:45 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:56 82:57 83:58 84:59 85:59 86:59 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:68 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:84 115:84 116:85 117:85 118:85 119:86 120:87 121:88 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:99 137:100 138:101 139:102 140:103 141:103 142:104 143:105 144:106 145:107 146:108 147:109 148:110 149:110 150:111 151:112 152:113 153:114 154:115 155:116 156:117 157:118 158:119 159:120 160:121 161:122 162:122 163:123 164:124 165:125 166:126 167:127 168:127 169:128 170:129 171:130 172:131 173:131 174:131
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True
input_ids: 101 157 9717 1116 1111 176 11071 1158 13520 2584 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 12
end_position: 24
answer: I think g ##rill ##ing is probably a bad plan for duck legs
*** Example ***
unique_id: 1000000010
example_index: 10
doc_span_index: 0
tokens: [CLS] Why is it a bad plan ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 9:0 10:1 11:2 12:2 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:31 46:32 47:33 48:34 49:34 50:35 51:35 52:35 53:36 54:37 55:38 56:39 57:40 58:40 59:41 60:41 61:42 62:43 63:44 64:45 65:45 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:56 79:57 80:58 81:59 82:59 83:59 84:60 85:61 86:62 87:63 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:74 100:75 101:76 102:77 103:77 104:78 105:79 106:80 107:81 108:82 109:83 110:84 111:84 112:84 113:85 114:85 115:85 116:86 117:87 118:88 119:88 120:89 121:89 122:89 123:90 124:91 125:91 126:92 127:93 128:94 129:95 130:96 131:97 132:98 133:99 134:100 135:101 136:102 137:103 138:103 139:104 140:105 141:106 142:107 143:108 144:109 145:110 146:110 147:111 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:122 159:122 160:123 161:124 162:125 163:126 164:127 165:127 166:128 167:129 168:130 169:131 170:131 171:131
token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True
input_ids: 101 2009 1110 1122 170 2213 2197 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 23
end_position: 50
answer: the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them
*** Example ***
unique_id: 1000000011
example_index: 11
doc_span_index: 0
tokens: [CLS] Will this make the duck tough ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 9:0 10:1 11:2 12:2 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:31 46:32 47:33 48:34 49:34 50:35 51:35 52:35 53:36 54:37 55:38 56:39 57:40 58:40 59:41 60:41 61:42 62:43 63:44 64:45 65:45 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:56 79:57 80:58 81:59 82:59 83:59 84:60 85:61 86:62 87:63 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:70 96:71 97:72 98:73 99:74 100:75 101:76 102:77 103:77 104:78 105:79 106:80 107:81 108:82 109:83 110:84 111:84 112:84 113:85 114:85 115:85 116:86 117:87 118:88 119:88 120:89 121:89 122:89 123:90 124:91 125:91 126:92 127:93 128:94 129:95 130:96 131:97 132:98 133:99 134:100 135:101 136:102 137:103 138:103 139:104 140:105 141:106 142:107 143:108 144:109 145:110 146:110 147:111 148:112 149:113 150:114 151:115 152:116 153:117 154:118 155:119 156:120 157:121 158:122 159:122 160:123 161:124 162:125 163:126 164:127 165:127 166:128 167:129 168:130 169:131 170:131 171:131
token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True
input_ids: 101 3100 1142 1294 1103 13520 8035 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 52
end_position: 87
answer: If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch
*** Example ***
unique_id: 1000000012
example_index: 12
doc_span_index: 0
tokens: [CLS] How do I make them look appealing ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 10:0 11:1 12:2 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:8 21:9 22:10 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:27 42:28 43:29 44:30 45:31 46:31 47:32 48:33 49:34 50:34 51:35 52:35 53:35 54:36 55:37 56:38 57:39 58:40 59:40 60:41 61:41 62:42 63:43 64:44 65:45 66:45 67:45 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:54 77:55 78:56 79:56 80:57 81:58 82:59 83:59 84:59 85:60 86:61 87:62 88:63 89:63 90:64 91:65 92:66 93:67 94:68 95:69 96:70 97:71 98:72 99:73 100:74 101:75 102:76 103:77 104:77 105:78 106:79 107:80 108:81 109:82 110:83 111:84 112:84 113:84 114:85 115:85 116:85 117:86 118:87 119:88 120:88 121:89 122:89 123:89 124:90 125:91 126:91 127:92 128:93 129:94 130:95 131:96 132:97 133:98 134:99 135:100 136:101 137:102 138:103 139:103 140:104 141:105 142:106 143:107 144:108 145:109 146:110 147:110 148:111 149:112 150:113 151:114 152:115 153:116 154:117 155:118 156:119 157:120 158:121 159:122 160:122 161:123 162:124 163:125 164:126 165:127 166:127 167:128 168:129 169:130 170:131 171:131 172:131
token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True
input_ids: 101 1731 1202 146 1294 1172 1440 17117 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 92
end_position: 103
answer: resting them in the fridge for a day or so in oil
*** Example ***
unique_id: 1000000013
example_index: 13
doc_span_index: 0
tokens: [CLS] Do you have any other advice to make this me ##lal not turn out as a disaster ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 20:0 21:1 22:2 23:2 24:2 25:3 26:4 27:5 28:6 29:7 30:8 31:9 32:10 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:20 45:21 46:22 47:23 48:24 49:25 50:26 51:27 52:28 53:29 54:30 55:31 56:31 57:32 58:33 59:34 60:34 61:35 62:35 63:35 64:36 65:37 66:38 67:39 68:40 69:40 70:41 71:41 72:42 73:43 74:44 75:45 76:45 77:45 78:46 79:47 80:48 81:49 82:50 83:51 84:52 85:53 86:54 87:55 88:56 89:56 90:57 91:58 92:59 93:59 94:59 95:60 96:61 97:62 98:63 99:63 100:64 101:65 102:66 103:67 104:68 105:69 106:70 107:71 108:72 109:73 110:74 111:75 112:76 113:77 114:77 115:78 116:79 117:80 118:81 119:82 120:83 121:84 122:84 123:84 124:85 125:85 126:85 127:86 128:87 129:88 130:88 131:89 132:89 133:89 134:90 135:91 136:91 137:92 138:93 139:94 140:95 141:96 142:97 143:98 144:99 145:100 146:101 147:102 148:103 149:103 150:104 151:105 152:106 153:107 154:108 155:109 156:110 157:110 158:111 159:112 160:113 161:114 162:115 163:116 164:117 165:118 166:119 167:120 168:121 169:122 170:122 171:123 172:124 173:125 174:126 175:127 176:127 177:128 178:129 179:130 180:131 181:131 182:131
token_is_max_context: 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True
input_ids: 101 2091 1128 1138 1251 1168 5566 1106 1294 1142 1143 14258 1136 1885 1149 1112 170 7286 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 115
end_position: 156
answer: As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through
*** Example ***
unique_id: 1000000014
example_index: 14
doc_span_index: 0
tokens: [CLS] Do I let them rest after they are cooked ? [SEP] I think g ##rill ##ing is probably a bad plan for duck legs ; the fat content is a real danger like you said , and duck legs are tough enough you probably want to con ##fit them or bra ##ise them . If you absolutely have to g ##rill them , I would suggest con ##fit ##ing them at 200 degrees for three or four hours first ( you could use ve ##gg ##ie oil in a pinch ) and then resting them in the fridge for a day or so in oil . As for finishing them on the g ##rill , r ##ins ##e them off gently , re - season if needed , cook flesh side down on a medium heat portion of the g ##rill for a while until mostly heated through , then flip them over on a high heat portion of the g ##rill to crisp up the skin , watching out for flare ##s . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:2 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:20 37:21 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:31 49:32 50:33 51:34 52:34 53:35 54:35 55:35 56:36 57:37 58:38 59:39 60:40 61:40 62:41 63:41 64:42 65:43 66:44 67:45 68:45 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:56 82:57 83:58 84:59 85:59 86:59 87:60 88:61 89:62 90:63 91:63 92:64 93:65 94:66 95:67 96:68 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:84 114:84 115:84 116:85 117:85 118:85 119:86 120:87 121:88 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:92 130:93 131:94 132:95 133:96 134:97 135:98 136:99 137:100 138:101 139:102 140:103 141:103 142:104 143:105 144:106 145:107 146:108 147:109 148:110 149:110 150:111 151:112 152:113 153:114 154:115 155:116 156:117 157:118 158:119 159:120 160:121 161:122 162:122 163:123 164:124 165:125 166:126 167:127 168:127 169:128 170:129 171:130 172:131 173:131 174:131
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True
input_ids: 101 2091 146 1519 1172 1832 1170 1152 1132 13446 136 102 146 1341 176 11071 1158 1110 1930 170 2213 2197 1111 13520 2584 132 1103 7930 3438 1110 170 1842 5170 1176 1128 1163 117 1105 13520 2584 1132 8035 1536 1128 1930 1328 1106 14255 14067 1172 1137 12418 4862 1172 119 1409 1128 7284 1138 1106 176 11071 1172 117 146 1156 5996 14255 14067 1158 1172 1120 2363 4842 1111 1210 1137 1300 2005 1148 113 1128 1180 1329 1396 9705 1663 2949 1107 170 21466 114 1105 1173 8137 1172 1107 1103 18243 1111 170 1285 1137 1177 1107 2949 119 1249 1111 4416 1172 1113 1103 176 11071 117 187 4935 1162 1172 1228 4588 117 1231 118 1265 1191 1834 117 9834 5352 1334 1205 1113 170 5143 3208 3849 1104 1103 176 11071 1111 170 1229 1235 2426 9511 1194 117 1173 12785 1172 1166 1113 170 1344 3208 3849 1104 1103 176 11071 1106 19501 1146 1103 2241 117 2903 1149 1111 20646 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 94
end_position: 105
answer: resting them in the fridge for a day or so in oil
*** Example ***
unique_id: 1000000015
example_index: 15
doc_span_index: 0
tokens: [CLS] Mean ##ing of do not th ##aw for frozen food [SEP] Your question is slightly confusing but I ' ll try to answer your question . As far as I can tell M ##c ##C ##oi ##n brand is bags of frozen vegetables ( correct me if I am wrong ) . If it says do not th ##aw and to cook from frozen , it just means you do not need to th ##aw it before you cook it . T ##haw ##ing is the act of un ##free ##zing something . This can be accomplished by leaving something out at room temperature to naturally th ##aw . So if you have frozen corn and want to put it in ch ##ili or soup , just throw the frozen corn directly in without th ##aw ##ing it . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:6 20:6 21:7 22:8 23:9 24:10 25:11 26:11 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:17 35:17 36:17 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:24 46:25 47:26 48:27 49:28 50:29 51:29 52:29 53:29 54:30 55:31 56:32 57:33 58:34 59:34 60:35 61:36 62:37 63:38 64:39 65:39 66:40 67:41 68:42 69:43 70:44 71:45 72:46 73:47 74:48 75:48 76:49 77:50 78:51 79:52 80:53 81:53 82:54 83:54 84:54 85:55 86:56 87:57 88:58 89:59 90:59 91:59 92:60 93:60 94:61 95:62 96:63 97:64 98:65 99:66 100:67 101:68 102:69 103:70 104:71 105:72 106:73 107:74 108:74 109:74 110:74 111:75 112:76 113:77 114:78 115:79 116:80 117:81 118:82 119:83 120:84 121:85 122:86 123:86 124:87 125:88 126:88 127:89 128:90 129:91 130:92 131:93 132:94 133:95 134:96 135:97 136:97 137:97 138:98 139:98
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True
input_ids: 101 25030 1158 1104 1202 1136 24438 7220 1111 7958 2094 102 2353 2304 1110 2776 18110 1133 146 112 1325 2222 1106 2590 1240 2304 119 1249 1677 1112 146 1169 1587 150 1665 1658 8136 1179 4097 1110 8483 1104 7958 11872 113 5663 1143 1191 146 1821 2488 114 119 1409 1122 1867 1202 1136 24438 7220 1105 1106 9834 1121 7958 117 1122 1198 2086 1128 1202 1136 1444 1106 24438 7220 1122 1196 1128 9834 1122 119 157 14431 1158 1110 1103 2496 1104 8362 26743 6185 1380 119 1188 1169 1129 8587 1118 2128 1380 1149 1120 1395 4143 1106 8534 24438 7220 119 1573 1191 1128 1138 7958 11184 1105 1328 1106 1508 1122 1107 22572 18575 1137 13128 117 1198 4932 1103 7958 11184 2626 1107 1443 24438 7220 1158 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 66
end_position: 80
answer: it just means you do not need to th ##aw it before you cook it
*** Example ***
unique_id: 1000000016
example_index: 16
doc_span_index: 0
tokens: [CLS] oh okay . am i supposed to wash frozen food after opening the package or can i cook it directly ? [SEP] Your question is slightly confusing but I ' ll try to answer your question . As far as I can tell M ##c ##C ##oi ##n brand is bags of frozen vegetables ( correct me if I am wrong ) . If it says do not th ##aw and to cook from frozen , it just means you do not need to th ##aw it before you cook it . T ##haw ##ing is the act of un ##free ##zing something . This can be accomplished by leaving something out at room temperature to naturally th ##aw . So if you have frozen corn and want to put it in ch ##ili or soup , just throw the frozen corn directly in without th ##aw ##ing it . [SEP]
token_to_orig_map: 23:0 24:1 25:2 26:3 27:4 28:5 29:6 30:6 31:6 32:7 33:8 34:9 35:10 36:11 37:11 38:11 39:12 40:13 41:14 42:15 43:16 44:17 45:17 46:17 47:17 48:17 49:18 50:19 51:20 52:21 53:22 54:23 55:24 56:24 57:25 58:26 59:27 60:28 61:29 62:29 63:29 64:29 65:30 66:31 67:32 68:33 69:34 70:34 71:35 72:36 73:37 74:38 75:39 76:39 77:40 78:41 79:42 80:43 81:44 82:45 83:46 84:47 85:48 86:48 87:49 88:50 89:51 90:52 91:53 92:53 93:54 94:54 95:54 96:55 97:56 98:57 99:58 100:59 101:59 102:59 103:60 104:60 105:61 106:62 107:63 108:64 109:65 110:66 111:67 112:68 113:69 114:70 115:71 116:72 117:73 118:74 119:74 120:74 121:74 122:75 123:76 124:77 125:78 126:79 127:80 128:81 129:82 130:83 131:84 132:85 133:86 134:86 135:87 136:88 137:88 138:89 139:90 140:91 141:92 142:93 143:94 144:95 145:96 146:97 147:97 148:97 149:98 150:98
token_is_max_context: 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True
input_ids: 101 9294 3008 119 1821 178 3155 1106 10124 7958 2094 1170 2280 1103 7305 1137 1169 178 9834 1122 2626 136 102 2353 2304 1110 2776 18110 1133 146 112 1325 2222 1106 2590 1240 2304 119 1249 1677 1112 146 1169 1587 150 1665 1658 8136 1179 4097 1110 8483 1104 7958 11872 113 5663 1143 1191 146 1821 2488 114 119 1409 1122 1867 1202 1136 24438 7220 1105 1106 9834 1121 7958 117 1122 1198 2086 1128 1202 1136 1444 1106 24438 7220 1122 1196 1128 9834 1122 119 157 14431 1158 1110 1103 2496 1104 8362 26743 6185 1380 119 1188 1169 1129 8587 1118 2128 1380 1149 1120 1395 4143 1106 8534 24438 7220 119 1573 1191 1128 1138 7958 11184 1105 1328 1106 1508 1122 1107 22572 18575 1137 13128 117 1198 4932 1103 7958 11184 2626 1107 1443 24438 7220 1158 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 121
end_position: 149
answer: So if you have frozen corn and want to put it in ch ##ili or soup , just throw the frozen corn directly in without th ##aw ##ing it
*** Example ***
unique_id: 1000000017
example_index: 17
doc_span_index: 0
tokens: [CLS] Mean ##ing of do not th ##aw for frozen food [SEP] Your question is slightly confusing but I ' ll try to answer your question . As far as I can tell M ##c ##C ##oi ##n brand is bags of frozen vegetables ( correct me if I am wrong ) . If it says do not th ##aw and to cook from frozen , it just means you do not need to th ##aw it before you cook it . T ##haw ##ing is the act of un ##free ##zing something . This can be accomplished by leaving something out at room temperature to naturally th ##aw . So if you have frozen corn and want to put it in ch ##ili or soup , just throw the frozen corn directly in without th ##aw ##ing it . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:6 20:6 21:7 22:8 23:9 24:10 25:11 26:11 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:17 35:17 36:17 37:17 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:24 46:25 47:26 48:27 49:28 50:29 51:29 52:29 53:29 54:30 55:31 56:32 57:33 58:34 59:34 60:35 61:36 62:37 63:38 64:39 65:39 66:40 67:41 68:42 69:43 70:44 71:45 72:46 73:47 74:48 75:48 76:49 77:50 78:51 79:52 80:53 81:53 82:54 83:54 84:54 85:55 86:56 87:57 88:58 89:59 90:59 91:59 92:60 93:60 94:61 95:62 96:63 97:64 98:65 99:66 100:67 101:68 102:69 103:70 104:71 105:72 106:73 107:74 108:74 109:74 110:74 111:75 112:76 113:77 114:78 115:79 116:80 117:81 118:82 119:83 120:84 121:85 122:86 123:86 124:87 125:88 126:88 127:89 128:90 129:91 130:92 131:93 132:94 133:95 134:96 135:97 136:97 137:97 138:98 139:98
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True
input_ids: 101 25030 1158 1104 1202 1136 24438 7220 1111 7958 2094 102 2353 2304 1110 2776 18110 1133 146 112 1325 2222 1106 2590 1240 2304 119 1249 1677 1112 146 1169 1587 150 1665 1658 8136 1179 4097 1110 8483 1104 7958 11872 113 5663 1143 1191 146 1821 2488 114 119 1409 1122 1867 1202 1136 24438 7220 1105 1106 9834 1121 7958 117 1122 1198 2086 1128 1202 1136 1444 1106 24438 7220 1122 1196 1128 9834 1122 119 157 14431 1158 1110 1103 2496 1104 8362 26743 6185 1380 119 1188 1169 1129 8587 1118 2128 1380 1149 1120 1395 4143 1106 8534 24438 7220 119 1573 1191 1128 1138 7958 11184 1105 1328 1106 1508 1122 1107 22572 18575 1137 13128 117 1198 4932 1103 7958 11184 2626 1107 1443 24438 7220 1158 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 53
end_position: 80
answer: If it says do not th ##aw and to cook from frozen , it just means you do not need to th ##aw it before you cook it
*** Example ***
unique_id: 1000000018
example_index: 18
doc_span_index: 0
tokens: [CLS] what ' s a good technique for freezing blue ##berries ? [SEP] Lay them out on a paper towel overnight so that the skins dry completely . This gives the benefit of keeping the frozen blue ##berries from sticking together without needing lots of freeze ##r space to do a quick freeze individually on a sheet pan . Then bag in a freeze ##r bag and freeze . Note that whenever you freeze fruit , the liquid will burst the cell walls as it th ##aws , causing the resulting be ##rry to be m ##ush ##ier . In my experience , frozen blue ##berries aren ' t good for eating alone . To b ##ake with blue ##berries , th ##aw them by placing them in a mesh si ##eve or co ##lland ##er and running water over them until the water is clear off the bottom ( no pig ##mentation from the skins , which may color your baked goods ) and the berries are th ##awed . Dry the skins before using in baking . Using these techniques I have not once had any of the 30 pounds of blue ##berries I froze this summer burst in the freeze ##r and have successfully made many blue ##berry baked goods from the results . [SEP]
token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:13 28:14 29:15 30:16 31:17 32:18 33:19 34:20 35:21 36:22 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:41 59:42 60:43 61:44 62:45 63:46 64:46 65:47 66:48 67:49 68:49 69:49 70:50 71:51 72:52 73:53 74:54 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:64 87:64 88:65 89:66 90:67 91:68 92:68 93:69 94:70 95:71 96:71 97:71 98:71 99:72 100:73 101:74 102:74 103:75 104:76 105:76 106:77 107:77 108:77 109:78 110:79 111:80 112:81 113:81 114:82 115:83 116:83 117:84 118:85 119:85 120:85 121:86 122:86 123:87 124:88 125:89 126:90 127:91 128:92 129:93 130:94 131:94 132:95 133:96 134:96 135:96 136:97 137:98 138:99 139:100 140:101 141:102 142:103 143:104 144:105 145:106 146:107 147:108 148:109 149:110 150:110 151:111 152:111 153:112 154:113 155:114 156:114 157:115 158:116 159:117 160:118 161:119 162:120 163:120 164:121 165:122 166:123 167:124 168:125 169:125 170:125 171:126 172:127 173:128 174:129 175:130 176:131 177:132 178:132 179:132 180:133 181:134 182:135 183:136 184:137 185:138 186:139 187:140 188:141 189:142 190:143 191:144 192:145 193:146 194:146 195:147 196:148 197:149 198:150 199:151 200:152 201:153 202:154 203:154 204:155 205:156 206:157 207:158 208:159 209:160 210:160 211:161 212:162 213:163 214:164 215:165 216:165
token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True
input_ids: 101 1184 112 188 170 1363 5531 1111 13543 2221 22630 136 102 22002 1172 1149 1113 170 2526 10166 12292 1177 1115 1103 27033 3712 2423 119 1188 3114 1103 5257 1104 3709 1103 7958 2221 22630 1121 14103 1487 1443 12038 7424 1104 16020 1197 2000 1106 1202 170 3613 16020 15473 1113 170 6837 13316 119 1599 3821 1107 170 16020 1197 3821 1105 16020 119 5322 1115 7747 1128 16020 5735 117 1103 6161 1209 6007 1103 2765 2928 1112 1122 24438 19194 117 3989 1103 3694 1129 6234 1106 1129 182 13148 2852 119 1130 1139 2541 117 7958 2221 22630 4597 112 189 1363 1111 5497 2041 119 1706 171 9899 1114 2221 22630 117 24438 7220 1172 1118 6544 1172 1107 170 24000 27466 19907 1137 1884 24397 1200 1105 1919 1447 1166 1172 1235 1103 1447 1110 2330 1228 1103 3248 113 1185 13407 18415 1121 1103 27033 117 1134 1336 2942 1240 19983 4817 114 1105 1103 26571 1132 24438 21449 119 18112 1103 27033 1196 1606 1107 26377 119 7993 1292 4884 146 1138 1136 1517 1125 1251 1104 1103 1476 6549 1104 2221 22630 146 10539 1142 2247 6007 1107 1103 16020 1197 1105 1138 4358 1189 1242 2221 6614 19983 4817 1121 1103 2686 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 13
end_position: 26
answer: Lay them out on a paper towel overnight so that the skins dry completely
*** Example ***
unique_id: 1000000019
example_index: 19
doc_span_index: 0
tokens: [CLS] Could I put them in the oven at 150 for an hour [SEP] Lay them out on a paper towel overnight so that the skins dry completely . This gives the benefit of keeping the frozen blue ##berries from sticking together without needing lots of freeze ##r space to do a quick freeze individually on a sheet pan . Then bag in a freeze ##r bag and freeze . Note that whenever you freeze fruit , the liquid will burst the cell walls as it th ##aws , causing the resulting be ##rry to be m ##ush ##ier . In my experience , frozen blue ##berries aren ' t good for eating alone . To b ##ake with blue ##berries , th ##aw them by placing them in a mesh si ##eve or co ##lland ##er and running water over them until the water is clear off the bottom ( no pig ##mentation from the skins , which may color your baked goods ) and the berries are th ##awed . Dry the skins before using in baking . Using these techniques I have not once had any of the 30 pounds of blue ##berries I froze this summer burst in the freeze ##r and have successfully made many blue ##berry baked goods from the results . [SEP]
token_to_orig_map: 14:0 15:1 16:2 17:3 18:4 19:5 20:6 21:7 22:8 23:9 24:10 25:11 26:12 27:13 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:29 46:30 47:30 48:31 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:44 63:45 64:46 65:46 66:47 67:48 68:49 69:49 70:49 71:50 72:51 73:52 74:53 75:54 76:54 77:55 78:56 79:57 80:58 81:59 82:60 83:61 84:62 85:63 86:64 87:64 88:64 89:65 90:66 91:67 92:68 93:68 94:69 95:70 96:71 97:71 98:71 99:71 100:72 101:73 102:74 103:74 104:75 105:76 106:76 107:77 108:77 109:77 110:78 111:79 112:80 113:81 114:81 115:82 116:83 117:83 118:84 119:85 120:85 121:85 122:86 123:86 124:87 125:88 126:89 127:90 128:91 129:92 130:93 131:94 132:94 133:95 134:96 135:96 136:96 137:97 138:98 139:99 140:100 141:101 142:102 143:103 144:104 145:105 146:106 147:107 148:108 149:109 150:110 151:110 152:111 153:111 154:112 155:113 156:114 157:114 158:115 159:116 160:117 161:118 162:119 163:120 164:120 165:121 166:122 167:123 168:124 169:125 170:125 171:125 172:126 173:127 174:128 175:129 176:130 177:131 178:132 179:132 180:132 181:133 182:134 183:135 184:136 185:137 186:138 187:139 188:140 189:141 190:142 191:143 192:144 193:145 194:146 195:146 196:147 197:148 198:149 199:150 200:151 201:152 202:153 203:154 204:154 205:155 206:156 207:157 208:158 209:159 210:160 211:160 212:161 213:162 214:163 215:164 216:165 217:165
token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True
input_ids: 101 7426 146 1508 1172 1107 1103 19645 1120 4214 1111 1126 2396 102 22002 1172 1149 1113 170 2526 10166 12292 1177 1115 1103 27033 3712 2423 119 1188 3114 1103 5257 1104 3709 1103 7958 2221 22630 1121 14103 1487 1443 12038 7424 1104 16020 1197 2000 1106 1202 170 3613 16020 15473 1113 170 6837 13316 119 1599 3821 1107 170 16020 1197 3821 1105 16020 119 5322 1115 7747 1128 16020 5735 117 1103 6161 1209 6007 1103 2765 2928 1112 1122 24438 19194 117 3989 1103 3694 1129 6234 1106 1129 182 13148 2852 119 1130 1139 2541 117 7958 2221 22630 4597 112 189 1363 1111 5497 2041 119 1706 171 9899 1114 2221 22630 117 24438 7220 1172 1118 6544 1172 1107 170 24000 27466 19907 1137 1884 24397 1200 1105 1919 1447 1166 1172 1235 1103 1447 1110 2330 1228 1103 3248 113 1185 13407 18415 1121 1103 27033 117 1134 1336 2942 1240 19983 4817 114 1105 1103 26571 1132 24438 21449 119 18112 1103 27033 1196 1606 1107 26377 119 7993 1292 4884 146 1138 1136 1517 1125 1251 1104 1103 1476 6549 1104 2221 22630 146 10539 1142 2247 6007 1107 1103 16020 1197 1105 1138 4358 1189 1242 2221 6614 19983 4817 1121 1103 2686 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
start_position: 115
end_position: 149
answer: To b ##ake with blue ##berries , th ##aw them by placing them in a mesh si ##eve or co ##lland ##er and running water over them until the water is clear off the bottom
***** Train *****
  Num orig examples = 3341
  Num split examples = 3341
  Batch size = 32
  Num steps = 2100
Start epoch #0 (lr = 1e-06)...
Epoch: 0, Step: 10 / 105, used_time = 6.56s, loss = 6.001276
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 16.590036868462516
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=0): 16.59
Epoch: 0, Step: 20 / 105, used_time = 18.90s, loss = 5.993877
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 16.782990813408308
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=0): 16.78
Epoch: 0, Step: 30 / 105, used_time = 31.42s, loss = 5.980828
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 16.63146695676176
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.71s, loss = 5.965410
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 16.530103173946713
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 54.06s, loss = 5.952344
***** Eval results *****
  exact = 0.0
  f1 = 16.410893249057693
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 65.45s, loss = 5.935456
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 16.546981275119336
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 76.70s, loss = 5.917691
***** Eval results *****
  exact = 0.45317220543806647
  f1 = 17.159727111139006
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=0): 17.16
Epoch: 0, Step: 80 / 105, used_time = 89.45s, loss = 5.896732
***** Eval results *****
  exact = 0.6042296072507553
  f1 = 17.88210079823061
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=0): 17.88
Epoch: 0, Step: 90 / 105, used_time = 102.23s, loss = 5.872964
***** Eval results *****
  exact = 1.0574018126888218
  f1 = 17.83042919755612
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 114.18s, loss = 5.845314
***** Eval results *****
  exact = 0.9063444108761329
  f1 = 19.249881354793313
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=0): 19.25
Start epoch #1 (lr = 1e-06)...
Epoch: 1, Step: 10 / 105, used_time = 130.76s, loss = 5.792828
***** Eval results *****
  exact = 0.9063444108761329
  f1 = 20.19674059055936
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 20.20
Epoch: 1, Step: 20 / 105, used_time = 143.71s, loss = 5.748395
***** Eval results *****
  exact = 0.9063444108761329
  f1 = 20.5030044911331
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 20.50
Epoch: 1, Step: 30 / 105, used_time = 157.13s, loss = 5.701481
***** Eval results *****
  exact = 1.0574018126888218
  f1 = 21.636744132449003
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 21.64
Epoch: 1, Step: 40 / 105, used_time = 170.63s, loss = 5.646909
***** Eval results *****
  exact = 1.2084592145015105
  f1 = 21.697611160658436
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 21.70
Epoch: 1, Step: 50 / 105, used_time = 184.10s, loss = 5.589119
***** Eval results *****
  exact = 1.0574018126888218
  f1 = 21.465309559966027
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 196.44s, loss = 5.525279
***** Eval results *****
  exact = 1.3595166163141994
  f1 = 21.636975208899145
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 208.66s, loss = 5.459954
***** Eval results *****
  exact = 1.8126888217522659
  f1 = 22.275113096513664
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 22.28
Epoch: 1, Step: 80 / 105, used_time = 222.13s, loss = 5.385739
***** Eval results *****
  exact = 1.8126888217522659
  f1 = 22.63372381252168
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 22.63
Epoch: 1, Step: 90 / 105, used_time = 235.60s, loss = 5.314351
***** Eval results *****
  exact = 2.719033232628399
  f1 = 23.39110098629433
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 23.39
Epoch: 1, Step: 100 / 105, used_time = 249.17s, loss = 5.244464
***** Eval results *****
  exact = 3.0211480362537766
  f1 = 23.969699121084673
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=1): 23.97
Start epoch #2 (lr = 1e-06)...
Epoch: 2, Step: 10 / 105, used_time = 266.02s, loss = 5.131718
***** Eval results *****
  exact = 3.6253776435045317
  f1 = 25.1879299345864
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=2): 25.19
Epoch: 2, Step: 20 / 105, used_time = 279.33s, loss = 5.059779
***** Eval results *****
  exact = 3.9274924471299095
  f1 = 25.771159063356578
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=2): 25.77
Epoch: 2, Step: 30 / 105, used_time = 292.81s, loss = 4.982846
***** Eval results *****
  exact = 4.380664652567976
  f1 = 25.190288658594934
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 305.17s, loss = 4.915816
***** Eval results *****
  exact = 4.984894259818731
  f1 = 25.931309761184014
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=2): 25.93
Epoch: 2, Step: 50 / 105, used_time = 318.64s, loss = 4.847629
***** Eval results *****
  exact = 5.438066465256798
  f1 = 25.67074627335811
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 331.09s, loss = 4.781075
***** Eval results *****
  exact = 5.438066465256798
  f1 = 25.676222566097053
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 343.27s, loss = 4.718800
***** Eval results *****
  exact = 4.984894259818731
  f1 = 25.458659213354203
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 355.34s, loss = 4.658582
***** Eval results *****
  exact = 5.589123867069486
  f1 = 25.746710887121996
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 367.43s, loss = 4.604841
***** Eval results *****
  exact = 5.589123867069486
  f1 = 26.362268337817742
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=2): 26.36
Epoch: 2, Step: 100 / 105, used_time = 380.80s, loss = 4.563549
***** Eval results *****
  exact = 5.589123867069486
  f1 = 26.716976744794817
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=2): 26.72
Start epoch #3 (lr = 1e-06)...
Epoch: 3, Step: 10 / 105, used_time = 397.46s, loss = 4.486002
***** Eval results *****
  exact = 5.891238670694864
  f1 = 26.68537142425753
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 409.97s, loss = 4.443551
***** Eval results *****
  exact = 6.042296072507553
  f1 = 26.573727411267082
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 422.51s, loss = 4.395574
***** Eval results *****
  exact = 6.193353474320242
  f1 = 26.805531051647794
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=3): 26.81
Epoch: 3, Step: 40 / 105, used_time = 436.10s, loss = 4.349918
***** Eval results *****
  exact = 6.193353474320242
  f1 = 26.563111344823955
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 448.55s, loss = 4.310709
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.001944556506473
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=3): 27.00
Epoch: 3, Step: 60 / 105, used_time = 461.69s, loss = 4.273719
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.211136434501373
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=3): 27.21
Epoch: 3, Step: 70 / 105, used_time = 475.35s, loss = 4.239239
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.01533930860013
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 487.84s, loss = 4.206012
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.811940036383163
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 500.08s, loss = 4.182106
***** Eval results *****
  exact = 6.042296072507553
  f1 = 26.95840056605885
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 512.24s, loss = 4.154873
***** Eval results *****
  exact = 6.3444108761329305
  f1 = 27.0260018489398
  total = 662
Start epoch #4 (lr = 1e-06)...
Epoch: 4, Step: 10 / 105, used_time = 527.68s, loss = 4.105049
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.941602941785355
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 539.81s, loss = 4.075393
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.88620090771098
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 551.99s, loss = 4.047845
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.208716663469136
  total = 662
Epoch: 4, Step: 40 / 105, used_time = 564.22s, loss = 4.020889
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.983366414497244
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 576.16s, loss = 3.997058
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.829153380581257
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 588.32s, loss = 3.975532
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.036532955988974
  total = 662
Epoch: 4, Step: 70 / 105, used_time = 600.48s, loss = 3.950980
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.985850549913028
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 612.69s, loss = 3.933239
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.909943332596963
  total = 662
Epoch: 4, Step: 90 / 105, used_time = 625.21s, loss = 3.911344
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.501190657426744
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=4): 27.50
Epoch: 4, Step: 100 / 105, used_time = 638.71s, loss = 3.890807
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.31783147394553
  total = 662
Start epoch #5 (lr = 1e-06)...
Epoch: 5, Step: 10 / 105, used_time = 654.33s, loss = 3.863006
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.51922206045607
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=5): 27.52
Epoch: 5, Step: 20 / 105, used_time = 667.94s, loss = 3.843827
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.635213291005147
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=5): 27.64
Epoch: 5, Step: 30 / 105, used_time = 681.69s, loss = 3.823653
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.08731249301402
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 694.12s, loss = 3.807451
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.7547303398776
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 706.43s, loss = 3.793734
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.898942505163784
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 718.30s, loss = 3.776651
***** Eval results *****
  exact = 6.948640483383686
  f1 = 26.882051170453966
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 730.61s, loss = 3.757612
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.20288775677268
  total = 662
Epoch: 5, Step: 80 / 105, used_time = 742.78s, loss = 3.742181
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.699319345534914
  total = 662
Epoch: 5, Step: 90 / 105, used_time = 754.89s, loss = 3.726398
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.71236437313277
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 767.00s, loss = 3.713810
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.953932281300506
  total = 662
Start epoch #6 (lr = 1e-06)...
Epoch: 6, Step: 10 / 105, used_time = 782.44s, loss = 3.694544
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.889630065521967
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 794.56s, loss = 3.681904
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.68508141280216
  total = 662
Epoch: 6, Step: 30 / 105, used_time = 806.75s, loss = 3.667211
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.082118433497616
  total = 662
Epoch: 6, Step: 40 / 105, used_time = 818.96s, loss = 3.651450
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.063178759340033
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 831.60s, loss = 3.638072
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.09098997968822
  total = 662
Epoch: 6, Step: 60 / 105, used_time = 844.14s, loss = 3.629336
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.603451452117792
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 856.49s, loss = 3.616827
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.83725824905737
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 868.73s, loss = 3.604881
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.742226254539062
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 881.10s, loss = 3.594040
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.73723039632033
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 893.27s, loss = 3.584476
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.98216777162317
  total = 662
Start epoch #7 (lr = 1e-06)...
Epoch: 7, Step: 10 / 105, used_time = 908.63s, loss = 3.567841
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.382206644778112
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 920.95s, loss = 3.555969
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.338978254345502
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 933.17s, loss = 3.547182
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.651116152495646
  total = 662
Epoch: 7, Step: 40 / 105, used_time = 945.31s, loss = 3.537043
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.61521314297385
  total = 662
Epoch: 7, Step: 50 / 105, used_time = 957.52s, loss = 3.527108
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.60511074579663
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 969.88s, loss = 3.517497
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.489471386514207
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 982.05s, loss = 3.509279
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.31527810148242
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 993.87s, loss = 3.500089
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.6107269671894
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 1006.10s, loss = 3.490768
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.81386856917753
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 1018.36s, loss = 3.481610
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.913344578976673
  total = 662
Start epoch #8 (lr = 1e-06)...
Epoch: 8, Step: 10 / 105, used_time = 1033.71s, loss = 3.471842
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.670388264011002
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1045.60s, loss = 3.462021
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.8475232906198
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1057.80s, loss = 3.451155
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.68353899829697
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1070.02s, loss = 3.443785
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.722463150497127
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1082.23s, loss = 3.434201
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.94081564810934
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1094.45s, loss = 3.429706
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.977937613893385
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1106.63s, loss = 3.422011
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.764504585337793
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1119.10s, loss = 3.417069
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.758284574674914
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1131.34s, loss = 3.409040
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.751187488447414
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1143.63s, loss = 3.404543
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.577017065714475
  total = 662
Start epoch #9 (lr = 1e-06)...
Epoch: 9, Step: 10 / 105, used_time = 1158.94s, loss = 3.392504
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.151621243955322
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1171.23s, loss = 3.385384
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.171455334331664
  total = 662
Epoch: 9, Step: 30 / 105, used_time = 1183.37s, loss = 3.378950
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.772077108528173
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1195.59s, loss = 3.371616
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.870397446372355
  total = 662
Epoch: 9, Step: 50 / 105, used_time = 1208.01s, loss = 3.368116
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.11950184512479
  total = 662
Epoch: 9, Step: 60 / 105, used_time = 1220.38s, loss = 3.362480
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.91873110993927
  total = 662
Epoch: 9, Step: 70 / 105, used_time = 1232.70s, loss = 3.355203
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.864719910398552
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1244.66s, loss = 3.348502
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.797321195512136
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1257.11s, loss = 3.343358
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.805151108192952
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1269.46s, loss = 3.338921
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.524210083035385
  total = 662
Start epoch #10 (lr = 1e-06)...
Epoch: 10, Step: 10 / 105, used_time = 1284.88s, loss = 3.330977
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.62263651939225
  total = 662
Epoch: 10, Step: 20 / 105, used_time = 1297.16s, loss = 3.325227
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.767883310987
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1309.38s, loss = 3.320357
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.82448326939965
  total = 662
Epoch: 10, Step: 40 / 105, used_time = 1321.70s, loss = 3.314640
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.050249952506228
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1333.90s, loss = 3.306879
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.16982622683677
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1346.17s, loss = 3.302236
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.26075539246626
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1358.66s, loss = 3.296547
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.330486181471624
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1370.93s, loss = 3.292169
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.38133749875191
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1383.23s, loss = 3.287013
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.462126623915438
  total = 662
Epoch: 10, Step: 100 / 105, used_time = 1395.55s, loss = 3.282225
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.070398655331644
  total = 662
Start epoch #11 (lr = 1e-06)...
Epoch: 11, Step: 10 / 105, used_time = 1410.68s, loss = 3.274735
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.907823793257414
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1422.96s, loss = 3.270665
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.248435989358338
  total = 662
Epoch: 11, Step: 30 / 105, used_time = 1435.24s, loss = 3.264349
***** Eval results *****
  exact = 6.495468277945619
  f1 = 27.198526524424825
  total = 662
Epoch: 11, Step: 40 / 105, used_time = 1447.61s, loss = 3.259845
***** Eval results *****
  exact = 6.495468277945619
  f1 = 27.1080554380473
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1459.97s, loss = 3.255018
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.86204961552464
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1471.81s, loss = 3.251344
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.06696273508453
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1484.22s, loss = 3.247882
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.2028665304933
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1496.47s, loss = 3.244257
***** Eval results *****
  exact = 6.495468277945619
  f1 = 27.01393335400014
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1508.81s, loss = 3.240484
***** Eval results *****
  exact = 6.495468277945619
  f1 = 27.151029389887718
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1521.00s, loss = 3.236824
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.916765656740505
  total = 662
Start epoch #12 (lr = 1e-06)...
Epoch: 12, Step: 10 / 105, used_time = 1536.34s, loss = 3.232101
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.756778793971574
  total = 662
Epoch: 12, Step: 20 / 105, used_time = 1548.52s, loss = 3.228574
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.87729108012931
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1560.84s, loss = 3.226723
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.659199727596878
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1573.04s, loss = 3.220761
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.614876813964656
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1585.23s, loss = 3.216563
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.77058536954374
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1597.53s, loss = 3.213432
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.97394050782523
  total = 662
Epoch: 12, Step: 70 / 105, used_time = 1609.58s, loss = 3.208960
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.1664195021218
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1621.80s, loss = 3.205095
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.064654509552632
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1634.10s, loss = 3.200735
***** Eval results *****
  exact = 6.495468277945619
  f1 = 27.03028778291141
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1646.54s, loss = 3.196473
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.99059857346614
  total = 662
Start epoch #13 (lr = 1e-06)...
Epoch: 13, Step: 10 / 105, used_time = 1661.92s, loss = 3.191255
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.252407714871357
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1674.16s, loss = 3.187441
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.14826965756109
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1686.63s, loss = 3.184794
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.267983815433666
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1699.06s, loss = 3.182088
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.124009695654777
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1711.31s, loss = 3.178921
***** Eval results *****
  exact = 6.646525679758308
  f1 = 27.22433827370214
  total = 662
Epoch: 13, Step: 60 / 105, used_time = 1723.49s, loss = 3.175358
***** Eval results *****
  exact = 6.495468277945619
  f1 = 27.012969879867587
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1735.19s, loss = 3.171187
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.87323867587463
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1747.30s, loss = 3.167842
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.330017961311768
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1759.60s, loss = 3.164599
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.187595506305883
  total = 662
Epoch: 13, Step: 100 / 105, used_time = 1771.96s, loss = 3.162728
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.580513410861897
  total = 662
Start epoch #14 (lr = 1e-06)...
Epoch: 14, Step: 10 / 105, used_time = 1787.61s, loss = 3.158764
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.576821881003326
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1800.21s, loss = 3.155456
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.85758011477334
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=14): 27.86
Epoch: 14, Step: 30 / 105, used_time = 1813.73s, loss = 3.151774
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.975617384692026
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=14): 27.98
Epoch: 14, Step: 40 / 105, used_time = 1827.42s, loss = 3.149225
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 28.006870640239477
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=14): 28.01
Epoch: 14, Step: 50 / 105, used_time = 1840.84s, loss = 3.146506
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.711949046224227
  total = 662
Epoch: 14, Step: 60 / 105, used_time = 1853.54s, loss = 3.143727
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.691113542525926
  total = 662
Epoch: 14, Step: 70 / 105, used_time = 1866.02s, loss = 3.140934
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.837165154520896
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1878.49s, loss = 3.137353
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.915169174236443
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1890.80s, loss = 3.134549
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.833804372800135
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1903.24s, loss = 3.132116
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.960692590322793
  total = 662
Start epoch #15 (lr = 1e-06)...
Epoch: 15, Step: 10 / 105, used_time = 1918.67s, loss = 3.127804
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.88287514090413
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1930.88s, loss = 3.123451
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.962626507349924
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1943.13s, loss = 3.121192
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.95489062269978
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1955.63s, loss = 3.118232
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.047397381201936
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=15): 28.05
Epoch: 15, Step: 50 / 105, used_time = 1968.83s, loss = 3.115819
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.842822361084686
  total = 662
Epoch: 15, Step: 60 / 105, used_time = 1981.27s, loss = 3.113159
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.904863793972044
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1993.56s, loss = 3.111329
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.140084623252157
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=15): 28.14
Epoch: 15, Step: 80 / 105, used_time = 2007.01s, loss = 3.108222
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.119249119553853
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 2019.25s, loss = 3.104764
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.23131738116894
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=15): 28.23
Epoch: 15, Step: 100 / 105, used_time = 2032.64s, loss = 3.102872
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.250445270387456
  total = 662
!!! Best dev f1 (lr=1e-06, epoch=15): 28.25
Start epoch #16 (lr = 1e-06)...
Epoch: 16, Step: 10 / 105, used_time = 2049.31s, loss = 3.101034
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.034577654598042
  total = 662
Epoch: 16, Step: 20 / 105, used_time = 2061.92s, loss = 3.098195
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.034577654598042
  total = 662
Epoch: 16, Step: 30 / 105, used_time = 2074.52s, loss = 3.096285
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.034577654598042
  total = 662
Epoch: 16, Step: 40 / 105, used_time = 2087.14s, loss = 3.094344
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.972367441563478
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2099.55s, loss = 3.092282
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.95118635542771
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2111.77s, loss = 3.089070
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.987637163256423
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2124.01s, loss = 3.086536
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.08316907842065
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2135.85s, loss = 3.084990
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.13873338564199
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2148.08s, loss = 3.082708
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.212099031367924
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2160.23s, loss = 3.081089
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.219595676619175
  total = 662
Start epoch #17 (lr = 1e-06)...
Epoch: 17, Step: 10 / 105, used_time = 2175.41s, loss = 3.077411
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.212099031367924
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2187.55s, loss = 3.075335
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.221697996700502
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2199.78s, loss = 3.072853
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.212099031367924
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2211.86s, loss = 3.070579
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.22494180623042
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2224.00s, loss = 3.069216
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.143227014903882
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2236.15s, loss = 3.067344
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.131733516939875
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2248.39s, loss = 3.064634
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.131733516939875
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2260.40s, loss = 3.063106
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.245777309928712
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2272.70s, loss = 3.060467
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.243236331988513
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2284.93s, loss = 3.058496
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.22494180623042
  total = 662
Start epoch #18 (lr = 1e-06)...
Epoch: 18, Step: 10 / 105, used_time = 2300.39s, loss = 3.056749
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2312.54s, loss = 3.054757
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2324.85s, loss = 3.052307
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.150522627832185
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2336.70s, loss = 3.050115
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2349.06s, loss = 3.047592
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.14597404788466
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2361.41s, loss = 3.045344
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.218923808290704
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2373.61s, loss = 3.042879
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2385.82s, loss = 3.040680
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2398.13s, loss = 3.039688
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2410.34s, loss = 3.039078
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Start epoch #19 (lr = 1e-06)...
Epoch: 19, Step: 10 / 105, used_time = 2425.72s, loss = 3.036464
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.150522627832185
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2437.99s, loss = 3.034442
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2450.51s, loss = 3.032210
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.236435304194426
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2462.97s, loss = 3.030040
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.236435304194426
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2475.39s, loss = 3.028325
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.236435304194426
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2487.83s, loss = 3.027245
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.1538865784558
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2500.23s, loss = 3.025439
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.150522627832185
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2512.36s, loss = 3.023991
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.150522627832185
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2524.78s, loss = 3.022373
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.150522627832185
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2537.18s, loss = 3.021647
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.150522627832185
  total = 662
Start epoch #0 (lr = 2e-06)...
Epoch: 0, Step: 10 / 105, used_time = 6.20s, loss = 5.896882
***** Eval results *****
  exact = 0.0
  f1 = 18.063425346326085
  total = 662
Epoch: 0, Step: 20 / 105, used_time = 18.45s, loss = 5.872836
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 18.034993556012562
  total = 662
Epoch: 0, Step: 30 / 105, used_time = 30.70s, loss = 5.850887
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 17.646619803095458
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.88s, loss = 5.831712
***** Eval results *****
  exact = 0.3021148036253776
  f1 = 17.803364933733093
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 55.17s, loss = 5.801545
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 17.212243882695056
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 67.32s, loss = 5.761842
***** Eval results *****
  exact = 0.45317220543806647
  f1 = 19.15411244306046
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 79.54s, loss = 5.709067
***** Eval results *****
  exact = 0.6042296072507553
  f1 = 20.65988006846565
  total = 662
Epoch: 0, Step: 80 / 105, used_time = 91.78s, loss = 5.652610
***** Eval results *****
  exact = 0.45317220543806647
  f1 = 22.153556015969777
  total = 662
Epoch: 0, Step: 90 / 105, used_time = 103.80s, loss = 5.593487
***** Eval results *****
  exact = 0.6042296072507553
  f1 = 23.23882936715538
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 116.05s, loss = 5.512516
***** Eval results *****
  exact = 1.0574018126888218
  f1 = 23.44474929586142
  total = 662
Start epoch #1 (lr = 2e-06)...
Epoch: 1, Step: 10 / 105, used_time = 131.44s, loss = 5.374940
***** Eval results *****
  exact = 2.416918429003021
  f1 = 24.337581039183284
  total = 662
Epoch: 1, Step: 20 / 105, used_time = 143.67s, loss = 5.277454
***** Eval results *****
  exact = 2.8700906344410875
  f1 = 25.15489808282219
  total = 662
Epoch: 1, Step: 30 / 105, used_time = 155.99s, loss = 5.182591
***** Eval results *****
  exact = 3.474320241691843
  f1 = 25.941597363819895
  total = 662
Epoch: 1, Step: 40 / 105, used_time = 168.21s, loss = 5.072112
***** Eval results *****
  exact = 3.7764350453172204
  f1 = 25.291429699247608
  total = 662
Epoch: 1, Step: 50 / 105, used_time = 180.48s, loss = 4.972117
***** Eval results *****
  exact = 3.6253776435045317
  f1 = 24.661425949418724
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 192.83s, loss = 4.865991
***** Eval results *****
  exact = 4.229607250755287
  f1 = 24.82945857189933
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 205.32s, loss = 4.768586
***** Eval results *****
  exact = 5.589123867069486
  f1 = 25.940271176591235
  total = 662
Epoch: 1, Step: 80 / 105, used_time = 217.40s, loss = 4.686667
***** Eval results *****
  exact = 4.984894259818731
  f1 = 25.6003237913795
  total = 662
Epoch: 1, Step: 90 / 105, used_time = 229.82s, loss = 4.601346
***** Eval results *****
  exact = 5.589123867069486
  f1 = 25.551973786804115
  total = 662
Epoch: 1, Step: 100 / 105, used_time = 242.18s, loss = 4.520666
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.649532148976203
  total = 662
Start epoch #2 (lr = 2e-06)...
Epoch: 2, Step: 10 / 105, used_time = 257.89s, loss = 4.406429
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.86626578525176
  total = 662
Epoch: 2, Step: 20 / 105, used_time = 270.30s, loss = 4.343662
***** Eval results *****
  exact = 6.042296072507553
  f1 = 26.30985845779892
  total = 662
Epoch: 2, Step: 30 / 105, used_time = 282.63s, loss = 4.294888
***** Eval results *****
  exact = 6.495468277945619
  f1 = 26.55331635626364
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 295.09s, loss = 4.234919
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.407782892690587
  total = 662
Epoch: 2, Step: 50 / 105, used_time = 307.45s, loss = 4.189857
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.428949219386098
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 319.44s, loss = 4.147007
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.879102740036586
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 331.93s, loss = 4.096559
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.716213470538285
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 344.30s, loss = 4.049142
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.766581054224233
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 356.69s, loss = 4.004801
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.96717927542645
  total = 662
Epoch: 2, Step: 100 / 105, used_time = 368.98s, loss = 3.968393
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 27.90432626558552
  total = 662
Start epoch #3 (lr = 2e-06)...
Epoch: 3, Step: 10 / 105, used_time = 384.45s, loss = 3.920584
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.989856681411165
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 397.00s, loss = 3.891815
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.009992815836515
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 409.46s, loss = 3.860960
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.52850504061455
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=3): 28.53
Epoch: 3, Step: 40 / 105, used_time = 422.99s, loss = 3.835324
***** Eval results *****
  exact = 8.308157099697885
  f1 = 28.282047585104664
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 435.15s, loss = 3.803727
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.62542618986283
  total = 662
Epoch: 3, Step: 60 / 105, used_time = 447.71s, loss = 3.775244
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.29232078910783
  total = 662
Epoch: 3, Step: 70 / 105, used_time = 460.07s, loss = 3.746565
***** Eval results *****
  exact = 8.157099697885196
  f1 = 27.831587216584133
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 472.33s, loss = 3.727447
***** Eval results *****
  exact = 8.610271903323262
  f1 = 28.37819140852473
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 484.62s, loss = 3.701583
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.04268415249171
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 497.05s, loss = 3.675264
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 27.742249199710432
  total = 662
Start epoch #4 (lr = 2e-06)...
Epoch: 4, Step: 10 / 105, used_time = 512.60s, loss = 3.639726
***** Eval results *****
  exact = 8.459214501510575
  f1 = 28.389826977070157
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 524.62s, loss = 3.621346
***** Eval results *****
  exact = 8.308157099697885
  f1 = 28.14021074935022
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 536.89s, loss = 3.604368
***** Eval results *****
  exact = 8.308157099697885
  f1 = 28.341326826863053
  total = 662
Epoch: 4, Step: 40 / 105, used_time = 549.32s, loss = 3.588968
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.347609862027642
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 561.69s, loss = 3.569220
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.23178972568509
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 574.08s, loss = 3.553852
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.314892729187896
  total = 662
Epoch: 4, Step: 70 / 105, used_time = 586.50s, loss = 3.534361
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.083322022860482
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 599.04s, loss = 3.516955
***** Eval results *****
  exact = 8.308157099697885
  f1 = 28.62688945791499
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=4): 28.63
Epoch: 4, Step: 90 / 105, used_time = 612.57s, loss = 3.502712
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.37672811640728
  total = 662
Epoch: 4, Step: 100 / 105, used_time = 625.04s, loss = 3.486085
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.16447734673719
  total = 662
Start epoch #5 (lr = 2e-06)...
Epoch: 5, Step: 10 / 105, used_time = 640.69s, loss = 3.465717
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.88817058073487
  total = 662
Epoch: 5, Step: 20 / 105, used_time = 653.15s, loss = 3.451122
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.25530801302515
  total = 662
Epoch: 5, Step: 30 / 105, used_time = 665.11s, loss = 3.437181
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.041135782889206
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 677.42s, loss = 3.420267
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.02877373098704
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 689.82s, loss = 3.411493
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.944566998943998
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 702.33s, loss = 3.401310
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.122623252411824
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 714.64s, loss = 3.391039
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.903084399413725
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=5): 28.90
Epoch: 5, Step: 80 / 105, used_time = 728.13s, loss = 3.375320
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.529951449012405
  total = 662
Epoch: 5, Step: 90 / 105, used_time = 740.59s, loss = 3.363847
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.57887862070951
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 753.04s, loss = 3.352730
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.13591308055982
  total = 662
Start epoch #6 (lr = 2e-06)...
Epoch: 6, Step: 10 / 105, used_time = 768.13s, loss = 3.336975
***** Eval results *****
  exact = 8.459214501510575
  f1 = 28.476348856015907
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 780.45s, loss = 3.325164
***** Eval results *****
  exact = 8.459214501510575
  f1 = 28.944779049142195
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=6): 28.94
Epoch: 6, Step: 30 / 105, used_time = 793.98s, loss = 3.316404
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.160930624084898
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=6): 29.16
Epoch: 6, Step: 40 / 105, used_time = 807.60s, loss = 3.308799
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.266824303202476
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 820.11s, loss = 3.300399
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.17029822415589
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=6): 29.17
Epoch: 6, Step: 60 / 105, used_time = 833.78s, loss = 3.289968
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.922159486355575
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 846.39s, loss = 3.279173
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.028472770962775
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 858.79s, loss = 3.271348
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.832991117319633
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 871.11s, loss = 3.262817
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 28.162096137214462
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 883.35s, loss = 3.253893
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.30124976762431
  total = 662
Start epoch #7 (lr = 2e-06)...
Epoch: 7, Step: 10 / 105, used_time = 898.74s, loss = 3.241874
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.543036324862015
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 910.76s, loss = 3.234859
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.845996934719235
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 923.06s, loss = 3.226283
***** Eval results *****
  exact = 8.459214501510575
  f1 = 29.22888476417832
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=7): 29.23
Epoch: 7, Step: 40 / 105, used_time = 936.53s, loss = 3.217788
***** Eval results *****
  exact = 8.459214501510575
  f1 = 29.118937252663248
  total = 662
Epoch: 7, Step: 50 / 105, used_time = 949.21s, loss = 3.208901
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.36347802663147
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 961.71s, loss = 3.201719
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.160367104069977
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 974.17s, loss = 3.193844
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.681448971453417
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 986.53s, loss = 3.187852
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.58581237133609
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 999.07s, loss = 3.180984
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.424384275419335
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 1011.46s, loss = 3.173383
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.614536146328188
  total = 662
Start epoch #8 (lr = 2e-06)...
Epoch: 8, Step: 10 / 105, used_time = 1027.07s, loss = 3.164907
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.516317886223234
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1039.45s, loss = 3.157744
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.998915364065173
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1051.96s, loss = 3.151806
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.45920455804623
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1064.30s, loss = 3.147479
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.540575951151766
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1076.55s, loss = 3.140893
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.65586669009345
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1088.97s, loss = 3.134747
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.784729151644417
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1101.10s, loss = 3.128097
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.95266171112552
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1113.45s, loss = 3.121939
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.543727357983173
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1125.75s, loss = 3.115723
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.659400431559412
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1138.01s, loss = 3.110011
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.46422693838508
  total = 662
Start epoch #9 (lr = 2e-06)...
Epoch: 9, Step: 10 / 105, used_time = 1153.63s, loss = 3.102530
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.897248089959792
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1165.89s, loss = 3.097479
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.354102403779414
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=9): 29.35
Epoch: 9, Step: 30 / 105, used_time = 1179.42s, loss = 3.093374
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.072805289624757
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1191.95s, loss = 3.087163
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.568509181013614
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=9): 29.57
Epoch: 9, Step: 50 / 105, used_time = 1205.33s, loss = 3.082820
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.579643697599227
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=9): 29.58
Epoch: 9, Step: 60 / 105, used_time = 1219.04s, loss = 3.077025
***** Eval results *****
  exact = 8.459214501510575
  f1 = 29.483034538741144
  total = 662
Epoch: 9, Step: 70 / 105, used_time = 1231.57s, loss = 3.072733
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.053348878597077
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1244.07s, loss = 3.066587
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.03134031497772
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1256.34s, loss = 3.060854
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.95471735359415
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1268.61s, loss = 3.056020
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.176045414503044
  total = 662
Start epoch #10 (lr = 2e-06)...
Epoch: 10, Step: 10 / 105, used_time = 1284.02s, loss = 3.050457
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.92870661174724
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=10): 29.93
Epoch: 10, Step: 20 / 105, used_time = 1297.65s, loss = 3.045632
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.744696364931826
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1310.23s, loss = 3.041877
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.555592862154118
  total = 662
Epoch: 10, Step: 40 / 105, used_time = 1322.72s, loss = 3.037719
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.38890702073954
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1335.17s, loss = 3.031765
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.578057314473845
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1347.71s, loss = 3.027753
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.741490646050284
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1359.77s, loss = 3.025690
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.518300747948178
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1372.15s, loss = 3.019488
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.90886965838527
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1384.51s, loss = 3.015407
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.30744920721669
  total = 662
Epoch: 10, Step: 100 / 105, used_time = 1397.00s, loss = 3.009935
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.679973968116784
  total = 662
Start epoch #11 (lr = 2e-06)...
Epoch: 11, Step: 10 / 105, used_time = 1412.21s, loss = 3.004868
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.595699155319448
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1424.65s, loss = 2.998661
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.138089419827985
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=11): 30.14
Epoch: 11, Step: 30 / 105, used_time = 1438.13s, loss = 2.994541
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.226469314439857
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=11): 30.23
Epoch: 11, Step: 40 / 105, used_time = 1451.88s, loss = 2.989445
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.71960680362465
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1464.42s, loss = 2.985395
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.683177490781453
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1476.86s, loss = 2.982812
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.892696666124937
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1489.30s, loss = 2.979593
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.903791965532626
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1501.71s, loss = 2.976276
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.999644622083498
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1513.97s, loss = 2.972715
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.04253389719871
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1526.29s, loss = 2.969073
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.887316334895136
  total = 662
Start epoch #12 (lr = 2e-06)...
Epoch: 12, Step: 10 / 105, used_time = 1541.80s, loss = 2.963478
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.8814188020037
  total = 662
Epoch: 12, Step: 20 / 105, used_time = 1554.24s, loss = 2.960956
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.815828375078798
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1566.55s, loss = 2.957335
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.851593881181042
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1578.83s, loss = 2.953946
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.011057732241962
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1591.07s, loss = 2.951403
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.007776773522934
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1603.42s, loss = 2.947594
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.928790114640655
  total = 662
Epoch: 12, Step: 70 / 105, used_time = 1615.76s, loss = 2.943420
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.10285014490075
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1628.11s, loss = 2.940466
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.029861781400783
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1640.52s, loss = 2.937253
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.984698893366193
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1652.56s, loss = 2.933913
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.941366560765026
  total = 662
Start epoch #13 (lr = 2e-06)...
Epoch: 13, Step: 10 / 105, used_time = 1668.11s, loss = 2.928117
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.670007700386854
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1680.50s, loss = 2.924705
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.778391297418928
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1692.92s, loss = 2.922006
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.88529702258469
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1705.41s, loss = 2.919858
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.93396292610666
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1717.82s, loss = 2.916463
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.842137079960285
  total = 662
Epoch: 13, Step: 60 / 105, used_time = 1730.22s, loss = 2.914164
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.82321558434595
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1742.40s, loss = 2.911896
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.83919632542827
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1754.67s, loss = 2.909602
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.08300455964751
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1767.00s, loss = 2.905488
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.972742526381523
  total = 662
Epoch: 13, Step: 100 / 105, used_time = 1779.32s, loss = 2.901930
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.155373467819913
  total = 662
Start epoch #14 (lr = 2e-06)...
Epoch: 14, Step: 10 / 105, used_time = 1794.74s, loss = 2.898913
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.2219145922537
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1807.14s, loss = 2.896765
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.00323481777938
  total = 662
Epoch: 14, Step: 30 / 105, used_time = 1819.56s, loss = 2.894188
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.144366397989426
  total = 662
Epoch: 14, Step: 40 / 105, used_time = 1831.92s, loss = 2.890828
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.083647919708675
  total = 662
Epoch: 14, Step: 50 / 105, used_time = 1844.23s, loss = 2.887699
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.239363211360228
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=14): 30.24
Epoch: 14, Step: 60 / 105, used_time = 1857.78s, loss = 2.884497
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.00807184329453
  total = 662
Epoch: 14, Step: 70 / 105, used_time = 1870.25s, loss = 2.881069
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.031124870393047
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1882.69s, loss = 2.878682
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.9964755655869
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1895.19s, loss = 2.877091
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.03619203991038
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1907.50s, loss = 2.874538
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.759610058947892
  total = 662
Start epoch #15 (lr = 2e-06)...
Epoch: 15, Step: 10 / 105, used_time = 1923.02s, loss = 2.870583
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.951809009098774
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1935.34s, loss = 2.867406
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.030000068614463
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1947.69s, loss = 2.864427
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.87415114798751
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1959.92s, loss = 2.861628
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.90967527760226
  total = 662
Epoch: 15, Step: 50 / 105, used_time = 1972.26s, loss = 2.858515
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.624019272608717
  total = 662
Epoch: 15, Step: 60 / 105, used_time = 1984.58s, loss = 2.856290
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.04933542793896
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1997.08s, loss = 2.853000
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.260376233674563
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=15): 30.26
Epoch: 15, Step: 80 / 105, used_time = 2010.21s, loss = 2.851665
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.156713789531615
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 2022.63s, loss = 2.849572
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.509460303767597
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=15): 30.51
Epoch: 15, Step: 100 / 105, used_time = 2036.31s, loss = 2.847964
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.627276332179434
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=15): 30.63
Start epoch #16 (lr = 2e-06)...
Epoch: 16, Step: 10 / 105, used_time = 2053.44s, loss = 2.845100
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.67446267308886
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=16): 30.67
Epoch: 16, Step: 20 / 105, used_time = 2066.94s, loss = 2.843614
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.780150863528206
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=16): 30.78
Epoch: 16, Step: 30 / 105, used_time = 2080.63s, loss = 2.840960
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.784804023639417
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=16): 30.78
Epoch: 16, Step: 40 / 105, used_time = 2094.43s, loss = 2.839021
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.72409203306592
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2107.63s, loss = 2.835938
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.580129751641397
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2120.01s, loss = 2.833490
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.16492114073006
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2132.35s, loss = 2.831990
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.162403517366517
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2144.63s, loss = 2.829304
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.3522476607066
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2157.00s, loss = 2.827455
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.743204142047365
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2169.26s, loss = 2.825430
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.632151924698764
  total = 662
Start epoch #17 (lr = 2e-06)...
Epoch: 17, Step: 10 / 105, used_time = 2184.77s, loss = 2.822475
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.60152751096911
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2197.19s, loss = 2.821002
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.492027967457478
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2209.49s, loss = 2.818855
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.43996483476707
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2221.76s, loss = 2.816738
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.42940251541162
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2234.05s, loss = 2.814915
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.711376332128644
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2246.51s, loss = 2.813831
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.656371090555325
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2258.73s, loss = 2.811547
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.547118418626017
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2271.07s, loss = 2.808886
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.68793204660638
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2283.48s, loss = 2.807059
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.6982675530462
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2295.44s, loss = 2.805312
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.9240093638575
  total = 662
!!! Best dev f1 (lr=2e-06, epoch=17): 30.92
Start epoch #18 (lr = 2e-06)...
Epoch: 18, Step: 10 / 105, used_time = 2312.16s, loss = 2.802393
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.674242775982783
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2324.65s, loss = 2.801641
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.759612754431053
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2337.06s, loss = 2.798374
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.759612754431053
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2349.36s, loss = 2.796978
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.649681343289497
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2361.67s, loss = 2.795313
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.83343795028369
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2373.95s, loss = 2.792936
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.848566452906045
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2386.23s, loss = 2.790250
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.723692334074222
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2398.32s, loss = 2.788623
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.78091104688206
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2410.69s, loss = 2.787650
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.907126135814895
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2423.03s, loss = 2.786279
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.8064212012731
  total = 662
Start epoch #19 (lr = 2e-06)...
Epoch: 19, Step: 10 / 105, used_time = 2438.67s, loss = 2.783734
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.65536379946041
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2451.18s, loss = 2.781936
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.756068734002206
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2463.62s, loss = 2.779833
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.73089250036676
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2475.61s, loss = 2.778296
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.756068734002206
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2487.84s, loss = 2.775649
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.756068734002206
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2500.27s, loss = 2.774079
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.756068734002206
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2512.63s, loss = 2.772192
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.756068734002206
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2524.96s, loss = 2.770000
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.749833719293242
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2537.27s, loss = 2.768774
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.749833719293242
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2549.55s, loss = 2.767975
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.749833719293242
  total = 662
Start epoch #0 (lr = 3e-06)...
Epoch: 0, Step: 10 / 105, used_time = 6.15s, loss = 5.898714
***** Eval results *****
  exact = 0.0
  f1 = 14.947535682582815
  total = 662
Epoch: 0, Step: 20 / 105, used_time = 18.35s, loss = 5.882937
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 15.708930842079011
  total = 662
Epoch: 0, Step: 30 / 105, used_time = 30.54s, loss = 5.854453
***** Eval results *****
  exact = 0.3021148036253776
  f1 = 15.496968013794252
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.84s, loss = 5.801027
***** Eval results *****
  exact = 0.45317220543806647
  f1 = 16.6227626306949
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 55.00s, loss = 5.743504
***** Eval results *****
  exact = 0.9063444108761329
  f1 = 19.003575371560988
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 67.20s, loss = 5.668031
***** Eval results *****
  exact = 1.5105740181268883
  f1 = 21.028408653482956
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 79.43s, loss = 5.583778
***** Eval results *****
  exact = 1.661631419939577
  f1 = 22.44651808262084
  total = 662
Epoch: 0, Step: 80 / 105, used_time = 91.79s, loss = 5.485053
***** Eval results *****
  exact = 1.9637462235649548
  f1 = 22.154145769967464
  total = 662
Epoch: 0, Step: 90 / 105, used_time = 104.07s, loss = 5.373405
***** Eval results *****
  exact = 2.2658610271903323
  f1 = 22.70244484403548
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 115.98s, loss = 5.254080
***** Eval results *****
  exact = 2.416918429003021
  f1 = 23.257332959767876
  total = 662
Start epoch #1 (lr = 3e-06)...
Epoch: 1, Step: 10 / 105, used_time = 131.46s, loss = 5.076016
***** Eval results *****
  exact = 3.9274924471299095
  f1 = 24.67833698063264
  total = 662
Epoch: 1, Step: 20 / 105, used_time = 143.95s, loss = 4.939776
***** Eval results *****
  exact = 4.380664652567976
  f1 = 24.175447051354162
  total = 662
Epoch: 1, Step: 30 / 105, used_time = 156.26s, loss = 4.809202
***** Eval results *****
  exact = 5.438066465256798
  f1 = 24.88239717003103
  total = 662
Epoch: 1, Step: 40 / 105, used_time = 168.63s, loss = 4.692844
***** Eval results *****
  exact = 5.13595166163142
  f1 = 24.420294997832876
  total = 662
Epoch: 1, Step: 50 / 105, used_time = 181.03s, loss = 4.586493
***** Eval results *****
  exact = 5.438066465256798
  f1 = 25.184779244906068
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 193.50s, loss = 4.493094
***** Eval results *****
  exact = 6.3444108761329305
  f1 = 25.799034193404548
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 205.87s, loss = 4.399106
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.387548852843565
  total = 662
Epoch: 1, Step: 80 / 105, used_time = 217.88s, loss = 4.328565
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.54699875239001
  total = 662
Epoch: 1, Step: 90 / 105, used_time = 230.22s, loss = 4.247890
***** Eval results *****
  exact = 7.099697885196375
  f1 = 26.767821237814786
  total = 662
Epoch: 1, Step: 100 / 105, used_time = 242.63s, loss = 4.181641
***** Eval results *****
  exact = 7.099697885196375
  f1 = 26.98807265777512
  total = 662
Start epoch #2 (lr = 3e-06)...
Epoch: 2, Step: 10 / 105, used_time = 258.13s, loss = 4.098529
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.706552738584296
  total = 662
Epoch: 2, Step: 20 / 105, used_time = 270.46s, loss = 4.043290
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.47660689892061
  total = 662
Epoch: 2, Step: 30 / 105, used_time = 282.87s, loss = 3.996980
***** Eval results *****
  exact = 6.948640483383686
  f1 = 27.367754855345762
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 295.35s, loss = 3.948727
***** Eval results *****
  exact = 7.099697885196375
  f1 = 26.626369072155768
  total = 662
Epoch: 2, Step: 50 / 105, used_time = 307.70s, loss = 3.905504
***** Eval results *****
  exact = 7.099697885196375
  f1 = 26.856888003949454
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 319.98s, loss = 3.866461
***** Eval results *****
  exact = 7.099697885196375
  f1 = 26.864868779067038
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 332.47s, loss = 3.832693
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 26.70910812707299
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 344.87s, loss = 3.790051
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.75709263484712
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 356.91s, loss = 3.756352
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.79377795643896
  total = 662
Epoch: 2, Step: 100 / 105, used_time = 369.28s, loss = 3.722127
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.281196839518852
  total = 662
Start epoch #3 (lr = 3e-06)...
Epoch: 3, Step: 10 / 105, used_time = 385.07s, loss = 3.671671
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 27.31184261820163
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 397.48s, loss = 3.643208
***** Eval results *****
  exact = 7.099697885196375
  f1 = 26.94647628549537
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 409.85s, loss = 3.621309
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.59662910336459
  total = 662
Epoch: 3, Step: 40 / 105, used_time = 422.11s, loss = 3.589376
***** Eval results *****
  exact = 7.552870090634441
  f1 = 26.929665766686597
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 434.41s, loss = 3.566315
***** Eval results *****
  exact = 7.401812688821752
  f1 = 26.970756420443106
  total = 662
Epoch: 3, Step: 60 / 105, used_time = 446.74s, loss = 3.545509
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.228490318621816
  total = 662
Epoch: 3, Step: 70 / 105, used_time = 459.03s, loss = 3.522834
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.51301448255388
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 471.31s, loss = 3.505116
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 27.97078698263389
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 483.36s, loss = 3.487244
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.344668301297425
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 495.60s, loss = 3.466797
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.334945473790615
  total = 662
Start epoch #4 (lr = 3e-06)...
Epoch: 4, Step: 10 / 105, used_time = 510.97s, loss = 3.437664
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.133119125098453
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 523.27s, loss = 3.422475
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.548836059433246
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 535.79s, loss = 3.404666
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.343732458375527
  total = 662
Epoch: 4, Step: 40 / 105, used_time = 548.10s, loss = 3.381409
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.011669010750683
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 560.44s, loss = 3.365471
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.83674496986517
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 572.78s, loss = 3.355801
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.23683771062739
  total = 662
Epoch: 4, Step: 70 / 105, used_time = 585.27s, loss = 3.339999
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.84405182427807
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 597.28s, loss = 3.327743
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.03287700855976
  total = 662
Epoch: 4, Step: 90 / 105, used_time = 609.69s, loss = 3.312721
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.733836522696798
  total = 662
Epoch: 4, Step: 100 / 105, used_time = 622.13s, loss = 3.301371
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.56324071443686
  total = 662
Start epoch #5 (lr = 3e-06)...
Epoch: 5, Step: 10 / 105, used_time = 637.30s, loss = 3.279770
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.38225233958632
  total = 662
Epoch: 5, Step: 20 / 105, used_time = 649.70s, loss = 3.268917
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.08802641942354
  total = 662
Epoch: 5, Step: 30 / 105, used_time = 661.96s, loss = 3.255569
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.358753812037634
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 674.26s, loss = 3.242197
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.249937371928034
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 686.63s, loss = 3.229945
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.6621501028369
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 698.89s, loss = 3.217435
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.41074849998806
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 711.16s, loss = 3.206012
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.990747283454716
  total = 662
Epoch: 5, Step: 80 / 105, used_time = 723.39s, loss = 3.197227
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.52753289013721
  total = 662
Epoch: 5, Step: 90 / 105, used_time = 735.75s, loss = 3.187692
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.935012903267836
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 747.94s, loss = 3.179625
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.20977154491318
  total = 662
Start epoch #6 (lr = 3e-06)...
Epoch: 6, Step: 10 / 105, used_time = 763.35s, loss = 3.164860
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.56094492614893
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 775.56s, loss = 3.154348
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.389136587221216
  total = 662
Epoch: 6, Step: 30 / 105, used_time = 787.95s, loss = 3.143252
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.32750236463582
  total = 662
Epoch: 6, Step: 40 / 105, used_time = 800.18s, loss = 3.135997
***** Eval results *****
  exact = 7.552870090634441
  f1 = 29.011287006494573
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 812.41s, loss = 3.124187
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.396114561300404
  total = 662
Epoch: 6, Step: 60 / 105, used_time = 824.62s, loss = 3.112606
***** Eval results *****
  exact = 7.552870090634441
  f1 = 29.16913778875296
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 836.83s, loss = 3.104842
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.221752090800837
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 849.19s, loss = 3.096077
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.820461004330966
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 861.47s, loss = 3.089676
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.432888496901473
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 873.50s, loss = 3.083520
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.732376229373894
  total = 662
Start epoch #7 (lr = 3e-06)...
Epoch: 7, Step: 10 / 105, used_time = 889.16s, loss = 3.070550
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.94427476898993
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 901.52s, loss = 3.063630
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.674114257072624
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 913.88s, loss = 3.053976
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.649707930667496
  total = 662
Epoch: 7, Step: 40 / 105, used_time = 925.92s, loss = 3.046015
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.492702048593607
  total = 662
Epoch: 7, Step: 50 / 105, used_time = 938.40s, loss = 3.038144
***** Eval results *****
  exact = 7.552870090634441
  f1 = 29.083424885669928
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 950.80s, loss = 3.030713
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.582073887176993
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 963.13s, loss = 3.023979
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 28.87336061747425
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 975.37s, loss = 3.019777
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.919766388123815
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 987.73s, loss = 3.014361
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 28.58161785493801
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 999.97s, loss = 3.007947
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.63810030797246
  total = 662
Start epoch #8 (lr = 3e-06)...
Epoch: 8, Step: 10 / 105, used_time = 1015.09s, loss = 2.998960
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.369556437106215
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1027.33s, loss = 2.991650
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.711387902233277
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1039.65s, loss = 2.983461
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.618795331235162
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1051.91s, loss = 2.977174
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.817781426639684
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1064.16s, loss = 2.971851
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.973229143838083
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1076.35s, loss = 2.965479
***** Eval results *****
  exact = 7.401812688821752
  f1 = 29.228117689037443
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1088.69s, loss = 2.960289
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.91770504106029
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1101.00s, loss = 2.953492
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.678832002142233
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1113.29s, loss = 2.948555
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.405044643121354
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1125.57s, loss = 2.944007
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.804427859881937
  total = 662
Start epoch #9 (lr = 3e-06)...
Epoch: 9, Step: 10 / 105, used_time = 1140.99s, loss = 2.935289
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 29.97519792696858
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1153.35s, loss = 2.928022
***** Eval results *****
  exact = 8.006042296072508
  f1 = 30.756220754828238
  total = 662
Epoch: 9, Step: 30 / 105, used_time = 1165.62s, loss = 2.924314
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.752699296193715
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1177.83s, loss = 2.919620
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.751071548074815
  total = 662
Epoch: 9, Step: 50 / 105, used_time = 1190.15s, loss = 2.914707
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.466293124414484
  total = 662
Epoch: 9, Step: 60 / 105, used_time = 1202.51s, loss = 2.910921
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.048247987841044
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=9): 31.05
Epoch: 9, Step: 70 / 105, used_time = 1215.83s, loss = 2.904393
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.674838930481293
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1227.85s, loss = 2.898439
***** Eval results *****
  exact = 8.006042296072508
  f1 = 30.524034838562557
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1240.35s, loss = 2.893149
***** Eval results *****
  exact = 8.006042296072508
  f1 = 30.713746809218396
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1252.65s, loss = 2.888433
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 30.207546934908795
  total = 662
Start epoch #10 (lr = 3e-06)...
Epoch: 10, Step: 10 / 105, used_time = 1268.07s, loss = 2.880319
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.67528812794416
  total = 662
Epoch: 10, Step: 20 / 105, used_time = 1280.35s, loss = 2.877749
***** Eval results *****
  exact = 7.854984894259819
  f1 = 30.264701102479286
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1292.72s, loss = 2.873025
***** Eval results *****
  exact = 8.006042296072508
  f1 = 31.04904872409377
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=10): 31.05
Epoch: 10, Step: 40 / 105, used_time = 1306.16s, loss = 2.868407
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.997938052049165
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1318.61s, loss = 2.864292
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.621365485057396
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1331.08s, loss = 2.858727
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.007687710678503
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1343.55s, loss = 2.854937
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.928108562076623
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1355.90s, loss = 2.849953
***** Eval results *****
  exact = 8.006042296072508
  f1 = 30.622206409931046
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1368.27s, loss = 2.843424
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.415874593753113
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=10): 31.42
Epoch: 10, Step: 100 / 105, used_time = 1381.34s, loss = 2.838959
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.963849887438236
  total = 662
Start epoch #11 (lr = 3e-06)...
Epoch: 11, Step: 10 / 105, used_time = 1397.07s, loss = 2.832121
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.415699027401406
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1409.46s, loss = 2.829348
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.86046986955501
  total = 662
Epoch: 11, Step: 30 / 105, used_time = 1421.75s, loss = 2.825232
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.00425880621742
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=11): 32.00
Epoch: 11, Step: 40 / 105, used_time = 1435.20s, loss = 2.820400
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.63035906508599
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1447.71s, loss = 2.815576
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.605709072127123
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1459.99s, loss = 2.810263
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.414829862985428
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1472.17s, loss = 2.805155
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.036729241404064
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1484.38s, loss = 2.803264
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.817164613112215
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1496.44s, loss = 2.798727
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.43342680988442
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1508.52s, loss = 2.794776
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.629711768775955
  total = 662
Start epoch #12 (lr = 3e-06)...
Epoch: 12, Step: 10 / 105, used_time = 1523.79s, loss = 2.788798
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.09721924705418
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=12): 32.10
Epoch: 12, Step: 20 / 105, used_time = 1537.30s, loss = 2.784066
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.00735053995738
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1549.27s, loss = 2.779685
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.82948525604932
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1561.60s, loss = 2.776168
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.321806603206827
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1573.80s, loss = 2.771767
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.573378101041055
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1586.11s, loss = 2.768101
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.295055333007593
  total = 662
Epoch: 12, Step: 70 / 105, used_time = 1598.38s, loss = 2.765837
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.408185954254726
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1610.65s, loss = 2.761083
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.28825618881347
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1622.86s, loss = 2.757993
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.601811717268372
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1635.17s, loss = 2.754727
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.8747380689641
  total = 662
Start epoch #13 (lr = 3e-06)...
Epoch: 13, Step: 10 / 105, used_time = 1650.53s, loss = 2.750375
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.73948106973943
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1662.73s, loss = 2.746347
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.872642628167263
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1675.02s, loss = 2.744203
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.00073804055975
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1687.38s, loss = 2.740113
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.447422623762147
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1699.57s, loss = 2.737790
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.13532489554456
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=13): 32.14
Epoch: 13, Step: 60 / 105, used_time = 1712.90s, loss = 2.734117
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.70551550157267
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1725.56s, loss = 2.730422
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.70331680760538
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1738.07s, loss = 2.726732
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.07927009474702
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1750.12s, loss = 2.723145
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.23940879668802
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=13): 32.24
Epoch: 13, Step: 100 / 105, used_time = 1763.52s, loss = 2.719721
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.23899989334028
  total = 662
Start epoch #14 (lr = 3e-06)...
Epoch: 14, Step: 10 / 105, used_time = 1779.07s, loss = 2.714985
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.6261676733057
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1791.42s, loss = 2.713074
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.67412039710881
  total = 662
Epoch: 14, Step: 30 / 105, used_time = 1803.72s, loss = 2.710535
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.893433403853493
  total = 662
Epoch: 14, Step: 40 / 105, used_time = 1815.89s, loss = 2.706652
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.06147816250361
  total = 662
Epoch: 14, Step: 50 / 105, used_time = 1828.08s, loss = 2.703017
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.366695653966076
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=14): 32.37
Epoch: 14, Step: 60 / 105, used_time = 1841.72s, loss = 2.698820
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.93963726387435
  total = 662
!!! Best dev f1 (lr=3e-06, epoch=14): 32.94
Epoch: 14, Step: 70 / 105, used_time = 1855.27s, loss = 2.696464
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.47941596433963
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1867.70s, loss = 2.693232
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.99480139060036
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1879.98s, loss = 2.689914
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.64950433395237
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1891.92s, loss = 2.686301
***** Eval results *****
  exact = 8.459214501510575
  f1 = 32.08607717587735
  total = 662
Start epoch #15 (lr = 3e-06)...
Epoch: 15, Step: 10 / 105, used_time = 1907.22s, loss = 2.684100
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.948232602630256
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1919.37s, loss = 2.681417
***** Eval results *****
  exact = 8.459214501510575
  f1 = 32.03353134773521
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1931.50s, loss = 2.678171
***** Eval results *****
  exact = 8.459214501510575
  f1 = 32.158451702084534
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1943.76s, loss = 2.675035
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.785500377951507
  total = 662
Epoch: 15, Step: 50 / 105, used_time = 1955.89s, loss = 2.672502
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.806700690789917
  total = 662
Epoch: 15, Step: 60 / 105, used_time = 1968.11s, loss = 2.669465
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.935839261835746
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1980.30s, loss = 2.667115
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.474371746765
  total = 662
Epoch: 15, Step: 80 / 105, used_time = 1992.59s, loss = 2.663025
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.49458750837832
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 2004.78s, loss = 2.660179
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.23041514296831
  total = 662
Epoch: 15, Step: 100 / 105, used_time = 2016.72s, loss = 2.657010
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.32167851876075
  total = 662
Start epoch #16 (lr = 3e-06)...
Epoch: 16, Step: 10 / 105, used_time = 2032.21s, loss = 2.653708
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.25140183303154
  total = 662
Epoch: 16, Step: 20 / 105, used_time = 2044.57s, loss = 2.651729
***** Eval results *****
  exact = 8.459214501510575
  f1 = 32.10686029864171
  total = 662
Epoch: 16, Step: 30 / 105, used_time = 2056.40s, loss = 2.647734
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.100715895540986
  total = 662
Epoch: 16, Step: 40 / 105, used_time = 2068.65s, loss = 2.644614
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.70574501022297
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2080.99s, loss = 2.641708
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.631017019651292
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2093.22s, loss = 2.639501
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.496591190361418
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2105.49s, loss = 2.636438
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.554286853458684
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2117.65s, loss = 2.634431
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.56720931519466
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2129.98s, loss = 2.632110
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.688783309525007
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2142.14s, loss = 2.629863
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.611150221406756
  total = 662
Start epoch #17 (lr = 3e-06)...
Epoch: 17, Step: 10 / 105, used_time = 2157.42s, loss = 2.626298
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.63448063873591
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2169.58s, loss = 2.624852
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.58321842271681
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2181.86s, loss = 2.622128
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.662256158919917
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2193.66s, loss = 2.619625
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.831619667495215
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2205.87s, loss = 2.617858
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.994091720821846
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2218.05s, loss = 2.616432
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.07007946633966
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2230.49s, loss = 2.613851
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.202746015817134
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2242.79s, loss = 2.611750
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.1384814618712
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2254.96s, loss = 2.609863
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.17585359991941
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2267.06s, loss = 2.606877
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.639827780590682
  total = 662
Start epoch #18 (lr = 3e-06)...
Epoch: 18, Step: 10 / 105, used_time = 2282.41s, loss = 2.603039
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.837485613003956
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2294.55s, loss = 2.600320
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.801299301247106
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2306.70s, loss = 2.599182
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.89134074290579
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2318.90s, loss = 2.596554
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.807052909273303
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2331.21s, loss = 2.593166
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.871345298339104
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2343.57s, loss = 2.591752
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.77324632847338
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2355.84s, loss = 2.589934
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.863884903589504
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2367.67s, loss = 2.588137
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.01687600939739
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2379.94s, loss = 2.585368
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.913949642476005
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2392.13s, loss = 2.583158
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.81068134269169
  total = 662
Start epoch #19 (lr = 3e-06)...
Epoch: 19, Step: 10 / 105, used_time = 2407.49s, loss = 2.580600
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.91138627723348
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2419.78s, loss = 2.579043
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.007812492265806
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2432.02s, loss = 2.576169
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.027407765579824
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2444.17s, loss = 2.573769
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.916043210461936
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2456.32s, loss = 2.571644
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.916043210461936
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2468.42s, loss = 2.569466
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.894886711608617
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2480.71s, loss = 2.567894
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.894886711608617
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2492.80s, loss = 2.566589
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.916043210461936
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2504.59s, loss = 2.564138
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.894886711608617
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2516.73s, loss = 2.561950
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.894886711608617
  total = 662
Start epoch #0 (lr = 5e-06)...
Epoch: 0, Step: 10 / 105, used_time = 5.83s, loss = 5.947386
***** Eval results *****
  exact = 0.1510574018126888
  f1 = 14.87348365654916
  total = 662
Epoch: 0, Step: 20 / 105, used_time = 17.93s, loss = 5.910818
***** Eval results *****
  exact = 0.7552870090634441
  f1 = 17.320789588002427
  total = 662
Epoch: 0, Step: 30 / 105, used_time = 30.06s, loss = 5.861879
***** Eval results *****
  exact = 0.6042296072507553
  f1 = 20.299020347631103
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.27s, loss = 5.787976
***** Eval results *****
  exact = 1.5105740181268883
  f1 = 21.53300006539913
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 54.54s, loss = 5.690773
***** Eval results *****
  exact = 1.661631419939577
  f1 = 22.12562169839829
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 66.70s, loss = 5.556792
***** Eval results *****
  exact = 2.2658610271903323
  f1 = 23.054402531770013
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 78.77s, loss = 5.381969
***** Eval results *****
  exact = 2.56797583081571
  f1 = 22.545427235397014
  total = 662
Epoch: 0, Step: 80 / 105, used_time = 90.84s, loss = 5.209860
***** Eval results *****
  exact = 3.1722054380664653
  f1 = 23.759913653839362
  total = 662
Epoch: 0, Step: 90 / 105, used_time = 103.11s, loss = 5.047216
***** Eval results *****
  exact = 3.9274924471299095
  f1 = 23.572913384408643
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 115.25s, loss = 4.898945
***** Eval results *****
  exact = 5.287009063444109
  f1 = 25.010646055553114
  total = 662
Start epoch #1 (lr = 5e-06)...
Epoch: 1, Step: 10 / 105, used_time = 130.54s, loss = 4.641066
***** Eval results *****
  exact = 5.589123867069486
  f1 = 26.002450548308474
  total = 662
Epoch: 1, Step: 20 / 105, used_time = 142.39s, loss = 4.520736
***** Eval results *****
  exact = 6.3444108761329305
  f1 = 26.325326499140314
  total = 662
Epoch: 1, Step: 30 / 105, used_time = 154.74s, loss = 4.410069
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.265767578043263
  total = 662
Epoch: 1, Step: 40 / 105, used_time = 166.94s, loss = 4.316248
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.603353435284934
  total = 662
Epoch: 1, Step: 50 / 105, used_time = 179.20s, loss = 4.218841
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.0937574067449
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 191.58s, loss = 4.138826
***** Eval results *****
  exact = 6.948640483383686
  f1 = 26.586804256037606
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 203.78s, loss = 4.062478
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.133696156715907
  total = 662
Epoch: 1, Step: 80 / 105, used_time = 215.99s, loss = 3.995337
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.263675345721563
  total = 662
Epoch: 1, Step: 90 / 105, used_time = 228.22s, loss = 3.937925
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.48837653851542
  total = 662
Epoch: 1, Step: 100 / 105, used_time = 240.44s, loss = 3.886859
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.803611808079918
  total = 662
Start epoch #2 (lr = 5e-06)...
Epoch: 2, Step: 10 / 105, used_time = 255.97s, loss = 3.803924
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.044146888570072
  total = 662
Epoch: 2, Step: 20 / 105, used_time = 268.24s, loss = 3.754465
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.735733140110092
  total = 662
Epoch: 2, Step: 30 / 105, used_time = 280.50s, loss = 3.712588
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.4960919720188
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 292.88s, loss = 3.685374
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.97071212778405
  total = 662
Epoch: 2, Step: 50 / 105, used_time = 305.17s, loss = 3.651091
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.77247326588608
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 317.16s, loss = 3.616220
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.32743670273275
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 329.44s, loss = 3.587032
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.086996564655795
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 341.87s, loss = 3.551684
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 27.708303399631788
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 354.12s, loss = 3.527108
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.2553448475061
  total = 662
Epoch: 2, Step: 100 / 105, used_time = 366.43s, loss = 3.502945
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.110319891806938
  total = 662
Start epoch #3 (lr = 5e-06)...
Epoch: 3, Step: 10 / 105, used_time = 381.91s, loss = 3.459847
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.654902535557834
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 394.35s, loss = 3.433785
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.039790219119986
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 406.64s, loss = 3.409386
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.39246463080845
  total = 662
Epoch: 3, Step: 40 / 105, used_time = 418.89s, loss = 3.388289
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.381200068325338
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 431.15s, loss = 3.362987
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.096033172399192
  total = 662
Epoch: 3, Step: 60 / 105, used_time = 443.34s, loss = 3.341936
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.098238856599075
  total = 662
Epoch: 3, Step: 70 / 105, used_time = 455.73s, loss = 3.318352
***** Eval results *****
  exact = 8.157099697885196
  f1 = 27.110735270507
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 467.99s, loss = 3.303580
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.27748774333322
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 480.28s, loss = 3.288630
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.07598844300029
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 492.75s, loss = 3.273695
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.814647583325236
  total = 662
Start epoch #4 (lr = 5e-06)...
Epoch: 4, Step: 10 / 105, used_time = 508.01s, loss = 3.254986
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.99993892535108
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 520.43s, loss = 3.239695
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.594453830645126
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 532.78s, loss = 3.224927
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.169918014885365
  total = 662
Epoch: 4, Step: 40 / 105, used_time = 545.26s, loss = 3.206986
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 28.016758282099765
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 557.57s, loss = 3.189685
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 28.20975471309886
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 569.83s, loss = 3.172472
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.380240837814362
  total = 662
Epoch: 4, Step: 70 / 105, used_time = 582.06s, loss = 3.162403
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.596039949385457
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 594.54s, loss = 3.149265
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.991401566406072
  total = 662
Epoch: 4, Step: 90 / 105, used_time = 606.61s, loss = 3.136934
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.55555577550611
  total = 662
Epoch: 4, Step: 100 / 105, used_time = 618.95s, loss = 3.121790
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.460967662746402
  total = 662
Start epoch #5 (lr = 5e-06)...
Epoch: 5, Step: 10 / 105, used_time = 634.46s, loss = 3.100125
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.34661298879015
  total = 662
Epoch: 5, Step: 20 / 105, used_time = 646.91s, loss = 3.086477
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.14205171698226
  total = 662
Epoch: 5, Step: 30 / 105, used_time = 659.23s, loss = 3.077416
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.755412881332216
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 671.51s, loss = 3.066025
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.393678313342836
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 683.83s, loss = 3.054156
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.452242293374308
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 696.05s, loss = 3.043329
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.42629193600651
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 708.39s, loss = 3.034169
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.947808013560746
  total = 662
Epoch: 5, Step: 80 / 105, used_time = 720.71s, loss = 3.021820
***** Eval results *****
  exact = 8.308157099697885
  f1 = 29.65851546396376
  total = 662
Epoch: 5, Step: 90 / 105, used_time = 733.00s, loss = 3.012078
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.84180799829282
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 745.35s, loss = 3.002805
***** Eval results *****
  exact = 7.552870090634441
  f1 = 29.900384905607332
  total = 662
Start epoch #6 (lr = 5e-06)...
Epoch: 6, Step: 10 / 105, used_time = 760.43s, loss = 2.985349
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.17547763800019
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 772.71s, loss = 2.975615
***** Eval results *****
  exact = 7.552870090634441
  f1 = 30.335651890481678
  total = 662
Epoch: 6, Step: 30 / 105, used_time = 784.92s, loss = 2.963951
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 29.11561901209177
  total = 662
Epoch: 6, Step: 40 / 105, used_time = 796.92s, loss = 2.957983
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.524375400802427
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 809.16s, loss = 2.947055
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.547742865668415
  total = 662
Epoch: 6, Step: 60 / 105, used_time = 821.39s, loss = 2.940534
***** Eval results *****
  exact = 8.006042296072508
  f1 = 30.093161727489917
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 833.72s, loss = 2.930728
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.457123274274316
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 846.15s, loss = 2.923182
***** Eval results *****
  exact = 8.006042296072508
  f1 = 30.316508167410866
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 858.49s, loss = 2.913929
***** Eval results *****
  exact = 7.854984894259819
  f1 = 30.42315815637715
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 870.85s, loss = 2.907502
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.421033662009254
  total = 662
Start epoch #7 (lr = 5e-06)...
Epoch: 7, Step: 10 / 105, used_time = 886.42s, loss = 2.892129
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.489658044747504
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 898.96s, loss = 2.881454
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.51015442036988
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 911.35s, loss = 2.873216
***** Eval results *****
  exact = 8.006042296072508
  f1 = 30.32110632803761
  total = 662
Epoch: 7, Step: 40 / 105, used_time = 923.68s, loss = 2.867162
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.660884076941233
  total = 662
Epoch: 7, Step: 50 / 105, used_time = 936.11s, loss = 2.857373
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.96309438677121
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 948.70s, loss = 2.850134
***** Eval results *****
  exact = 7.854984894259819
  f1 = 29.872584317759067
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 961.09s, loss = 2.843020
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.279282849307403
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 973.40s, loss = 2.836046
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.639344569042905
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 985.32s, loss = 2.829759
***** Eval results *****
  exact = 8.91238670694864
  f1 = 30.962392630585082
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 997.73s, loss = 2.822360
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.15347734582698
  total = 662
Start epoch #8 (lr = 5e-06)...
Epoch: 8, Step: 10 / 105, used_time = 1012.82s, loss = 2.810935
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.340553583623493
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1025.09s, loss = 2.802018
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.478725057997828
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1037.36s, loss = 2.792784
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.023323061494143
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1049.88s, loss = 2.787946
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.95433959972696
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1062.30s, loss = 2.781808
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.95158345722846
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1074.68s, loss = 2.774150
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.29259072192142
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1087.07s, loss = 2.766507
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.131195731968013
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1099.48s, loss = 2.760049
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.182818496110524
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1111.76s, loss = 2.754161
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.283773876937587
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1124.06s, loss = 2.748398
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.797457504137704
  total = 662
Start epoch #9 (lr = 5e-06)...
Epoch: 9, Step: 10 / 105, used_time = 1139.41s, loss = 2.737151
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.62228495327838
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1151.77s, loss = 2.730332
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.739240925603962
  total = 662
Epoch: 9, Step: 30 / 105, used_time = 1163.98s, loss = 2.724896
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.952756833717732
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1176.13s, loss = 2.718512
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.190575841985172
  total = 662
Epoch: 9, Step: 50 / 105, used_time = 1188.42s, loss = 2.713364
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.814795439874903
  total = 662
Epoch: 9, Step: 60 / 105, used_time = 1200.85s, loss = 2.706208
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.306109096025253
  total = 662
Epoch: 9, Step: 70 / 105, used_time = 1213.27s, loss = 2.703031
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.810720776385672
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1225.71s, loss = 2.696765
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.477112525831064
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1238.12s, loss = 2.689504
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.971554326069253
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1250.24s, loss = 2.684020
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.685085147110613
  total = 662
Start epoch #10 (lr = 5e-06)...
Epoch: 10, Step: 10 / 105, used_time = 1265.82s, loss = 2.676178
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.883732745364238
  total = 662
Epoch: 10, Step: 20 / 105, used_time = 1278.22s, loss = 2.671134
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.03979673453741
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1290.60s, loss = 2.664384
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.86024540259975
  total = 662
Epoch: 10, Step: 40 / 105, used_time = 1303.03s, loss = 2.657313
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.68445641148648
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1315.16s, loss = 2.651586
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.864307461456214
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1327.54s, loss = 2.646558
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.581952139016742
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1339.87s, loss = 2.641002
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.096570535534646
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1352.33s, loss = 2.636109
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.400807709305848
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1364.63s, loss = 2.631663
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.11441303395558
  total = 662
Epoch: 10, Step: 100 / 105, used_time = 1376.86s, loss = 2.624716
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.57008901160265
  total = 662
Start epoch #11 (lr = 5e-06)...
Epoch: 11, Step: 10 / 105, used_time = 1392.38s, loss = 2.617369
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.782837621169094
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1404.89s, loss = 2.611377
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.33606539140135
  total = 662
Epoch: 11, Step: 30 / 105, used_time = 1417.25s, loss = 2.605879
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.50640641099884
  total = 662
Epoch: 11, Step: 40 / 105, used_time = 1429.64s, loss = 2.599632
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.35726644022748
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1441.96s, loss = 2.595280
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.31888146233945
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1454.34s, loss = 2.590415
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.164594449141454
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1466.27s, loss = 2.584299
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.615008371360915
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1478.63s, loss = 2.580120
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.69821390922825
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1490.88s, loss = 2.575676
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.73299791202884
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1503.35s, loss = 2.571866
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.89920711121793
  total = 662
Start epoch #12 (lr = 5e-06)...
Epoch: 12, Step: 10 / 105, used_time = 1518.69s, loss = 2.564180
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.23945596429376
  total = 662
Epoch: 12, Step: 20 / 105, used_time = 1530.94s, loss = 2.558551
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.60970739027825
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1543.21s, loss = 2.554495
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.040297715891775
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1555.61s, loss = 2.550310
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.329029121250095
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1567.77s, loss = 2.544676
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.39452578105007
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1579.97s, loss = 2.540627
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.102804469440755
  total = 662
!!! Best dev f1 (lr=5e-06, epoch=12): 33.10
Epoch: 12, Step: 70 / 105, used_time = 1593.35s, loss = 2.536919
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.353672628288656
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1605.48s, loss = 2.532991
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.87794745517778
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1617.78s, loss = 2.528838
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.90278311027921
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1630.08s, loss = 2.524073
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.684559269401795
  total = 662
Start epoch #13 (lr = 5e-06)...
Epoch: 13, Step: 10 / 105, used_time = 1645.45s, loss = 2.516991
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.26945627099855
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1657.79s, loss = 2.512313
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.626063648193416
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1669.99s, loss = 2.508178
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.823578714239794
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1682.21s, loss = 2.503927
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.71770688227638
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1694.42s, loss = 2.499801
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.06327758133737
  total = 662
Epoch: 13, Step: 60 / 105, used_time = 1706.77s, loss = 2.495205
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.71906997748004
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1719.09s, loss = 2.492688
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.001811721743664
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1731.45s, loss = 2.488360
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.96645989865308
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1743.76s, loss = 2.484846
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.164379365721075
  total = 662
!!! Best dev f1 (lr=5e-06, epoch=13): 33.16
Epoch: 13, Step: 100 / 105, used_time = 1756.94s, loss = 2.480060
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.01070740570599
  total = 662
Start epoch #14 (lr = 5e-06)...
Epoch: 14, Step: 10 / 105, used_time = 1772.58s, loss = 2.473675
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.67066818411061
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1784.52s, loss = 2.469897
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.927458071436654
  total = 662
Epoch: 14, Step: 30 / 105, used_time = 1796.69s, loss = 2.466706
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.525784600949244
  total = 662
Epoch: 14, Step: 40 / 105, used_time = 1808.98s, loss = 2.463123
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.724274686411626
  total = 662
Epoch: 14, Step: 50 / 105, used_time = 1821.07s, loss = 2.458915
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.84838606188651
  total = 662
Epoch: 14, Step: 60 / 105, used_time = 1833.22s, loss = 2.453485
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.8727957005545
  total = 662
Epoch: 14, Step: 70 / 105, used_time = 1845.45s, loss = 2.450622
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.722914039518884
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1857.70s, loss = 2.447494
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.774498107533724
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1869.83s, loss = 2.444660
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.0182769354514
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1882.00s, loss = 2.440849
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.489220015743875
  total = 662
!!! Best dev f1 (lr=5e-06, epoch=14): 33.49
Start epoch #15 (lr = 5e-06)...
Epoch: 15, Step: 10 / 105, used_time = 1898.47s, loss = 2.435366
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.14141745945862
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1910.97s, loss = 2.432025
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.096958037734254
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1923.32s, loss = 2.428751
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.16212213518654
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1935.66s, loss = 2.425680
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.88648292025758
  total = 662
Epoch: 15, Step: 50 / 105, used_time = 1947.65s, loss = 2.422181
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.606685723305645
  total = 662
!!! Best dev f1 (lr=5e-06, epoch=15): 33.61
Epoch: 15, Step: 60 / 105, used_time = 1961.23s, loss = 2.418183
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.5446624593573
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1973.58s, loss = 2.414612
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.378992499200116
  total = 662
Epoch: 15, Step: 80 / 105, used_time = 1985.98s, loss = 2.410386
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.34768674912524
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 1998.32s, loss = 2.406844
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.946513815744545
  total = 662
Epoch: 15, Step: 100 / 105, used_time = 2010.69s, loss = 2.403809
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.36699289526949
  total = 662
Start epoch #16 (lr = 5e-06)...
Epoch: 16, Step: 10 / 105, used_time = 2026.09s, loss = 2.398564
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.114257480578566
  total = 662
Epoch: 16, Step: 20 / 105, used_time = 2038.33s, loss = 2.394738
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.11304598253672
  total = 662
Epoch: 16, Step: 30 / 105, used_time = 2050.61s, loss = 2.391099
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.21980244830913
  total = 662
Epoch: 16, Step: 40 / 105, used_time = 2062.93s, loss = 2.388818
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.254133987581106
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2075.14s, loss = 2.385745
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.40205244646523
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2087.00s, loss = 2.383125
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.11904142395892
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2099.28s, loss = 2.379962
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.19184048050803
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2111.47s, loss = 2.376342
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.56702874016436
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2123.65s, loss = 2.372703
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.68118928256787
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2135.94s, loss = 2.369576
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.26847933912091
  total = 662
Start epoch #17 (lr = 5e-06)...
Epoch: 17, Step: 10 / 105, used_time = 2151.49s, loss = 2.365164
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.37170622781688
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2163.75s, loss = 2.362421
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.46477730578222
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2175.99s, loss = 2.359216
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.01595993843696
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2188.26s, loss = 2.355609
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.15106394384211
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2200.61s, loss = 2.352703
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.8761571956273
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2212.78s, loss = 2.349484
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.74853305742914
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2224.58s, loss = 2.346171
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.58659602929216
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2236.74s, loss = 2.343387
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.75115403748488
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2248.97s, loss = 2.341023
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.43916072239644
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2261.17s, loss = 2.338312
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.28905506749465
  total = 662
Start epoch #18 (lr = 5e-06)...
Epoch: 18, Step: 10 / 105, used_time = 2276.70s, loss = 2.334552
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.762468579690456
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2289.04s, loss = 2.332895
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.69844761519745
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2301.64s, loss = 2.329581
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.74767108011356
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2314.18s, loss = 2.326535
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.66387253127023
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2326.23s, loss = 2.323449
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.51495518179983
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2338.49s, loss = 2.320903
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.313847504491996
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2350.78s, loss = 2.317753
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.62689687383661
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2363.00s, loss = 2.315141
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.693468914163184
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2375.03s, loss = 2.312743
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.71517241577695
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2387.39s, loss = 2.310098
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.6950796859977
  total = 662
Start epoch #19 (lr = 5e-06)...
Epoch: 19, Step: 10 / 105, used_time = 2402.66s, loss = 2.306349
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.84003505109288
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2414.97s, loss = 2.304169
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.757745894199324
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2427.21s, loss = 2.301265
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.63524976583861
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2439.33s, loss = 2.298455
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.8022707006397
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2451.74s, loss = 2.296045
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.638989073789574
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2463.93s, loss = 2.293917
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.679774572278994
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2476.13s, loss = 2.292330
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.679774572278994
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2488.35s, loss = 2.289812
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.679774572278994
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2500.73s, loss = 2.287791
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.679774572278994
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2512.61s, loss = 2.284681
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.679774572278994
  total = 662
Start epoch #0 (lr = 1e-05)...
Epoch: 0, Step: 10 / 105, used_time = 6.17s, loss = 5.927367
***** Eval results *****
  exact = 0.0
  f1 = 15.753018849925327
  total = 662
Epoch: 0, Step: 20 / 105, used_time = 18.32s, loss = 5.883266
***** Eval results *****
  exact = 0.0
  f1 = 16.29811441984452
  total = 662
Epoch: 0, Step: 30 / 105, used_time = 30.69s, loss = 5.796511
***** Eval results *****
  exact = 1.8126888217522659
  f1 = 20.43961918906824
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.92s, loss = 5.648937
***** Eval results *****
  exact = 1.2084592145015105
  f1 = 21.406713207196727
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 55.13s, loss = 5.442122
***** Eval results *****
  exact = 2.8700906344410875
  f1 = 22.373311765842537
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 66.87s, loss = 5.217696
***** Eval results *****
  exact = 3.9274924471299095
  f1 = 23.8578922481705
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 79.17s, loss = 4.963092
***** Eval results *****
  exact = 5.589123867069486
  f1 = 25.32520370351071
  total = 662
Epoch: 0, Step: 80 / 105, used_time = 91.38s, loss = 4.725516
***** Eval results *****
  exact = 5.891238670694864
  f1 = 24.68549923521404
  total = 662
Epoch: 0, Step: 90 / 105, used_time = 103.68s, loss = 4.521464
***** Eval results *****
  exact = 6.646525679758308
  f1 = 25.65957998612097
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 116.11s, loss = 4.341713
***** Eval results *****
  exact = 7.401812688821752
  f1 = 26.80654869861415
  total = 662
Start epoch #1 (lr = 1e-05)...
Epoch: 1, Step: 10 / 105, used_time = 131.80s, loss = 4.139398
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 26.861090996082453
  total = 662
Epoch: 1, Step: 20 / 105, used_time = 144.19s, loss = 4.031743
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.465826831206446
  total = 662
Epoch: 1, Step: 30 / 105, used_time = 156.53s, loss = 3.944772
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.741806543516727
  total = 662
Epoch: 1, Step: 40 / 105, used_time = 168.86s, loss = 3.857483
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.545334352508586
  total = 662
Epoch: 1, Step: 50 / 105, used_time = 181.35s, loss = 3.793553
***** Eval results *****
  exact = 8.459214501510575
  f1 = 28.582168476520913
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 193.62s, loss = 3.738705
***** Eval results *****
  exact = 8.761329305135952
  f1 = 29.268537907374387
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 205.60s, loss = 3.697263
***** Eval results *****
  exact = 6.7975830815709966
  f1 = 27.3619351088953
  total = 662
Epoch: 1, Step: 80 / 105, used_time = 217.81s, loss = 3.645965
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.05723977972768
  total = 662
Epoch: 1, Step: 90 / 105, used_time = 230.22s, loss = 3.603045
***** Eval results *****
  exact = 8.459214501510575
  f1 = 28.07487079311365
  total = 662
Epoch: 1, Step: 100 / 105, used_time = 242.47s, loss = 3.554018
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.73215666529073
  total = 662
Start epoch #2 (lr = 1e-05)...
Epoch: 2, Step: 10 / 105, used_time = 258.00s, loss = 3.502887
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 29.093149579955973
  total = 662
Epoch: 2, Step: 20 / 105, used_time = 270.34s, loss = 3.469884
***** Eval results *****
  exact = 7.552870090634441
  f1 = 28.207451968036118
  total = 662
Epoch: 2, Step: 30 / 105, used_time = 282.72s, loss = 3.426221
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.350743868387912
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 294.93s, loss = 3.396714
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.342521582337135
  total = 662
Epoch: 2, Step: 50 / 105, used_time = 307.20s, loss = 3.364764
***** Eval results *****
  exact = 8.459214501510575
  f1 = 29.783418089588615
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 319.54s, loss = 3.338238
***** Eval results *****
  exact = 8.006042296072508
  f1 = 29.268311134741047
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 331.63s, loss = 3.307289
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 29.71616475666644
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 343.95s, loss = 3.282221
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.0594161038703
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 356.35s, loss = 3.255362
***** Eval results *****
  exact = 7.552870090634441
  f1 = 30.21635788165803
  total = 662
Epoch: 2, Step: 100 / 105, used_time = 368.75s, loss = 3.235212
***** Eval results *****
  exact = 8.91238670694864
  f1 = 30.401373552012384
  total = 662
Start epoch #3 (lr = 1e-05)...
Epoch: 3, Step: 10 / 105, used_time = 384.57s, loss = 3.201495
***** Eval results *****
  exact = 9.214501510574019
  f1 = 30.429423439596615
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 397.07s, loss = 3.176724
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.185398184460443
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 409.44s, loss = 3.158021
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.68726292675891
  total = 662
Epoch: 3, Step: 40 / 105, used_time = 421.79s, loss = 3.136497
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.811001235943902
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 434.16s, loss = 3.113132
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.94969273106237
  total = 662
Epoch: 3, Step: 60 / 105, used_time = 446.47s, loss = 3.091230
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.458193257789574
  total = 662
Epoch: 3, Step: 70 / 105, used_time = 458.37s, loss = 3.071794
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.07056247889572
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 470.69s, loss = 3.052383
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.40607960044605
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 483.13s, loss = 3.031826
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.395906475537615
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 495.48s, loss = 3.016036
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.78044979437327
  total = 662
Start epoch #4 (lr = 1e-05)...
Epoch: 4, Step: 10 / 105, used_time = 511.05s, loss = 2.990403
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.20029959146292
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 523.06s, loss = 2.973233
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.591829866465595
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 535.61s, loss = 2.954920
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.54909441015534
  total = 662
Epoch: 4, Step: 40 / 105, used_time = 547.97s, loss = 2.939253
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.89799621831894
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 560.33s, loss = 2.916706
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.81784958737681
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 572.75s, loss = 2.899602
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.75690059223706
  total = 662
!!! Best dev f1 (lr=1e-05, epoch=4): 33.76
Epoch: 4, Step: 70 / 105, used_time = 586.37s, loss = 2.882422
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.580174764854625
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 598.89s, loss = 2.868308
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.943996763810006
  total = 662
Epoch: 4, Step: 90 / 105, used_time = 611.32s, loss = 2.852674
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.78129060096169
  total = 662
Epoch: 4, Step: 100 / 105, used_time = 623.82s, loss = 2.839093
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.923972057411795
  total = 662
Start epoch #5 (lr = 1e-05)...
Epoch: 5, Step: 10 / 105, used_time = 639.56s, loss = 2.810831
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.71505472386653
  total = 662
Epoch: 5, Step: 20 / 105, used_time = 651.88s, loss = 2.794544
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.3882454002926
  total = 662
Epoch: 5, Step: 30 / 105, used_time = 664.23s, loss = 2.777121
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.52776910669782
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 676.77s, loss = 2.764573
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.2447195430395
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 689.10s, loss = 2.750893
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.0947466387706
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 701.53s, loss = 2.737863
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.56492200907814
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 713.82s, loss = 2.725865
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.99611076173851
  total = 662
!!! Best dev f1 (lr=1e-05, epoch=5): 34.00
Epoch: 5, Step: 80 / 105, used_time = 727.01s, loss = 2.712948
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.5068248070792
  total = 662
!!! Best dev f1 (lr=1e-05, epoch=5): 34.51
Epoch: 5, Step: 90 / 105, used_time = 740.46s, loss = 2.699463
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.30501023590777
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 752.88s, loss = 2.687459
***** Eval results *****
  exact = 10.422960725075528
  f1 = 34.20010632816535
  total = 662
Start epoch #6 (lr = 1e-05)...
Epoch: 6, Step: 10 / 105, used_time = 768.46s, loss = 2.666261
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.727408011277575
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 780.84s, loss = 2.651441
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.32069111567237
  total = 662
Epoch: 6, Step: 30 / 105, used_time = 792.61s, loss = 2.635877
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.37904347982892
  total = 662
Epoch: 6, Step: 40 / 105, used_time = 804.79s, loss = 2.621656
***** Eval results *****
  exact = 9.969788519637461
  f1 = 34.44007284352948
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 816.93s, loss = 2.609026
***** Eval results *****
  exact = 10.120845921450151
  f1 = 34.06393879953732
  total = 662
Epoch: 6, Step: 60 / 105, used_time = 829.19s, loss = 2.595104
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.672200922449065
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 841.45s, loss = 2.583359
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.71219532150823
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 853.70s, loss = 2.572817
***** Eval results *****
  exact = 10.120845921450151
  f1 = 34.29556270850474
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 865.98s, loss = 2.562237
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.67798588637804
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 878.44s, loss = 2.553685
***** Eval results *****
  exact = 10.120845921450151
  f1 = 34.234572329154915
  total = 662
Start epoch #7 (lr = 1e-05)...
Epoch: 7, Step: 10 / 105, used_time = 893.57s, loss = 2.532345
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.59080413704271
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 905.91s, loss = 2.521123
***** Eval results *****
  exact = 8.610271903323262
  f1 = 33.54458228667479
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 918.23s, loss = 2.507083
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.74484426092028
  total = 662
Epoch: 7, Step: 40 / 105, used_time = 930.66s, loss = 2.494460
***** Eval results *****
  exact = 9.969788519637461
  f1 = 35.21663926627142
  total = 662
!!! Best dev f1 (lr=1e-05, epoch=7): 35.22
Epoch: 7, Step: 50 / 105, used_time = 944.14s, loss = 2.483972
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.773926446547776
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 956.61s, loss = 2.472664
***** Eval results *****
  exact = 10.27190332326284
  f1 = 34.17246323591788
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 968.90s, loss = 2.463392
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.83838107632514
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 981.29s, loss = 2.452733
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.88604550549687
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 993.55s, loss = 2.442787
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.93885991670049
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 1005.78s, loss = 2.431980
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.98052891646196
  total = 662
Start epoch #8 (lr = 1e-05)...
Epoch: 8, Step: 10 / 105, used_time = 1021.33s, loss = 2.415663
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.82813178121858
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1033.60s, loss = 2.405011
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.627046955176716
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1045.76s, loss = 2.393274
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.4479334300316
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1057.95s, loss = 2.381595
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.755176727518254
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1070.01s, loss = 2.369644
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.83175712613698
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1082.32s, loss = 2.359848
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.87732385320122
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1094.66s, loss = 2.348801
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.343551639118715
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1106.99s, loss = 2.340024
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.14884747715036
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1119.49s, loss = 2.330372
***** Eval results *****
  exact = 8.610271903323262
  f1 = 33.68372543210924
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1131.82s, loss = 2.321101
***** Eval results *****
  exact = 9.06344410876133
  f1 = 34.18058711934638
  total = 662
Start epoch #9 (lr = 1e-05)...
Epoch: 9, Step: 10 / 105, used_time = 1147.39s, loss = 2.308040
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.77261005393506
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1159.73s, loss = 2.298179
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.781410805855444
  total = 662
Epoch: 9, Step: 30 / 105, used_time = 1172.09s, loss = 2.288611
***** Eval results *****
  exact = 9.214501510574019
  f1 = 34.30770576077066
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1184.38s, loss = 2.279553
***** Eval results *****
  exact = 9.06344410876133
  f1 = 33.41669662387621
  total = 662
Epoch: 9, Step: 50 / 105, used_time = 1196.36s, loss = 2.270213
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.862272185250156
  total = 662
Epoch: 9, Step: 60 / 105, used_time = 1208.63s, loss = 2.260327
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.269117670579135
  total = 662
Epoch: 9, Step: 70 / 105, used_time = 1221.07s, loss = 2.249787
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.87979445070188
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1233.33s, loss = 2.240897
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.41679926491007
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1245.62s, loss = 2.233005
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.51782770243475
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1257.88s, loss = 2.225247
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.27035401649971
  total = 662
Start epoch #10 (lr = 1e-05)...
Epoch: 10, Step: 10 / 105, used_time = 1273.56s, loss = 2.211024
***** Eval results *****
  exact = 9.214501510574019
  f1 = 34.20267556032689
  total = 662
Epoch: 10, Step: 20 / 105, used_time = 1285.93s, loss = 2.201293
***** Eval results *****
  exact = 9.214501510574019
  f1 = 34.37688464218226
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1298.18s, loss = 2.191826
***** Eval results *****
  exact = 9.06344410876133
  f1 = 34.134589158982216
  total = 662
Epoch: 10, Step: 40 / 105, used_time = 1310.31s, loss = 2.182750
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.38581605301463
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1322.59s, loss = 2.174418
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.951268254631486
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1334.70s, loss = 2.165141
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.24027857884201
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1346.56s, loss = 2.157296
***** Eval results *****
  exact = 8.91238670694864
  f1 = 34.03210019610231
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1358.66s, loss = 2.150679
***** Eval results *****
  exact = 9.06344410876133
  f1 = 34.56576602889554
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1371.02s, loss = 2.141399
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.33936073502029
  total = 662
Epoch: 10, Step: 100 / 105, used_time = 1383.34s, loss = 2.133727
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.26910225408338
  total = 662
Start epoch #11 (lr = 1e-05)...
Epoch: 11, Step: 10 / 105, used_time = 1398.95s, loss = 2.120464
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.88215627372926
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1411.00s, loss = 2.112153
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.94269810129218
  total = 662
Epoch: 11, Step: 30 / 105, used_time = 1423.39s, loss = 2.103982
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.61037359018069
  total = 662
Epoch: 11, Step: 40 / 105, used_time = 1435.59s, loss = 2.095804
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.11292643420739
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1447.83s, loss = 2.088112
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.43213618699489
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1460.09s, loss = 2.080589
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.97107891016153
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1472.45s, loss = 2.073311
***** Eval results *****
  exact = 9.06344410876133
  f1 = 33.74993029146895
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1484.63s, loss = 2.065827
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.25346792461119
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1496.84s, loss = 2.058362
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.95590896226603
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1509.02s, loss = 2.051455
***** Eval results *****
  exact = 9.214501510574019
  f1 = 34.82984631472341
  total = 662
Start epoch #12 (lr = 1e-05)...
Epoch: 12, Step: 10 / 105, used_time = 1524.55s, loss = 2.039063
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.54997593714338
  total = 662
Epoch: 12, Step: 20 / 105, used_time = 1536.81s, loss = 2.031326
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.00989787994151
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1549.05s, loss = 2.024144
***** Eval results *****
  exact = 9.06344410876133
  f1 = 34.355256352204506
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1561.32s, loss = 2.017474
***** Eval results *****
  exact = 9.214501510574019
  f1 = 34.84361488214393
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1573.72s, loss = 2.009789
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.0596109315974
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1585.99s, loss = 2.003639
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.331636975298835
  total = 662
Epoch: 12, Step: 70 / 105, used_time = 1598.24s, loss = 1.996682
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.37052003823607
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1610.54s, loss = 1.990060
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.94638950398991
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1622.62s, loss = 1.982610
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.537995176870005
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1634.89s, loss = 1.975671
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.47003522775234
  total = 662
Start epoch #13 (lr = 1e-05)...
Epoch: 13, Step: 10 / 105, used_time = 1650.33s, loss = 1.965603
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.64922902540683
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1662.62s, loss = 1.958780
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.669312278001414
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1675.18s, loss = 1.951747
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.50310629098929
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1687.49s, loss = 1.944100
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.76112172264336
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1699.40s, loss = 1.936911
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.77651727014818
  total = 662
Epoch: 13, Step: 60 / 105, used_time = 1711.63s, loss = 1.930709
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.21779232824232
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1723.91s, loss = 1.924859
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.47017721269722
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1736.05s, loss = 1.918457
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.63297503219413
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1748.28s, loss = 1.912814
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.69586752167455
  total = 662
Epoch: 13, Step: 100 / 105, used_time = 1760.38s, loss = 1.907275
***** Eval results *****
  exact = 9.06344410876133
  f1 = 33.44595175053464
  total = 662
Start epoch #14 (lr = 1e-05)...
Epoch: 14, Step: 10 / 105, used_time = 1775.78s, loss = 1.898051
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.942295678387424
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1787.94s, loss = 1.891619
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.63995650273732
  total = 662
Epoch: 14, Step: 30 / 105, used_time = 1800.09s, loss = 1.885376
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.45631769020723
  total = 662
Epoch: 14, Step: 40 / 105, used_time = 1812.28s, loss = 1.878933
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.64457694717467
  total = 662
Epoch: 14, Step: 50 / 105, used_time = 1824.70s, loss = 1.873264
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.01705089833534
  total = 662
Epoch: 14, Step: 60 / 105, used_time = 1836.63s, loss = 1.866592
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.21211292130241
  total = 662
Epoch: 14, Step: 70 / 105, used_time = 1848.90s, loss = 1.861702
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.18449679923532
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1861.15s, loss = 1.856195
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.6796796315659
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1873.51s, loss = 1.849657
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.62383060926911
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1885.71s, loss = 1.844507
***** Eval results *****
  exact = 9.06344410876133
  f1 = 33.1883084265751
  total = 662
Start epoch #15 (lr = 1e-05)...
Epoch: 15, Step: 10 / 105, used_time = 1901.22s, loss = 1.836767
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.615052360606875
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1913.46s, loss = 1.831310
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.853572244689346
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1925.91s, loss = 1.825400
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.12307331437465
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1938.11s, loss = 1.819885
***** Eval results *****
  exact = 9.06344410876133
  f1 = 33.68762932702646
  total = 662
Epoch: 15, Step: 50 / 105, used_time = 1950.36s, loss = 1.814350
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.65585438188441
  total = 662
Epoch: 15, Step: 60 / 105, used_time = 1962.61s, loss = 1.809074
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.12822161877229
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1974.57s, loss = 1.802824
***** Eval results *****
  exact = 9.969788519637461
  f1 = 34.15025178716612
  total = 662
Epoch: 15, Step: 80 / 105, used_time = 1986.76s, loss = 1.797345
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.73961254353951
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 1999.04s, loss = 1.791980
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.333917339999715
  total = 662
Epoch: 15, Step: 100 / 105, used_time = 2011.22s, loss = 1.786848
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.24326220656092
  total = 662
Start epoch #16 (lr = 1e-05)...
Epoch: 16, Step: 10 / 105, used_time = 2027.02s, loss = 1.778964
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.91498975004049
  total = 662
Epoch: 16, Step: 20 / 105, used_time = 2039.32s, loss = 1.773940
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.91198232788055
  total = 662
Epoch: 16, Step: 30 / 105, used_time = 2051.58s, loss = 1.768451
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.8257758285464
  total = 662
Epoch: 16, Step: 40 / 105, used_time = 2063.90s, loss = 1.763490
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.80185979453897
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2076.25s, loss = 1.758573
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.58743976485616
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2088.04s, loss = 1.752939
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.87703683320143
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2100.27s, loss = 1.747998
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.33059926070586
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2112.52s, loss = 1.743370
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.114659374876425
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2124.90s, loss = 1.738379
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.878119539227065
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2137.18s, loss = 1.733730
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.61091061591397
  total = 662
Start epoch #17 (lr = 1e-05)...
Epoch: 17, Step: 10 / 105, used_time = 2152.58s, loss = 1.726260
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.36410329322461
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2164.79s, loss = 1.721462
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.124084832878886
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2176.80s, loss = 1.716223
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.77476616285409
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2188.90s, loss = 1.710995
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.505990016730685
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2201.09s, loss = 1.706483
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.53662923827552
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2213.37s, loss = 1.701912
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.03094550568798
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2225.71s, loss = 1.698114
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.29654597814186
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2237.96s, loss = 1.693174
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.293331941987994
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2250.15s, loss = 1.689009
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.27201529339244
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2262.43s, loss = 1.684489
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.15032525287517
  total = 662
Start epoch #18 (lr = 1e-05)...
Epoch: 18, Step: 10 / 105, used_time = 2277.96s, loss = 1.677952
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.80728667937162
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2290.18s, loss = 1.673692
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.11359986637495
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2302.47s, loss = 1.669205
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.970764560877356
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2314.86s, loss = 1.664804
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.84230903478479
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2327.13s, loss = 1.660568
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.016722018644636
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2339.28s, loss = 1.656188
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.625975833965306
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2351.43s, loss = 1.652835
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.01347525111449
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2363.37s, loss = 1.648162
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.1291392591914
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2375.61s, loss = 1.643683
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.24067108778444
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2387.77s, loss = 1.639967
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.00607557841791
  total = 662
Start epoch #19 (lr = 1e-05)...
Epoch: 19, Step: 10 / 105, used_time = 2403.17s, loss = 1.633845
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.10349280008669
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2415.58s, loss = 1.630343
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.05625064238365
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2427.73s, loss = 1.626427
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.16318129080975
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2439.52s, loss = 1.621641
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.061617167342305
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2451.67s, loss = 1.617360
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.999807363077586
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2463.98s, loss = 1.614001
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.980790941728195
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2476.26s, loss = 1.610954
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.07953409183086
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2488.49s, loss = 1.607475
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.13754967805864
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2500.66s, loss = 1.603771
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.07214884624666
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2512.89s, loss = 1.599560
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.07214884624666
  total = 662
Start epoch #0 (lr = 2e-05)...
Epoch: 0, Step: 10 / 105, used_time = 6.18s, loss = 5.933690
***** Eval results *****
  exact = 0.3021148036253776
  f1 = 17.884727481044262
  total = 662
Epoch: 0, Step: 20 / 105, used_time = 18.29s, loss = 5.833039
***** Eval results *****
  exact = 0.9063444108761329
  f1 = 20.464780778304622
  total = 662
Epoch: 0, Step: 30 / 105, used_time = 30.56s, loss = 5.586755
***** Eval results *****
  exact = 0.7552870090634441
  f1 = 21.645235576906604
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.85s, loss = 5.264290
***** Eval results *****
  exact = 2.416918429003021
  f1 = 22.740331313370763
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 54.98s, loss = 4.900147
***** Eval results *****
  exact = 4.078549848942598
  f1 = 23.64055375008108
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 67.08s, loss = 4.625884
***** Eval results *****
  exact = 5.891238670694864
  f1 = 25.214617272854607
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 79.27s, loss = 4.379633
***** Eval results *****
  exact = 6.646525679758308
  f1 = 26.091037671114112
  total = 662
Epoch: 0, Step: 80 / 105, used_time = 91.61s, loss = 4.195871
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.34341474795774
  total = 662
Epoch: 0, Step: 90 / 105, used_time = 103.42s, loss = 4.039229
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.633311894853623
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 115.67s, loss = 3.940686
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.91644173112255
  total = 662
Start epoch #1 (lr = 2e-05)...
Epoch: 1, Step: 10 / 105, used_time = 131.22s, loss = 3.785559
***** Eval results *****
  exact = 7.854984894259819
  f1 = 28.727865074578204
  total = 662
Epoch: 1, Step: 20 / 105, used_time = 143.63s, loss = 3.686023
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.441326895174917
  total = 662
Epoch: 1, Step: 30 / 105, used_time = 156.01s, loss = 3.622691
***** Eval results *****
  exact = 8.91238670694864
  f1 = 27.680774712532735
  total = 662
Epoch: 1, Step: 40 / 105, used_time = 168.29s, loss = 3.560958
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.49278326676138
  total = 662
Epoch: 1, Step: 50 / 105, used_time = 180.75s, loss = 3.493812
***** Eval results *****
  exact = 8.91238670694864
  f1 = 29.05008781834386
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 193.10s, loss = 3.453243
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.171875135708184
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 205.39s, loss = 3.413047
***** Eval results *****
  exact = 9.06344410876133
  f1 = 29.163415337122153
  total = 662
Epoch: 1, Step: 80 / 105, used_time = 217.45s, loss = 3.380471
***** Eval results *****
  exact = 8.157099697885196
  f1 = 28.07577979810768
  total = 662
Epoch: 1, Step: 90 / 105, used_time = 229.92s, loss = 3.345743
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.589739675785417
  total = 662
Epoch: 1, Step: 100 / 105, used_time = 242.30s, loss = 3.328979
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 27.78775710504778
  total = 662
Start epoch #2 (lr = 2e-05)...
Epoch: 2, Step: 10 / 105, used_time = 257.84s, loss = 3.281019
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.299414243718125
  total = 662
Epoch: 2, Step: 20 / 105, used_time = 270.20s, loss = 3.251666
***** Eval results *****
  exact = 8.91238670694864
  f1 = 29.817362637350367
  total = 662
Epoch: 2, Step: 30 / 105, used_time = 282.56s, loss = 3.219717
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.149566703105418
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 294.91s, loss = 3.198346
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.76690633384414
  total = 662
Epoch: 2, Step: 50 / 105, used_time = 307.18s, loss = 3.173211
***** Eval results *****
  exact = 9.516616314199396
  f1 = 29.56125800042384
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 319.46s, loss = 3.142455
***** Eval results *****
  exact = 8.459214501510575
  f1 = 30.085604075345774
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 331.96s, loss = 3.117154
***** Eval results *****
  exact = 9.06344410876133
  f1 = 29.95830783351423
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 344.26s, loss = 3.093667
***** Eval results *****
  exact = 9.214501510574019
  f1 = 30.132963788625545
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 356.31s, loss = 3.068373
***** Eval results *****
  exact = 9.667673716012084
  f1 = 30.708043990585594
  total = 662
Epoch: 2, Step: 100 / 105, used_time = 368.68s, loss = 3.053510
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.343483357261395
  total = 662
Start epoch #3 (lr = 2e-05)...
Epoch: 3, Step: 10 / 105, used_time = 384.48s, loss = 3.014023
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.86469553883077
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 396.89s, loss = 2.985771
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.951041661190708
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 409.23s, loss = 2.959765
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.26075138357077
  total = 662
Epoch: 3, Step: 40 / 105, used_time = 421.52s, loss = 2.938913
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.41202737196575
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 433.95s, loss = 2.916803
***** Eval results *****
  exact = 11.027190332326285
  f1 = 32.043143187972106
  total = 662
Epoch: 3, Step: 60 / 105, used_time = 446.29s, loss = 2.896616
***** Eval results *****
  exact = 9.365558912386707
  f1 = 30.961143308202114
  total = 662
Epoch: 3, Step: 70 / 105, used_time = 458.65s, loss = 2.877707
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.41107247630905
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 470.67s, loss = 2.858318
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.00579430358334
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 483.11s, loss = 2.840689
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.859366731543396
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 495.39s, loss = 2.823392
***** Eval results *****
  exact = 10.422960725075528
  f1 = 34.41420596458907
  total = 662
Start epoch #4 (lr = 2e-05)...
Epoch: 4, Step: 10 / 105, used_time = 510.95s, loss = 2.789832
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.428630356676756
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 523.36s, loss = 2.766550
***** Eval results *****
  exact = 11.178247734138973
  f1 = 33.70451014964799
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 535.75s, loss = 2.747575
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.942521989897497
  total = 662
Epoch: 4, Step: 40 / 105, used_time = 548.24s, loss = 2.726175
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.00970381582164
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 560.23s, loss = 2.704442
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.69107163254914
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 572.50s, loss = 2.686195
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.246740649815024
  total = 662
Epoch: 4, Step: 70 / 105, used_time = 584.91s, loss = 2.668637
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.0893118201225
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 597.28s, loss = 2.650182
***** Eval results *****
  exact = 10.27190332326284
  f1 = 33.143261772494675
  total = 662
Epoch: 4, Step: 90 / 105, used_time = 609.64s, loss = 2.632985
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.65562326288923
  total = 662
Epoch: 4, Step: 100 / 105, used_time = 621.99s, loss = 2.617522
***** Eval results *****
  exact = 10.725075528700906
  f1 = 34.515861801042895
  total = 662
Start epoch #5 (lr = 2e-05)...
Epoch: 5, Step: 10 / 105, used_time = 637.73s, loss = 2.587979
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.94273816110116
  total = 662
Epoch: 5, Step: 20 / 105, used_time = 650.04s, loss = 2.566042
***** Eval results *****
  exact = 10.574018126888218
  f1 = 33.4314690176162
  total = 662
Epoch: 5, Step: 30 / 105, used_time = 662.30s, loss = 2.546466
***** Eval results *****
  exact = 10.27190332326284
  f1 = 33.11531512322772
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 674.71s, loss = 2.527591
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.77065582455663
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 687.17s, loss = 2.510009
***** Eval results *****
  exact = 10.27190332326284
  f1 = 33.80734010659655
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 699.45s, loss = 2.493659
***** Eval results *****
  exact = 10.120845921450151
  f1 = 34.86862669818755
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 711.70s, loss = 2.477510
***** Eval results *****
  exact = 10.27190332326284
  f1 = 34.518365819025945
  total = 662
Epoch: 5, Step: 80 / 105, used_time = 723.57s, loss = 2.461267
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.38161575238437
  total = 662
Epoch: 5, Step: 90 / 105, used_time = 735.97s, loss = 2.443260
***** Eval results *****
  exact = 11.329305135951662
  f1 = 34.48561715074212
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 748.20s, loss = 2.429581
***** Eval results *****
  exact = 11.178247734138973
  f1 = 33.41861569824774
  total = 662
Start epoch #6 (lr = 2e-05)...
Epoch: 6, Step: 10 / 105, used_time = 763.57s, loss = 2.402920
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.8392202783529
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 775.82s, loss = 2.384858
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.56968381900598
  total = 662
Epoch: 6, Step: 30 / 105, used_time = 788.33s, loss = 2.369161
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.68603103293725
  total = 662
Epoch: 6, Step: 40 / 105, used_time = 800.64s, loss = 2.352041
***** Eval results *****
  exact = 10.876132930513595
  f1 = 33.672593467636965
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 812.91s, loss = 2.334892
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.78627810037455
  total = 662
Epoch: 6, Step: 60 / 105, used_time = 825.19s, loss = 2.317920
***** Eval results *****
  exact = 11.782477341389727
  f1 = 34.65314248689923
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 837.49s, loss = 2.302536
***** Eval results *****
  exact = 10.725075528700906
  f1 = 34.56744037759859
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 849.72s, loss = 2.287193
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.99190839376714
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 861.60s, loss = 2.272801
***** Eval results *****
  exact = 11.027190332326285
  f1 = 34.4904442711001
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 873.91s, loss = 2.260228
***** Eval results *****
  exact = 10.574018126888218
  f1 = 33.68474329304669
  total = 662
Start epoch #7 (lr = 2e-05)...
Epoch: 7, Step: 10 / 105, used_time = 889.60s, loss = 2.234105
***** Eval results *****
  exact = 12.084592145015106
  f1 = 34.85627032155492
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 901.86s, loss = 2.216280
***** Eval results *****
  exact = 11.027190332326285
  f1 = 35.1688018751169
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 914.11s, loss = 2.202097
***** Eval results *****
  exact = 11.178247734138973
  f1 = 35.022190326338155
  total = 662
Epoch: 7, Step: 40 / 105, used_time = 926.44s, loss = 2.183707
***** Eval results *****
  exact = 10.876132930513595
  f1 = 34.34749885169155
  total = 662
Epoch: 7, Step: 50 / 105, used_time = 938.86s, loss = 2.167554
***** Eval results *****
  exact = 10.876132930513595
  f1 = 34.70132994464892
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 951.07s, loss = 2.152241
***** Eval results *****
  exact = 11.178247734138973
  f1 = 34.558333513293434
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 962.98s, loss = 2.137913
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.291805700413306
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 975.28s, loss = 2.124902
***** Eval results *****
  exact = 11.178247734138973
  f1 = 33.743849045402754
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 987.55s, loss = 2.113373
***** Eval results *****
  exact = 10.27190332326284
  f1 = 33.19090384388845
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 999.93s, loss = 2.100835
***** Eval results *****
  exact = 10.876132930513595
  f1 = 32.33110973191925
  total = 662
Start epoch #8 (lr = 2e-05)...
Epoch: 8, Step: 10 / 105, used_time = 1015.48s, loss = 2.077797
***** Eval results *****
  exact = 11.178247734138973
  f1 = 33.4311567869421
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1027.74s, loss = 2.063523
***** Eval results *****
  exact = 11.027190332326285
  f1 = 34.032633538990474
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1040.13s, loss = 2.048248
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.60597015848939
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1052.41s, loss = 2.032887
***** Eval results *****
  exact = 11.329305135951662
  f1 = 33.89238685381023
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1064.39s, loss = 2.017864
***** Eval results *****
  exact = 11.48036253776435
  f1 = 33.7986759335285
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1076.70s, loss = 2.004329
***** Eval results *****
  exact = 11.329305135951662
  f1 = 34.21373927008289
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1089.14s, loss = 1.990778
***** Eval results *****
  exact = 11.63141993957704
  f1 = 33.73054116968687
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1101.42s, loss = 1.978435
***** Eval results *****
  exact = 10.574018126888218
  f1 = 33.80332496259633
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1113.73s, loss = 1.967237
***** Eval results *****
  exact = 10.120845921450151
  f1 = 34.24058009495168
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1126.12s, loss = 1.955370
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.14884586327647
  total = 662
Start epoch #9 (lr = 2e-05)...
Epoch: 9, Step: 10 / 105, used_time = 1141.97s, loss = 1.935988
***** Eval results *****
  exact = 10.574018126888218
  f1 = 33.09807730911631
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1154.29s, loss = 1.922843
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.7710544346025
  total = 662
Epoch: 9, Step: 30 / 105, used_time = 1166.57s, loss = 1.909176
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.99380118059161
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1178.92s, loss = 1.895749
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.896837237845883
  total = 662
Epoch: 9, Step: 50 / 105, used_time = 1191.19s, loss = 1.882901
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.5808995500269
  total = 662
Epoch: 9, Step: 60 / 105, used_time = 1203.73s, loss = 1.870045
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.27451471608869
  total = 662
Epoch: 9, Step: 70 / 105, used_time = 1215.94s, loss = 1.857854
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.8597682516486
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1228.18s, loss = 1.847298
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.150899658867715
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1240.59s, loss = 1.835559
***** Eval results *****
  exact = 11.027190332326285
  f1 = 33.2454631045053
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1252.97s, loss = 1.824408
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.828906978602575
  total = 662
Start epoch #10 (lr = 2e-05)...
Epoch: 10, Step: 10 / 105, used_time = 1268.23s, loss = 1.806488
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.49856437536301
  total = 662
Epoch: 10, Step: 20 / 105, used_time = 1280.60s, loss = 1.794172
***** Eval results *****
  exact = 11.027190332326285
  f1 = 33.15325305236128
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1293.04s, loss = 1.783899
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.867590178440565
  total = 662
Epoch: 10, Step: 40 / 105, used_time = 1305.28s, loss = 1.772613
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.9889859641205
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1317.58s, loss = 1.761046
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.166378365051216
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1329.85s, loss = 1.750064
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.80630807288824
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1342.11s, loss = 1.739033
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.85024752648854
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1354.45s, loss = 1.727765
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.30823127199345
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1366.39s, loss = 1.717006
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.55587310575582
  total = 662
Epoch: 10, Step: 100 / 105, used_time = 1378.69s, loss = 1.706362
***** Eval results *****
  exact = 11.027190332326285
  f1 = 32.984062591746856
  total = 662
Start epoch #11 (lr = 2e-05)...
Epoch: 11, Step: 10 / 105, used_time = 1394.35s, loss = 1.690719
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.67846882374206
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1406.67s, loss = 1.680769
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.137441119332955
  total = 662
Epoch: 11, Step: 30 / 105, used_time = 1418.94s, loss = 1.670511
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.61740316831251
  total = 662
Epoch: 11, Step: 40 / 105, used_time = 1431.18s, loss = 1.660243
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.517180210399474
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1443.50s, loss = 1.650035
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.27023278555941
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1455.74s, loss = 1.639981
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.508844807438344
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1468.02s, loss = 1.630226
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.945183517498684
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1480.03s, loss = 1.620639
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.34196291152555
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1492.30s, loss = 1.611760
***** Eval results *****
  exact = 10.574018126888218
  f1 = 33.00014586244508
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1504.74s, loss = 1.602952
***** Eval results *****
  exact = 11.027190332326285
  f1 = 33.925798734718356
  total = 662
Start epoch #12 (lr = 2e-05)...
Epoch: 12, Step: 10 / 105, used_time = 1520.23s, loss = 1.588860
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.255864559758365
  total = 662
Epoch: 12, Step: 20 / 105, used_time = 1532.50s, loss = 1.579815
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.930670723204194
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1544.52s, loss = 1.570678
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.937951951394332
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1556.77s, loss = 1.561667
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.93102193295578
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1569.01s, loss = 1.553235
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.30461830644171
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1581.24s, loss = 1.544600
***** Eval results *****
  exact = 10.876132930513595
  f1 = 32.792894349754896
  total = 662
Epoch: 12, Step: 70 / 105, used_time = 1593.62s, loss = 1.535847
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.857978216083346
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1605.89s, loss = 1.527536
***** Eval results *****
  exact = 10.574018126888218
  f1 = 31.97179745059907
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1618.13s, loss = 1.518513
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.29958161592865
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1630.39s, loss = 1.510739
***** Eval results *****
  exact = 10.27190332326284
  f1 = 32.246879049218606
  total = 662
Start epoch #13 (lr = 2e-05)...
Epoch: 13, Step: 10 / 105, used_time = 1645.91s, loss = 1.499015
***** Eval results *****
  exact = 10.876132930513595
  f1 = 32.91569142172506
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1658.32s, loss = 1.490492
***** Eval results *****
  exact = 10.27190332326284
  f1 = 31.95120538012472
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1670.59s, loss = 1.482079
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.27481985163824
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1682.91s, loss = 1.474066
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.18393446827066
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1695.37s, loss = 1.466082
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.86477435492056
  total = 662
Epoch: 13, Step: 60 / 105, used_time = 1707.64s, loss = 1.458138
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.35075161451383
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1719.94s, loss = 1.450441
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.559002288113746
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1731.84s, loss = 1.442417
***** Eval results *****
  exact = 10.574018126888218
  f1 = 32.335900809888926
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1744.23s, loss = 1.434889
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.646077590436622
  total = 662
Epoch: 13, Step: 100 / 105, used_time = 1756.60s, loss = 1.427655
***** Eval results *****
  exact = 10.574018126888218
  f1 = 33.132582946577834
  total = 662
Start epoch #14 (lr = 2e-05)...
Epoch: 14, Step: 10 / 105, used_time = 1771.71s, loss = 1.416523
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.282719465567165
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1783.81s, loss = 1.408795
***** Eval results *****
  exact = 9.516616314199396
  f1 = 30.58905610496671
  total = 662
Epoch: 14, Step: 30 / 105, used_time = 1795.84s, loss = 1.401609
***** Eval results *****
  exact = 10.27190332326284
  f1 = 31.730664837116503
  total = 662
Epoch: 14, Step: 40 / 105, used_time = 1807.91s, loss = 1.394945
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.82602378268421
  total = 662
Epoch: 14, Step: 50 / 105, used_time = 1819.87s, loss = 1.387832
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.279524888945556
  total = 662
Epoch: 14, Step: 60 / 105, used_time = 1831.85s, loss = 1.381255
***** Eval results *****
  exact = 10.574018126888218
  f1 = 31.576298566472506
  total = 662
Epoch: 14, Step: 70 / 105, used_time = 1843.93s, loss = 1.374404
***** Eval results *****
  exact = 10.27190332326284
  f1 = 31.30984379095343
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1856.06s, loss = 1.367742
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.44852393979092
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1868.40s, loss = 1.361292
***** Eval results *****
  exact = 10.27190332326284
  f1 = 32.107080024480446
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1880.68s, loss = 1.354522
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.24872574444371
  total = 662
Start epoch #15 (lr = 2e-05)...
Epoch: 15, Step: 10 / 105, used_time = 1896.28s, loss = 1.344403
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.500502707129495
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1908.50s, loss = 1.338035
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.30371603657886
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1920.82s, loss = 1.331536
***** Eval results *****
  exact = 10.725075528700906
  f1 = 32.30984123619808
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1933.08s, loss = 1.324819
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.48312982405455
  total = 662
Epoch: 15, Step: 50 / 105, used_time = 1945.36s, loss = 1.318551
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.626026708712573
  total = 662
Epoch: 15, Step: 60 / 105, used_time = 1957.77s, loss = 1.312222
***** Eval results *****
  exact = 10.27190332326284
  f1 = 32.49124495054577
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1970.01s, loss = 1.306228
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.690418898625957
  total = 662
Epoch: 15, Step: 80 / 105, used_time = 1982.27s, loss = 1.300111
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.305874028445874
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 1994.69s, loss = 1.294112
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.025243711253736
  total = 662
Epoch: 15, Step: 100 / 105, used_time = 2006.63s, loss = 1.288075
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.29635000937122
  total = 662
Start epoch #16 (lr = 2e-05)...
Epoch: 16, Step: 10 / 105, used_time = 2022.17s, loss = 1.279156
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.17276226221155
  total = 662
Epoch: 16, Step: 20 / 105, used_time = 2034.55s, loss = 1.273263
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.20670923351724
  total = 662
Epoch: 16, Step: 30 / 105, used_time = 2046.68s, loss = 1.267662
***** Eval results *****
  exact = 9.365558912386707
  f1 = 30.906925060438727
  total = 662
Epoch: 16, Step: 40 / 105, used_time = 2058.54s, loss = 1.261711
***** Eval results *****
  exact = 8.91238670694864
  f1 = 30.318283628668574
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2070.58s, loss = 1.255910
***** Eval results *****
  exact = 9.06344410876133
  f1 = 30.463869534489376
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2082.60s, loss = 1.250295
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.155845291001395
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2094.77s, loss = 1.244432
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.233944318148033
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2106.87s, loss = 1.238869
***** Eval results *****
  exact = 9.667673716012084
  f1 = 30.639749245365095
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2118.95s, loss = 1.233418
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.32952766952965
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2131.04s, loss = 1.228013
***** Eval results *****
  exact = 10.422960725075528
  f1 = 32.47796389448375
  total = 662
Start epoch #17 (lr = 2e-05)...
Epoch: 17, Step: 10 / 105, used_time = 2146.41s, loss = 1.220132
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.309096380112095
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2158.55s, loss = 1.214419
***** Eval results *****
  exact = 9.667673716012084
  f1 = 30.736147959207415
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2170.75s, loss = 1.208938
***** Eval results *****
  exact = 9.969788519637461
  f1 = 30.800381007997743
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2182.95s, loss = 1.203731
***** Eval results *****
  exact = 9.818731117824774
  f1 = 30.84509991263967
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2195.17s, loss = 1.198691
***** Eval results *****
  exact = 9.818731117824774
  f1 = 30.849530448208917
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2207.43s, loss = 1.193513
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.40511309689535
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2219.48s, loss = 1.188722
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.50554707281628
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2231.57s, loss = 1.183895
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.512898046590703
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2243.48s, loss = 1.178859
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.434948911640202
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2255.62s, loss = 1.173852
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.27478033890513
  total = 662
Start epoch #18 (lr = 2e-05)...
Epoch: 18, Step: 10 / 105, used_time = 2271.15s, loss = 1.166540
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.251755066162296
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2283.51s, loss = 1.161868
***** Eval results *****
  exact = 10.27190332326284
  f1 = 31.34067883777898
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2295.80s, loss = 1.157019
***** Eval results *****
  exact = 10.27190332326284
  f1 = 31.871963097535726
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2308.23s, loss = 1.152179
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.689309174350058
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2320.50s, loss = 1.147343
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.354251475207008
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2332.82s, loss = 1.142914
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.182653961401048
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2345.26s, loss = 1.138147
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.344380358875508
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2357.22s, loss = 1.133578
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.47639203589968
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2369.29s, loss = 1.129465
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.701062479228536
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2381.38s, loss = 1.125083
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.878910473917333
  total = 662
Start epoch #19 (lr = 2e-05)...
Epoch: 19, Step: 10 / 105, used_time = 2396.55s, loss = 1.118671
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.09397421466084
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2408.73s, loss = 1.114149
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.989238989079695
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2420.84s, loss = 1.109947
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.746175766285855
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2432.92s, loss = 1.105784
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.0508757487728
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2445.23s, loss = 1.101476
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.83111301267924
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2456.98s, loss = 1.097363
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.822720934800753
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2469.15s, loss = 1.093306
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.74719223389441
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2481.30s, loss = 1.089186
***** Eval results *****
  exact = 10.27190332326284
  f1 = 31.907149469558064
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2493.41s, loss = 1.085132
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.620281516924486
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2505.66s, loss = 1.080941
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.620281516924486
  total = 662
Start epoch #0 (lr = 3e-05)...
Epoch: 0, Step: 10 / 105, used_time = 6.13s, loss = 5.996892
***** Eval results *****
  exact = 0.0
  f1 = 15.111074315634633
  total = 662
Epoch: 0, Step: 20 / 105, used_time = 18.23s, loss = 5.826142
***** Eval results *****
  exact = 0.6042296072507553
  f1 = 20.208478773072333
  total = 662
Epoch: 0, Step: 30 / 105, used_time = 30.56s, loss = 5.467158
***** Eval results *****
  exact = 2.719033232628399
  f1 = 24.49841597231433
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.82s, loss = 4.948781
***** Eval results *****
  exact = 4.984894259818731
  f1 = 25.535827819966745
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 55.10s, loss = 4.548421
***** Eval results *****
  exact = 5.740181268882175
  f1 = 26.745673602598853
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 67.43s, loss = 4.290751
***** Eval results *****
  exact = 6.495468277945619
  f1 = 28.692426241434532
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 79.84s, loss = 4.072340
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.07129966272359
  total = 662
Epoch: 0, Step: 80 / 105, used_time = 91.72s, loss = 3.943573
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.700805460422302
  total = 662
Epoch: 0, Step: 90 / 105, used_time = 103.92s, loss = 3.852072
***** Eval results *****
  exact = 7.401812688821752
  f1 = 27.523937327027525
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 116.12s, loss = 3.762616
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.285455289336927
  total = 662
Start epoch #1 (lr = 3e-05)...
Epoch: 1, Step: 10 / 105, used_time = 131.59s, loss = 3.651194
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.86556241710243
  total = 662
Epoch: 1, Step: 20 / 105, used_time = 143.82s, loss = 3.563176
***** Eval results *****
  exact = 7.099697885196375
  f1 = 27.30370981094394
  total = 662
Epoch: 1, Step: 30 / 105, used_time = 155.80s, loss = 3.503213
***** Eval results *****
  exact = 7.854984894259819
  f1 = 27.51507089693083
  total = 662
Epoch: 1, Step: 40 / 105, used_time = 168.13s, loss = 3.441952
***** Eval results *****
  exact = 8.157099697885196
  f1 = 27.854879881302654
  total = 662
Epoch: 1, Step: 50 / 105, used_time = 180.57s, loss = 3.395532
***** Eval results *****
  exact = 8.91238670694864
  f1 = 28.845568602835687
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 192.93s, loss = 3.349554
***** Eval results *****
  exact = 8.006042296072508
  f1 = 27.85140756801197
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 205.24s, loss = 3.318287
***** Eval results *****
  exact = 8.610271903323262
  f1 = 28.808797356402252
  total = 662
Epoch: 1, Step: 80 / 105, used_time = 217.53s, loss = 3.284199
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 28.296668231009857
  total = 662
Epoch: 1, Step: 90 / 105, used_time = 229.82s, loss = 3.263006
***** Eval results *****
  exact = 9.06344410876133
  f1 = 29.320294662645594
  total = 662
Epoch: 1, Step: 100 / 105, used_time = 242.04s, loss = 3.239431
***** Eval results *****
  exact = 8.459214501510575
  f1 = 27.940566344626177
  total = 662
Start epoch #2 (lr = 3e-05)...
Epoch: 2, Step: 10 / 105, used_time = 257.48s, loss = 3.187062
***** Eval results *****
  exact = 9.214501510574019
  f1 = 30.96647320730952
  total = 662
Epoch: 2, Step: 20 / 105, used_time = 269.80s, loss = 3.161219
***** Eval results *****
  exact = 9.06344410876133
  f1 = 30.85933597803886
  total = 662
Epoch: 2, Step: 30 / 105, used_time = 282.27s, loss = 3.130088
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.47719506227546
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 294.68s, loss = 3.109159
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.794761221186775
  total = 662
Epoch: 2, Step: 50 / 105, used_time = 306.69s, loss = 3.085386
***** Eval results *****
  exact = 8.91238670694864
  f1 = 29.42995853021295
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 319.01s, loss = 3.067007
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.99412256395429
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 331.31s, loss = 3.039392
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.27557226981211
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 343.31s, loss = 3.013236
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.1660991652401
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 355.40s, loss = 2.988560
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.58893959608354
  total = 662
Epoch: 2, Step: 100 / 105, used_time = 367.65s, loss = 2.970631
***** Eval results *****
  exact = 8.308157099697885
  f1 = 30.35297428624952
  total = 662
Start epoch #3 (lr = 3e-05)...
Epoch: 3, Step: 10 / 105, used_time = 383.38s, loss = 2.938213
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.3172021257693
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 395.29s, loss = 2.911977
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.39284512951771
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 407.53s, loss = 2.881842
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.58426110616993
  total = 662
Epoch: 3, Step: 40 / 105, used_time = 419.85s, loss = 2.853731
***** Eval results *****
  exact = 10.27190332326284
  f1 = 33.03775694037318
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 432.14s, loss = 2.829943
***** Eval results *****
  exact = 11.178247734138973
  f1 = 34.493349467168315
  total = 662
Epoch: 3, Step: 60 / 105, used_time = 444.42s, loss = 2.810754
***** Eval results *****
  exact = 11.48036253776435
  f1 = 34.54392934984573
  total = 662
Epoch: 3, Step: 70 / 105, used_time = 456.70s, loss = 2.788787
***** Eval results *****
  exact = 11.178247734138973
  f1 = 34.78619894609993
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 469.00s, loss = 2.769509
***** Eval results *****
  exact = 11.48036253776435
  f1 = 34.94691372410509
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 481.36s, loss = 2.755426
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.01630218310478
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 493.58s, loss = 2.737291
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.40606105574243
  total = 662
Start epoch #4 (lr = 3e-05)...
Epoch: 4, Step: 10 / 105, used_time = 509.02s, loss = 2.700252
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.50488832668221
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 521.27s, loss = 2.674832
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.62887653478316
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 533.70s, loss = 2.647363
***** Eval results *****
  exact = 11.48036253776435
  f1 = 35.794257680790324
  total = 662
!!! Best dev f1 (lr=3e-05, epoch=4): 35.79
Epoch: 4, Step: 40 / 105, used_time = 547.21s, loss = 2.621821
***** Eval results *****
  exact = 11.027190332326285
  f1 = 34.8526171062353
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 559.66s, loss = 2.601966
***** Eval results *****
  exact = 11.782477341389727
  f1 = 35.0307328595885
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 571.95s, loss = 2.578935
***** Eval results *****
  exact = 10.27190332326284
  f1 = 33.84369256181144
  total = 662
Epoch: 4, Step: 70 / 105, used_time = 584.02s, loss = 2.563281
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.52775281566114
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 596.29s, loss = 2.544369
***** Eval results *****
  exact = 10.876132930513595
  f1 = 35.22780955703347
  total = 662
Epoch: 4, Step: 90 / 105, used_time = 608.63s, loss = 2.525850
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.98368531012206
  total = 662
Epoch: 4, Step: 100 / 105, used_time = 620.85s, loss = 2.507877
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.72087488246093
  total = 662
Start epoch #5 (lr = 3e-05)...
Epoch: 5, Step: 10 / 105, used_time = 636.39s, loss = 2.477335
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.39542178757009
  total = 662
Epoch: 5, Step: 20 / 105, used_time = 648.45s, loss = 2.452941
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.072133018558446
  total = 662
Epoch: 5, Step: 30 / 105, used_time = 660.50s, loss = 2.431890
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.6501914068654
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 672.49s, loss = 2.409644
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.4035952315664
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 684.67s, loss = 2.388905
***** Eval results *****
  exact = 10.876132930513595
  f1 = 35.30680579381883
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 696.62s, loss = 2.370288
***** Eval results *****
  exact = 11.178247734138973
  f1 = 35.60213157909538
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 708.84s, loss = 2.352303
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.23678041801469
  total = 662
Epoch: 5, Step: 80 / 105, used_time = 721.11s, loss = 2.334081
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.62403464392086
  total = 662
Epoch: 5, Step: 90 / 105, used_time = 733.46s, loss = 2.316683
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.52006933108659
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 745.62s, loss = 2.297352
***** Eval results *****
  exact = 10.725075528700906
  f1 = 34.74305916923556
  total = 662
Start epoch #6 (lr = 3e-05)...
Epoch: 6, Step: 10 / 105, used_time = 761.01s, loss = 2.268676
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.08807864155796
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 773.12s, loss = 2.246699
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.40553118484569
  total = 662
Epoch: 6, Step: 30 / 105, used_time = 785.41s, loss = 2.226114
***** Eval results *****
  exact = 9.365558912386707
  f1 = 35.125239890916575
  total = 662
Epoch: 6, Step: 40 / 105, used_time = 797.74s, loss = 2.207088
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.62875222725623
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 809.74s, loss = 2.189040
***** Eval results *****
  exact = 9.969788519637461
  f1 = 34.49614230172165
  total = 662
Epoch: 6, Step: 60 / 105, used_time = 822.01s, loss = 2.169580
***** Eval results *****
  exact = 9.516616314199396
  f1 = 34.252311753317954
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 834.36s, loss = 2.151755
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.91036341766142
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 846.53s, loss = 2.135912
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.34637754519201
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 858.80s, loss = 2.118692
***** Eval results *****
  exact = 8.308157099697885
  f1 = 33.1134885467327
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 871.05s, loss = 2.102481
***** Eval results *****
  exact = 8.459214501510575
  f1 = 32.09836407605134
  total = 662
Start epoch #7 (lr = 3e-05)...
Epoch: 7, Step: 10 / 105, used_time = 886.59s, loss = 2.076045
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.68517778906802
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 898.95s, loss = 2.057113
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.538807202085756
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 911.25s, loss = 2.037957
***** Eval results *****
  exact = 8.308157099697885
  f1 = 32.338867803656775
  total = 662
Epoch: 7, Step: 40 / 105, used_time = 923.40s, loss = 2.019444
***** Eval results *****
  exact = 7.552870090634441
  f1 = 31.32336958575983
  total = 662
Epoch: 7, Step: 50 / 105, used_time = 935.53s, loss = 2.003412
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.551245328917624
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 947.88s, loss = 1.986964
***** Eval results *****
  exact = 8.006042296072508
  f1 = 32.500613909150104
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 959.86s, loss = 1.971059
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.220255072722736
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 972.07s, loss = 1.955954
***** Eval results *****
  exact = 8.157099697885196
  f1 = 32.01719309340263
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 984.43s, loss = 1.940559
***** Eval results *****
  exact = 8.459214501510575
  f1 = 32.652204431679095
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 996.58s, loss = 1.926068
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.91618794828521
  total = 662
Start epoch #8 (lr = 3e-05)...
Epoch: 8, Step: 10 / 105, used_time = 1011.89s, loss = 1.902147
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.295996596513255
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1024.04s, loss = 1.885558
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.81011087161615
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1036.29s, loss = 1.870269
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.233967718118546
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1048.43s, loss = 1.854488
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.64764008270973
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1060.41s, loss = 1.838777
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.64435315452455
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1072.37s, loss = 1.824536
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.490811675040895
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1084.55s, loss = 1.810015
***** Eval results *****
  exact = 9.214501510574019
  f1 = 33.2071616975031
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1096.20s, loss = 1.795581
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.99389663665028
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1108.11s, loss = 1.781914
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.486702192082475
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1120.00s, loss = 1.768515
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.16873289735647
  total = 662
Start epoch #9 (lr = 3e-05)...
Epoch: 9, Step: 10 / 105, used_time = 1135.15s, loss = 1.747211
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.72870183779192
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1147.08s, loss = 1.732842
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.554753325139043
  total = 662
Epoch: 9, Step: 30 / 105, used_time = 1159.02s, loss = 1.719684
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.884198985210283
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1171.00s, loss = 1.706393
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.605613005958066
  total = 662
Epoch: 9, Step: 50 / 105, used_time = 1183.02s, loss = 1.693749
***** Eval results *****
  exact = 8.006042296072508
  f1 = 31.51623242739676
  total = 662
Epoch: 9, Step: 60 / 105, used_time = 1195.01s, loss = 1.681529
***** Eval results *****
  exact = 9.06344410876133
  f1 = 33.480434803598875
  total = 662
Epoch: 9, Step: 70 / 105, used_time = 1207.03s, loss = 1.668149
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.05097253714014
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1218.97s, loss = 1.655958
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.2921362185017
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1230.71s, loss = 1.643559
***** Eval results *****
  exact = 8.006042296072508
  f1 = 31.839634946265086
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1242.70s, loss = 1.631015
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.16387210478733
  total = 662
Start epoch #10 (lr = 3e-05)...
Epoch: 10, Step: 10 / 105, used_time = 1257.81s, loss = 1.612907
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.901939552160893
  total = 662
Epoch: 10, Step: 20 / 105, used_time = 1269.77s, loss = 1.600533
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.68119873124853
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1281.84s, loss = 1.588121
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.832538641916965
  total = 662
Epoch: 10, Step: 40 / 105, used_time = 1293.92s, loss = 1.576578
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.01211624103891
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1305.65s, loss = 1.564770
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.627758877916108
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1317.91s, loss = 1.553736
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.713520416619204
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1330.28s, loss = 1.542873
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.532477087698155
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1342.58s, loss = 1.532020
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.76587010573604
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1354.81s, loss = 1.521427
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.250208658740256
  total = 662
Epoch: 10, Step: 100 / 105, used_time = 1367.05s, loss = 1.511086
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.44387187230046
  total = 662
Start epoch #11 (lr = 3e-05)...
Epoch: 11, Step: 10 / 105, used_time = 1382.59s, loss = 1.495653
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.523210020889426
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1394.88s, loss = 1.484921
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.887798248284412
  total = 662
Epoch: 11, Step: 30 / 105, used_time = 1407.02s, loss = 1.474938
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.611693003797264
  total = 662
Epoch: 11, Step: 40 / 105, used_time = 1419.21s, loss = 1.464748
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.660929535042857
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1431.45s, loss = 1.454827
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.62140046300774
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1443.54s, loss = 1.444796
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.435801299318186
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1455.33s, loss = 1.436303
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.073738662430564
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1467.55s, loss = 1.426533
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.84280209628217
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1479.92s, loss = 1.417615
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.07061779547098
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1492.21s, loss = 1.408786
***** Eval results *****
  exact = 10.725075528700906
  f1 = 33.70397563599852
  total = 662
Start epoch #12 (lr = 3e-05)...
Epoch: 12, Step: 10 / 105, used_time = 1507.46s, loss = 1.394891
***** Eval results *****
  exact = 10.27190332326284
  f1 = 33.75557449811707
  total = 662
Epoch: 12, Step: 20 / 105, used_time = 1519.49s, loss = 1.385914
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.93802064028383
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1531.54s, loss = 1.376822
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.37741408540248
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1543.87s, loss = 1.368215
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.56255281838061
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1556.16s, loss = 1.359290
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.771496354435335
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1568.33s, loss = 1.350698
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.79484826107782
  total = 662
Epoch: 12, Step: 70 / 105, used_time = 1580.57s, loss = 1.342108
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.933061603796865
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1592.68s, loss = 1.333980
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.89135471597116
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1604.84s, loss = 1.325700
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.660805713719405
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1617.05s, loss = 1.317773
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.55581543370664
  total = 662
Start epoch #13 (lr = 3e-05)...
Epoch: 13, Step: 10 / 105, used_time = 1632.18s, loss = 1.305941
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.232525456927696
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1644.52s, loss = 1.298347
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.75303623614757
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1656.75s, loss = 1.290722
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.993617703224825
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1669.06s, loss = 1.283100
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.33225489013713
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1681.36s, loss = 1.275564
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.48888181728166
  total = 662
Epoch: 13, Step: 60 / 105, used_time = 1693.58s, loss = 1.268123
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.827096282417436
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1705.77s, loss = 1.261128
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.339010950441114
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1717.95s, loss = 1.253326
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.588908283416398
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1730.22s, loss = 1.246250
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.76754553943087
  total = 662
Epoch: 13, Step: 100 / 105, used_time = 1742.40s, loss = 1.239323
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.99147884662231
  total = 662
Start epoch #14 (lr = 3e-05)...
Epoch: 14, Step: 10 / 105, used_time = 1757.48s, loss = 1.228375
***** Eval results *****
  exact = 9.06344410876133
  f1 = 30.739261958003897
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1769.72s, loss = 1.221603
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.195372142267797
  total = 662
Epoch: 14, Step: 30 / 105, used_time = 1781.91s, loss = 1.214443
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.160569801868537
  total = 662
Epoch: 14, Step: 40 / 105, used_time = 1794.11s, loss = 1.207626
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.406500969534783
  total = 662
Epoch: 14, Step: 50 / 105, used_time = 1806.25s, loss = 1.200822
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.875983755026027
  total = 662
Epoch: 14, Step: 60 / 105, used_time = 1818.41s, loss = 1.194089
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.7338089987547
  total = 662
Epoch: 14, Step: 70 / 105, used_time = 1830.53s, loss = 1.187720
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.23417533770883
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1842.69s, loss = 1.181412
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.25049156645738
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1854.86s, loss = 1.174902
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.721623483137925
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1867.00s, loss = 1.168687
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.773058869349374
  total = 662
Start epoch #15 (lr = 3e-05)...
Epoch: 15, Step: 10 / 105, used_time = 1882.48s, loss = 1.159455
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.391121912950194
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1894.62s, loss = 1.153230
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.22582776612465
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1906.78s, loss = 1.146710
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.5278188576617
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1918.48s, loss = 1.140534
***** Eval results *****
  exact = 8.91238670694864
  f1 = 30.803432817257534
  total = 662
Epoch: 15, Step: 50 / 105, used_time = 1930.64s, loss = 1.134554
***** Eval results *****
  exact = 8.91238670694864
  f1 = 30.986522731195116
  total = 662
Epoch: 15, Step: 60 / 105, used_time = 1942.65s, loss = 1.128830
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.72268512469843
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1954.69s, loss = 1.123438
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.79141506267276
  total = 662
Epoch: 15, Step: 80 / 105, used_time = 1966.65s, loss = 1.117830
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.505966120733593
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 1978.74s, loss = 1.112268
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.227909191531992
  total = 662
Epoch: 15, Step: 100 / 105, used_time = 1990.73s, loss = 1.106518
***** Eval results *****
  exact = 9.06344410876133
  f1 = 30.931026830298173
  total = 662
Start epoch #16 (lr = 3e-05)...
Epoch: 16, Step: 10 / 105, used_time = 2005.88s, loss = 1.098206
***** Eval results *****
  exact = 8.91238670694864
  f1 = 30.610591832500873
  total = 662
Epoch: 16, Step: 20 / 105, used_time = 2017.99s, loss = 1.092824
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.313205947917485
  total = 662
Epoch: 16, Step: 30 / 105, used_time = 2030.13s, loss = 1.087392
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.900836394820086
  total = 662
Epoch: 16, Step: 40 / 105, used_time = 2042.10s, loss = 1.081829
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.343584595106282
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2053.72s, loss = 1.076642
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.24188753040442
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2065.76s, loss = 1.071219
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.528549664644636
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2077.82s, loss = 1.065916
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.11057423221038
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2089.86s, loss = 1.060999
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.999423257935753
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2101.86s, loss = 1.055785
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.47975767193067
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2113.80s, loss = 1.050564
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.02204513016556
  total = 662
Start epoch #17 (lr = 3e-05)...
Epoch: 17, Step: 10 / 105, used_time = 2128.96s, loss = 1.043168
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.09571343920201
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2140.94s, loss = 1.038209
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.21701177031174
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2152.61s, loss = 1.033056
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.871986328876325
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2164.54s, loss = 1.028044
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.11858207605542
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2176.61s, loss = 1.023322
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.328361509956615
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2188.72s, loss = 1.018683
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.926289378163506
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2200.90s, loss = 1.013861
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.91166788632283
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2213.10s, loss = 1.009194
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.72664986655286
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2225.13s, loss = 1.004810
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.45343932315695
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2237.36s, loss = 1.000127
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.400581771645733
  total = 662
Start epoch #18 (lr = 3e-05)...
Epoch: 18, Step: 10 / 105, used_time = 2252.45s, loss = 0.993084
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.161202583189812
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2264.45s, loss = 0.988813
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.688624513191094
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2276.49s, loss = 0.984500
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.785858084220376
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2288.54s, loss = 0.980078
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.659988211945993
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2300.10s, loss = 0.975644
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.689275024527515
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2312.19s, loss = 0.971499
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.85097573028382
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2324.18s, loss = 0.967318
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.917909447984844
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2336.26s, loss = 0.963107
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.84081342839032
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2348.43s, loss = 0.959033
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.625930981413084
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2360.70s, loss = 0.954873
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.485898839703022
  total = 662
Start epoch #19 (lr = 3e-05)...
Epoch: 19, Step: 10 / 105, used_time = 2376.03s, loss = 0.948609
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.580533627900824
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2388.20s, loss = 0.944637
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.60271681473658
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2400.26s, loss = 0.940670
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.489060783247822
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2412.31s, loss = 0.936569
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.322432962087777
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2424.36s, loss = 0.932789
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.153854389935482
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2436.39s, loss = 0.928730
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.153854389935482
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2448.07s, loss = 0.924863
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.068907552722784
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2460.18s, loss = 0.921002
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.211799689572622
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2472.12s, loss = 0.917283
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.223497737524447
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2484.11s, loss = 0.913604
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.223497737524447
  total = 662
Start epoch #0 (lr = 5e-05)...
Epoch: 0, Step: 10 / 105, used_time = 6.11s, loss = 5.922102
***** Eval results *****
  exact = 0.7552870090634441
  f1 = 19.92517163136979
  total = 662
Epoch: 0, Step: 20 / 105, used_time = 18.33s, loss = 5.625524
***** Eval results *****
  exact = 0.6042296072507553
  f1 = 21.96391350125724
  total = 662
Epoch: 0, Step: 30 / 105, used_time = 30.49s, loss = 5.075198
***** Eval results *****
  exact = 3.1722054380664653
  f1 = 22.56980585321148
  total = 662
Epoch: 0, Step: 40 / 105, used_time = 42.74s, loss = 4.591341
***** Eval results *****
  exact = 4.531722054380665
  f1 = 25.042103740774
  total = 662
Epoch: 0, Step: 50 / 105, used_time = 54.92s, loss = 4.257674
***** Eval results *****
  exact = 6.948640483383686
  f1 = 25.813488135215977
  total = 662
Epoch: 0, Step: 60 / 105, used_time = 67.13s, loss = 4.020916
***** Eval results *****
  exact = 6.193353474320242
  f1 = 26.946880154829955
  total = 662
Epoch: 0, Step: 70 / 105, used_time = 79.40s, loss = 3.872981
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 26.78076140793266
  total = 662
Epoch: 0, Step: 80 / 105, used_time = 91.76s, loss = 3.768649
***** Eval results *****
  exact = 6.948640483383686
  f1 = 26.452915808864798
  total = 662
Epoch: 0, Step: 90 / 105, used_time = 103.81s, loss = 3.670650
***** Eval results *****
  exact = 8.610271903323262
  f1 = 26.90813961566768
  total = 662
Epoch: 0, Step: 100 / 105, used_time = 116.11s, loss = 3.591575
***** Eval results *****
  exact = 7.7039274924471295
  f1 = 27.072202285781767
  total = 662
Start epoch #1 (lr = 5e-05)...
Epoch: 1, Step: 10 / 105, used_time = 131.34s, loss = 3.456263
***** Eval results *****
  exact = 6.3444108761329305
  f1 = 27.684024256117862
  total = 662
Epoch: 1, Step: 20 / 105, used_time = 143.50s, loss = 3.392987
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.198976640753347
  total = 662
Epoch: 1, Step: 30 / 105, used_time = 155.55s, loss = 3.334234
***** Eval results *****
  exact = 7.2507552870090635
  f1 = 27.16309328863318
  total = 662
Epoch: 1, Step: 40 / 105, used_time = 167.80s, loss = 3.291237
***** Eval results *****
  exact = 8.006042296072508
  f1 = 28.566336628338792
  total = 662
Epoch: 1, Step: 50 / 105, used_time = 179.85s, loss = 3.251509
***** Eval results *****
  exact = 8.157099697885196
  f1 = 29.21302761539052
  total = 662
Epoch: 1, Step: 60 / 105, used_time = 191.56s, loss = 3.225668
***** Eval results *****
  exact = 7.552870090634441
  f1 = 27.926681248637852
  total = 662
Epoch: 1, Step: 70 / 105, used_time = 203.73s, loss = 3.210740
***** Eval results *****
  exact = 8.308157099697885
  f1 = 27.431562388332768
  total = 662
Epoch: 1, Step: 80 / 105, used_time = 215.86s, loss = 3.182284
***** Eval results *****
  exact = 8.610271903323262
  f1 = 28.55948723065013
  total = 662
Epoch: 1, Step: 90 / 105, used_time = 227.93s, loss = 3.157838
***** Eval results *****
  exact = 8.459214501510575
  f1 = 29.82486773845841
  total = 662
Epoch: 1, Step: 100 / 105, used_time = 240.10s, loss = 3.146813
***** Eval results *****
  exact = 8.91238670694864
  f1 = 29.105409734548758
  total = 662
Start epoch #2 (lr = 5e-05)...
Epoch: 2, Step: 10 / 105, used_time = 255.57s, loss = 3.095118
***** Eval results *****
  exact = 9.818731117824774
  f1 = 30.33000577066528
  total = 662
Epoch: 2, Step: 20 / 105, used_time = 267.71s, loss = 3.063693
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.961576287371322
  total = 662
Epoch: 2, Step: 30 / 105, used_time = 279.72s, loss = 3.032438
***** Eval results *****
  exact = 9.516616314199396
  f1 = 30.722861411356124
  total = 662
Epoch: 2, Step: 40 / 105, used_time = 291.78s, loss = 3.003435
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.65319458338857
  total = 662
Epoch: 2, Step: 50 / 105, used_time = 303.97s, loss = 2.981069
***** Eval results *****
  exact = 8.761329305135952
  f1 = 30.957727214647825
  total = 662
Epoch: 2, Step: 60 / 105, used_time = 316.05s, loss = 2.963135
***** Eval results *****
  exact = 10.422960725075528
  f1 = 31.323749338723132
  total = 662
Epoch: 2, Step: 70 / 105, used_time = 328.20s, loss = 2.947485
***** Eval results *****
  exact = 8.006042296072508
  f1 = 31.460448488367298
  total = 662
Epoch: 2, Step: 80 / 105, used_time = 340.04s, loss = 2.941078
***** Eval results *****
  exact = 7.401812688821752
  f1 = 28.416648401946077
  total = 662
Epoch: 2, Step: 90 / 105, used_time = 352.21s, loss = 2.920728
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.8362148469102
  total = 662
Epoch: 2, Step: 100 / 105, used_time = 364.54s, loss = 2.900906
***** Eval results *****
  exact = 8.761329305135952
  f1 = 32.7324761042738
  total = 662
Start epoch #3 (lr = 5e-05)...
Epoch: 3, Step: 10 / 105, used_time = 379.53s, loss = 2.872956
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.985662052316034
  total = 662
Epoch: 3, Step: 20 / 105, used_time = 391.71s, loss = 2.841350
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.10381338996575
  total = 662
Epoch: 3, Step: 30 / 105, used_time = 404.08s, loss = 2.813451
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.793985316163905
  total = 662
Epoch: 3, Step: 40 / 105, used_time = 416.41s, loss = 2.791732
***** Eval results *****
  exact = 11.329305135951662
  f1 = 34.22992952335739
  total = 662
Epoch: 3, Step: 50 / 105, used_time = 428.78s, loss = 2.764263
***** Eval results *****
  exact = 11.178247734138973
  f1 = 33.70906507243153
  total = 662
Epoch: 3, Step: 60 / 105, used_time = 441.12s, loss = 2.742762
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.25331667249395
  total = 662
Epoch: 3, Step: 70 / 105, used_time = 453.59s, loss = 2.721494
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.55013771928894
  total = 662
Epoch: 3, Step: 80 / 105, used_time = 465.76s, loss = 2.702175
***** Eval results *****
  exact = 11.027190332326285
  f1 = 33.85790725069375
  total = 662
Epoch: 3, Step: 90 / 105, used_time = 478.06s, loss = 2.687318
***** Eval results *****
  exact = 12.83987915407855
  f1 = 34.89580832326096
  total = 662
Epoch: 3, Step: 100 / 105, used_time = 490.39s, loss = 2.670430
***** Eval results *****
  exact = 12.688821752265861
  f1 = 35.182215040660395
  total = 662
Start epoch #4 (lr = 5e-05)...
Epoch: 4, Step: 10 / 105, used_time = 505.95s, loss = 2.633287
***** Eval results *****
  exact = 11.027190332326285
  f1 = 33.92855400146878
  total = 662
Epoch: 4, Step: 20 / 105, used_time = 518.26s, loss = 2.607769
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.31024460974993
  total = 662
Epoch: 4, Step: 30 / 105, used_time = 530.39s, loss = 2.579606
***** Eval results *****
  exact = 11.178247734138973
  f1 = 33.81547280753638
  total = 662
Epoch: 4, Step: 40 / 105, used_time = 542.51s, loss = 2.554260
***** Eval results *****
  exact = 8.610271903323262
  f1 = 32.080998107881165
  total = 662
Epoch: 4, Step: 50 / 105, used_time = 554.72s, loss = 2.538214
***** Eval results *****
  exact = 11.178247734138973
  f1 = 34.82619114702738
  total = 662
Epoch: 4, Step: 60 / 105, used_time = 566.83s, loss = 2.515340
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.77591709117809
  total = 662
Epoch: 4, Step: 70 / 105, used_time = 578.57s, loss = 2.494079
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.54053310008331
  total = 662
Epoch: 4, Step: 80 / 105, used_time = 590.67s, loss = 2.475130
***** Eval results *****
  exact = 11.329305135951662
  f1 = 35.61482113635579
  total = 662
Epoch: 4, Step: 90 / 105, used_time = 602.89s, loss = 2.454609
***** Eval results *****
  exact = 10.422960725075528
  f1 = 33.23915618173327
  total = 662
Epoch: 4, Step: 100 / 105, used_time = 614.92s, loss = 2.435723
***** Eval results *****
  exact = 9.969788519637461
  f1 = 33.38047730733473
  total = 662
Start epoch #5 (lr = 5e-05)...
Epoch: 5, Step: 10 / 105, used_time = 630.13s, loss = 2.400522
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.654917843232155
  total = 662
Epoch: 5, Step: 20 / 105, used_time = 642.31s, loss = 2.375224
***** Eval results *****
  exact = 8.308157099697885
  f1 = 31.834079973411768
  total = 662
Epoch: 5, Step: 30 / 105, used_time = 654.63s, loss = 2.348246
***** Eval results *****
  exact = 8.459214501510575
  f1 = 32.228739497566295
  total = 662
Epoch: 5, Step: 40 / 105, used_time = 666.78s, loss = 2.324639
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.54036728852366
  total = 662
Epoch: 5, Step: 50 / 105, used_time = 678.93s, loss = 2.302980
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.31728519919548
  total = 662
Epoch: 5, Step: 60 / 105, used_time = 691.25s, loss = 2.284398
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.22268549228304
  total = 662
Epoch: 5, Step: 70 / 105, used_time = 703.90s, loss = 2.262351
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.013356063932626
  total = 662
Epoch: 5, Step: 80 / 105, used_time = 716.14s, loss = 2.240444
***** Eval results *****
  exact = 10.574018126888218
  f1 = 34.378850439709275
  total = 662
Epoch: 5, Step: 90 / 105, used_time = 728.43s, loss = 2.220899
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.599397143795215
  total = 662
Epoch: 5, Step: 100 / 105, used_time = 740.70s, loss = 2.204251
***** Eval results *****
  exact = 10.120845921450151
  f1 = 35.012887721615236
  total = 662
Start epoch #6 (lr = 5e-05)...
Epoch: 6, Step: 10 / 105, used_time = 756.16s, loss = 2.171577
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.48023939711356
  total = 662
Epoch: 6, Step: 20 / 105, used_time = 768.34s, loss = 2.149901
***** Eval results *****
  exact = 9.818731117824774
  f1 = 34.010966965561806
  total = 662
Epoch: 6, Step: 30 / 105, used_time = 780.43s, loss = 2.127471
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.77860326521217
  total = 662
Epoch: 6, Step: 40 / 105, used_time = 792.50s, loss = 2.105933
***** Eval results *****
  exact = 8.610271903323262
  f1 = 33.27875192246575
  total = 662
Epoch: 6, Step: 50 / 105, used_time = 804.66s, loss = 2.085406
***** Eval results *****
  exact = 8.761329305135952
  f1 = 33.22008958250897
  total = 662
Epoch: 6, Step: 60 / 105, used_time = 816.35s, loss = 2.063702
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.707459148632246
  total = 662
Epoch: 6, Step: 70 / 105, used_time = 828.29s, loss = 2.045017
***** Eval results *****
  exact = 8.308157099697885
  f1 = 32.197827855528004
  total = 662
Epoch: 6, Step: 80 / 105, used_time = 840.32s, loss = 2.027735
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.21603656875679
  total = 662
Epoch: 6, Step: 90 / 105, used_time = 852.33s, loss = 2.009194
***** Eval results *****
  exact = 9.969788519637461
  f1 = 34.266870908533285
  total = 662
Epoch: 6, Step: 100 / 105, used_time = 864.58s, loss = 1.992122
***** Eval results *****
  exact = 8.91238670694864
  f1 = 33.37573846066146
  total = 662
Start epoch #7 (lr = 5e-05)...
Epoch: 7, Step: 10 / 105, used_time = 879.92s, loss = 1.965110
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.6966998378343
  total = 662
Epoch: 7, Step: 20 / 105, used_time = 892.06s, loss = 1.947103
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.83181022178394
  total = 662
Epoch: 7, Step: 30 / 105, used_time = 904.31s, loss = 1.927907
***** Eval results *****
  exact = 9.818731117824774
  f1 = 33.67011133453529
  total = 662
Epoch: 7, Step: 40 / 105, used_time = 916.41s, loss = 1.909478
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.43961343233212
  total = 662
Epoch: 7, Step: 50 / 105, used_time = 928.51s, loss = 1.891640
***** Eval results *****
  exact = 8.761329305135952
  f1 = 31.96867634637751
  total = 662
Epoch: 7, Step: 60 / 105, used_time = 940.73s, loss = 1.874530
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.59536162772127
  total = 662
Epoch: 7, Step: 70 / 105, used_time = 953.11s, loss = 1.858540
***** Eval results *****
  exact = 9.818731117824774
  f1 = 35.328285243415095
  total = 662
Epoch: 7, Step: 80 / 105, used_time = 964.96s, loss = 1.841431
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.30527802287336
  total = 662
Epoch: 7, Step: 90 / 105, used_time = 977.09s, loss = 1.824637
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.71433759805059
  total = 662
Epoch: 7, Step: 100 / 105, used_time = 989.23s, loss = 1.808324
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.46298700861716
  total = 662
Start epoch #8 (lr = 5e-05)...
Epoch: 8, Step: 10 / 105, used_time = 1004.67s, loss = 1.783041
***** Eval results *****
  exact = 8.610271903323262
  f1 = 30.908856862849298
  total = 662
Epoch: 8, Step: 20 / 105, used_time = 1016.45s, loss = 1.765894
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.53805917513028
  total = 662
Epoch: 8, Step: 30 / 105, used_time = 1028.54s, loss = 1.750056
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.455959277449715
  total = 662
Epoch: 8, Step: 40 / 105, used_time = 1040.67s, loss = 1.734409
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.35405428223349
  total = 662
Epoch: 8, Step: 50 / 105, used_time = 1053.01s, loss = 1.720205
***** Eval results *****
  exact = 9.365558912386707
  f1 = 34.36413854077949
  total = 662
Epoch: 8, Step: 60 / 105, used_time = 1065.15s, loss = 1.705429
***** Eval results *****
  exact = 9.667673716012084
  f1 = 34.263379873574
  total = 662
Epoch: 8, Step: 70 / 105, used_time = 1077.30s, loss = 1.690743
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.227200279233767
  total = 662
Epoch: 8, Step: 80 / 105, used_time = 1089.39s, loss = 1.675641
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.49732841152208
  total = 662
Epoch: 8, Step: 90 / 105, used_time = 1101.45s, loss = 1.662415
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.006143954855546
  total = 662
Epoch: 8, Step: 100 / 105, used_time = 1113.68s, loss = 1.648302
***** Eval results *****
  exact = 9.365558912386707
  f1 = 33.59124107710226
  total = 662
Start epoch #9 (lr = 5e-05)...
Epoch: 9, Step: 10 / 105, used_time = 1129.01s, loss = 1.627208
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.7863457839451
  total = 662
Epoch: 9, Step: 20 / 105, used_time = 1141.23s, loss = 1.613258
***** Eval results *****
  exact = 9.516616314199396
  f1 = 33.27488224474624
  total = 662
Epoch: 9, Step: 30 / 105, used_time = 1153.42s, loss = 1.599018
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.82856741578885
  total = 662
Epoch: 9, Step: 40 / 105, used_time = 1165.63s, loss = 1.585788
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.926268710515206
  total = 662
Epoch: 9, Step: 50 / 105, used_time = 1177.39s, loss = 1.572358
***** Eval results *****
  exact = 9.667673716012084
  f1 = 33.27089022264885
  total = 662
Epoch: 9, Step: 60 / 105, used_time = 1189.63s, loss = 1.559684
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.22194298722085
  total = 662
Epoch: 9, Step: 70 / 105, used_time = 1202.06s, loss = 1.546872
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.50001076215902
  total = 662
Epoch: 9, Step: 80 / 105, used_time = 1214.30s, loss = 1.534734
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.14001856554582
  total = 662
Epoch: 9, Step: 90 / 105, used_time = 1226.52s, loss = 1.523078
***** Eval results *****
  exact = 8.91238670694864
  f1 = 30.843774928393145
  total = 662
Epoch: 9, Step: 100 / 105, used_time = 1238.78s, loss = 1.511504
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.852888224809654
  total = 662
Start epoch #10 (lr = 5e-05)...
Epoch: 10, Step: 10 / 105, used_time = 1254.35s, loss = 1.493309
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.75174254891952
  total = 662
Epoch: 10, Step: 20 / 105, used_time = 1266.65s, loss = 1.481087
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.663572693799658
  total = 662
Epoch: 10, Step: 30 / 105, used_time = 1278.94s, loss = 1.469636
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.49510482321873
  total = 662
Epoch: 10, Step: 40 / 105, used_time = 1290.85s, loss = 1.457835
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.35148871419562
  total = 662
Epoch: 10, Step: 50 / 105, used_time = 1303.05s, loss = 1.446689
***** Eval results *****
  exact = 8.157099697885196
  f1 = 30.70075718508061
  total = 662
Epoch: 10, Step: 60 / 105, used_time = 1315.64s, loss = 1.435983
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.949467714308753
  total = 662
Epoch: 10, Step: 70 / 105, used_time = 1327.90s, loss = 1.425587
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.062261065589304
  total = 662
Epoch: 10, Step: 80 / 105, used_time = 1340.14s, loss = 1.415101
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.336049212700182
  total = 662
Epoch: 10, Step: 90 / 105, used_time = 1352.33s, loss = 1.405213
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.16397807623807
  total = 662
Epoch: 10, Step: 100 / 105, used_time = 1364.35s, loss = 1.395079
***** Eval results *****
  exact = 10.120845921450151
  f1 = 33.08520305372558
  total = 662
Start epoch #11 (lr = 5e-05)...
Epoch: 11, Step: 10 / 105, used_time = 1379.49s, loss = 1.379380
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.52968895527431
  total = 662
Epoch: 11, Step: 20 / 105, used_time = 1391.48s, loss = 1.368888
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.610232398819548
  total = 662
Epoch: 11, Step: 30 / 105, used_time = 1403.65s, loss = 1.358750
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.590912809277675
  total = 662
Epoch: 11, Step: 40 / 105, used_time = 1415.65s, loss = 1.349275
***** Eval results *****
  exact = 9.06344410876133
  f1 = 32.41578490363686
  total = 662
Epoch: 11, Step: 50 / 105, used_time = 1427.69s, loss = 1.339686
***** Eval results *****
  exact = 8.91238670694864
  f1 = 32.376721991140336
  total = 662
Epoch: 11, Step: 60 / 105, used_time = 1439.69s, loss = 1.330304
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.59148764173471
  total = 662
Epoch: 11, Step: 70 / 105, used_time = 1451.89s, loss = 1.321270
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.894050739927057
  total = 662
Epoch: 11, Step: 80 / 105, used_time = 1463.97s, loss = 1.312410
***** Eval results *****
  exact = 8.610271903323262
  f1 = 31.679444649255853
  total = 662
Epoch: 11, Step: 90 / 105, used_time = 1476.13s, loss = 1.303685
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.77748158960985
  total = 662
Epoch: 11, Step: 100 / 105, used_time = 1488.39s, loss = 1.294654
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.15813372807711
  total = 662
Start epoch #12 (lr = 5e-05)...
Epoch: 12, Step: 10 / 105, used_time = 1503.37s, loss = 1.280786
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.194564361409338
  total = 662
Epoch: 12, Step: 20 / 105, used_time = 1515.68s, loss = 1.272008
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.09444509039506
  total = 662
Epoch: 12, Step: 30 / 105, used_time = 1527.74s, loss = 1.263035
***** Eval results *****
  exact = 9.214501510574019
  f1 = 32.02308890595372
  total = 662
Epoch: 12, Step: 40 / 105, used_time = 1539.79s, loss = 1.254213
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.0504016735423
  total = 662
Epoch: 12, Step: 50 / 105, used_time = 1552.02s, loss = 1.246145
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.3351212223338
  total = 662
Epoch: 12, Step: 60 / 105, used_time = 1564.23s, loss = 1.238384
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.71906148879053
  total = 662
Epoch: 12, Step: 70 / 105, used_time = 1576.45s, loss = 1.230414
***** Eval results *****
  exact = 9.667673716012084
  f1 = 32.93797270886949
  total = 662
Epoch: 12, Step: 80 / 105, used_time = 1588.28s, loss = 1.222451
***** Eval results *****
  exact = 9.365558912386707
  f1 = 32.28804892226288
  total = 662
Epoch: 12, Step: 90 / 105, used_time = 1600.53s, loss = 1.214307
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.959391140188522
  total = 662
Epoch: 12, Step: 100 / 105, used_time = 1612.65s, loss = 1.206547
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.944497722036655
  total = 662
Start epoch #13 (lr = 5e-05)...
Epoch: 13, Step: 10 / 105, used_time = 1627.89s, loss = 1.194689
***** Eval results *****
  exact = 9.06344410876133
  f1 = 30.89585205499226
  total = 662
Epoch: 13, Step: 20 / 105, used_time = 1640.00s, loss = 1.187244
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.279066230051438
  total = 662
Epoch: 13, Step: 30 / 105, used_time = 1652.10s, loss = 1.179718
***** Eval results *****
  exact = 8.459214501510575
  f1 = 31.102304443716378
  total = 662
Epoch: 13, Step: 40 / 105, used_time = 1664.37s, loss = 1.172336
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.330914517834966
  total = 662
Epoch: 13, Step: 50 / 105, used_time = 1676.62s, loss = 1.164901
***** Eval results *****
  exact = 8.91238670694864
  f1 = 31.160879083257417
  total = 662
Epoch: 13, Step: 60 / 105, used_time = 1688.74s, loss = 1.157449
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.43839981012395
  total = 662
Epoch: 13, Step: 70 / 105, used_time = 1701.00s, loss = 1.150349
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.670541048492613
  total = 662
Epoch: 13, Step: 80 / 105, used_time = 1713.06s, loss = 1.143582
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.91872976242366
  total = 662
Epoch: 13, Step: 90 / 105, used_time = 1724.85s, loss = 1.136450
***** Eval results *****
  exact = 9.516616314199396
  f1 = 32.68048009581558
  total = 662
Epoch: 13, Step: 100 / 105, used_time = 1737.00s, loss = 1.129762
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.96711248681101
  total = 662
Start epoch #14 (lr = 5e-05)...
Epoch: 14, Step: 10 / 105, used_time = 1752.49s, loss = 1.119889
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.968247088113603
  total = 662
Epoch: 14, Step: 20 / 105, used_time = 1764.66s, loss = 1.113039
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.74328921915997
  total = 662
Epoch: 14, Step: 30 / 105, used_time = 1776.43s, loss = 1.106415
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.01711995504163
  total = 662
Epoch: 14, Step: 40 / 105, used_time = 1788.67s, loss = 1.099880
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.126560781073323
  total = 662
Epoch: 14, Step: 50 / 105, used_time = 1800.93s, loss = 1.093523
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.338685244996526
  total = 662
Epoch: 14, Step: 60 / 105, used_time = 1813.25s, loss = 1.087328
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.68056278129144
  total = 662
Epoch: 14, Step: 70 / 105, used_time = 1825.43s, loss = 1.080941
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.93893000350333
  total = 662
Epoch: 14, Step: 80 / 105, used_time = 1837.55s, loss = 1.074544
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.806956939331087
  total = 662
Epoch: 14, Step: 90 / 105, used_time = 1849.73s, loss = 1.068491
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.32287233777149
  total = 662
Epoch: 14, Step: 100 / 105, used_time = 1861.81s, loss = 1.062616
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.13508479814497
  total = 662
Start epoch #15 (lr = 5e-05)...
Epoch: 15, Step: 10 / 105, used_time = 1877.20s, loss = 1.053847
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.995943838245005
  total = 662
Epoch: 15, Step: 20 / 105, used_time = 1889.31s, loss = 1.048044
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.20563015981219
  total = 662
Epoch: 15, Step: 30 / 105, used_time = 1901.54s, loss = 1.042339
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.167701649505634
  total = 662
Epoch: 15, Step: 40 / 105, used_time = 1913.62s, loss = 1.036416
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.529602145361842
  total = 662
Epoch: 15, Step: 50 / 105, used_time = 1925.70s, loss = 1.030680
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.802709423548876
  total = 662
Epoch: 15, Step: 60 / 105, used_time = 1937.78s, loss = 1.024815
***** Eval results *****
  exact = 9.667673716012084
  f1 = 30.989089672888724
  total = 662
Epoch: 15, Step: 70 / 105, used_time = 1949.86s, loss = 1.019338
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.327337069868822
  total = 662
Epoch: 15, Step: 80 / 105, used_time = 1962.04s, loss = 1.013790
***** Eval results *****
  exact = 10.27190332326284
  f1 = 32.836616077984395
  total = 662
Epoch: 15, Step: 90 / 105, used_time = 1973.76s, loss = 1.008182
***** Eval results *****
  exact = 10.27190332326284
  f1 = 32.672503138499174
  total = 662
Epoch: 15, Step: 100 / 105, used_time = 1985.82s, loss = 1.002805
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.796992160817652
  total = 662
Start epoch #16 (lr = 5e-05)...
Epoch: 16, Step: 10 / 105, used_time = 2001.22s, loss = 0.994709
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.494387557862552
  total = 662
Epoch: 16, Step: 20 / 105, used_time = 2013.36s, loss = 0.989450
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.069182626763226
  total = 662
Epoch: 16, Step: 30 / 105, used_time = 2025.57s, loss = 0.984516
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.10629745356191
  total = 662
Epoch: 16, Step: 40 / 105, used_time = 2037.68s, loss = 0.979460
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.800138017285093
  total = 662
Epoch: 16, Step: 50 / 105, used_time = 2049.94s, loss = 0.974343
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.56391374187957
  total = 662
Epoch: 16, Step: 60 / 105, used_time = 2062.04s, loss = 0.969409
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.569339876541996
  total = 662
Epoch: 16, Step: 70 / 105, used_time = 2073.84s, loss = 0.964339
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.810908640787268
  total = 662
Epoch: 16, Step: 80 / 105, used_time = 2085.97s, loss = 0.959482
***** Eval results *****
  exact = 9.818731117824774
  f1 = 32.1721705698861
  total = 662
Epoch: 16, Step: 90 / 105, used_time = 2098.08s, loss = 0.954736
***** Eval results *****
  exact = 9.06344410876133
  f1 = 31.288904334837998
  total = 662
Epoch: 16, Step: 100 / 105, used_time = 2110.35s, loss = 0.949976
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.43571501765482
  total = 662
Start epoch #17 (lr = 5e-05)...
Epoch: 17, Step: 10 / 105, used_time = 2125.74s, loss = 0.943008
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.82301267192686
  total = 662
Epoch: 17, Step: 20 / 105, used_time = 2137.85s, loss = 0.938158
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.403223054431262
  total = 662
Epoch: 17, Step: 30 / 105, used_time = 2150.15s, loss = 0.933469
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.64711728925416
  total = 662
Epoch: 17, Step: 40 / 105, used_time = 2162.29s, loss = 0.928740
***** Eval results *****
  exact = 9.516616314199396
  f1 = 31.838584891109612
  total = 662
Epoch: 17, Step: 50 / 105, used_time = 2174.46s, loss = 0.924237
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.916019515083445
  total = 662
Epoch: 17, Step: 60 / 105, used_time = 2186.61s, loss = 0.919683
***** Eval results *****
  exact = 9.214501510574019
  f1 = 31.45132320019999
  total = 662
Epoch: 17, Step: 70 / 105, used_time = 2198.71s, loss = 0.915076
***** Eval results *****
  exact = 9.365558912386707
  f1 = 31.328094719930338
  total = 662
Epoch: 17, Step: 80 / 105, used_time = 2210.60s, loss = 0.910712
***** Eval results *****
  exact = 9.667673716012084
  f1 = 31.756046127417356
  total = 662
Epoch: 17, Step: 90 / 105, used_time = 2222.68s, loss = 0.906464
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.745359886891137
  total = 662
Epoch: 17, Step: 100 / 105, used_time = 2234.92s, loss = 0.902197
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.898194190869265
  total = 662
Start epoch #18 (lr = 5e-05)...
Epoch: 18, Step: 10 / 105, used_time = 2250.53s, loss = 0.895763
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.034376297864064
  total = 662
Epoch: 18, Step: 20 / 105, used_time = 2262.79s, loss = 0.891619
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.98528809905505
  total = 662
Epoch: 18, Step: 30 / 105, used_time = 2275.02s, loss = 0.887570
***** Eval results *****
  exact = 10.120845921450151
  f1 = 32.18424987486397
  total = 662
Epoch: 18, Step: 40 / 105, used_time = 2287.21s, loss = 0.883565
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.92025567598657
  total = 662
Epoch: 18, Step: 50 / 105, used_time = 2299.42s, loss = 0.879467
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.812116070892746
  total = 662
Epoch: 18, Step: 60 / 105, used_time = 2311.54s, loss = 0.875385
***** Eval results *****
  exact = 10.120845921450151
  f1 = 31.87680631802556
  total = 662
Epoch: 18, Step: 70 / 105, used_time = 2323.29s, loss = 0.871161
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.73410594435719
  total = 662
Epoch: 18, Step: 80 / 105, used_time = 2335.40s, loss = 0.867136
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.75419367842836
  total = 662
Epoch: 18, Step: 90 / 105, used_time = 2347.50s, loss = 0.863288
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.62793686747122
  total = 662
Epoch: 18, Step: 100 / 105, used_time = 2359.66s, loss = 0.859395
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.995892494490285
  total = 662
Start epoch #19 (lr = 5e-05)...
Epoch: 19, Step: 10 / 105, used_time = 2375.06s, loss = 0.853737
***** Eval results *****
  exact = 9.969788519637461
  f1 = 31.947160340596323
  total = 662
Epoch: 19, Step: 20 / 105, used_time = 2387.00s, loss = 0.850126
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.0643673442437
  total = 662
Epoch: 19, Step: 30 / 105, used_time = 2399.26s, loss = 0.846519
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.196607637720554
  total = 662
Epoch: 19, Step: 40 / 105, used_time = 2411.39s, loss = 0.842780
***** Eval results *****
  exact = 9.969788519637461
  f1 = 32.1620144220402
  total = 662
Epoch: 19, Step: 50 / 105, used_time = 2423.48s, loss = 0.839039
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.900951073199366
  total = 662
Epoch: 19, Step: 60 / 105, used_time = 2435.58s, loss = 0.835287
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.85590168492827
  total = 662
Epoch: 19, Step: 70 / 105, used_time = 2447.80s, loss = 0.831721
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.85590168492827
  total = 662
Epoch: 19, Step: 80 / 105, used_time = 2459.92s, loss = 0.828164
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.848207759538838
  total = 662
Epoch: 19, Step: 90 / 105, used_time = 2472.14s, loss = 0.824674
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.848207759538838
  total = 662
Epoch: 19, Step: 100 / 105, used_time = 2484.28s, loss = 0.821122
***** Eval results *****
  exact = 9.818731117824774
  f1 = 31.848207759538838
  total = 662
*** Example ***
unique_id: 1000000000
example_index: 0
doc_span_index: 0
tokens: [CLS] What material would you advice using for can ##ning ? [SEP] If you are going to be can ##ning this for long term storage you will need to be pressure can ##ning it , and as that will mean some pretty high heat you ' d be better off not cooking you beans too long before can ##ning . I ' d add them in a few minutes before the end of cooking just to get them warmed up in preparation for can ##ning it as a half hour of cooking plus pressure can ##ning would probably mean m ##ush . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:6 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:18 33:19 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:29 46:29 47:30 48:31 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:40 59:40 60:41 61:41 62:41 63:42 64:43 65:44 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:62 85:63 86:64 87:65 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:72 96:73 97:74 98:75 99:76 100:76 101:76
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True
input_ids: 101 1327 2578 1156 1128 5566 1606 1111 1169 3381 136 102 1409 1128 1132 1280 1106 1129 1169 3381 1142 1111 1263 1858 5092 1128 1209 1444 1106 1129 2997 1169 3381 1122 117 1105 1112 1115 1209 1928 1199 2785 1344 3208 1128 112 173 1129 1618 1228 1136 8739 1128 15154 1315 1263 1196 1169 3381 119 146 112 173 5194 1172 1107 170 1374 1904 1196 1103 1322 1104 8739 1198 1106 1243 1172 18694 1146 1107 7288 1111 1169 3381 1122 1112 170 1544 2396 1104 8739 4882 2997 1169 3381 1156 1930 1928 182 13148 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000001
example_index: 1
doc_span_index: 0
tokens: [CLS] Do I need a particular piece of machine ##r for this ? [SEP] If you are going to be can ##ning this for long term storage you will need to be pressure can ##ning it , and as that will mean some pretty high heat you ' d be better off not cooking you beans too long before can ##ning . I ' d add them in a few minutes before the end of cooking just to get them warmed up in preparation for can ##ning it as a half hour of cooking plus pressure can ##ning would probably mean m ##ush . [SEP]
token_to_orig_map: 14:0 15:1 16:2 17:3 18:4 19:5 20:6 21:6 22:7 23:8 24:9 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:18 35:19 36:19 37:20 38:21 39:22 40:23 41:24 42:25 43:26 44:27 45:28 46:29 47:29 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:37 57:38 58:39 59:40 60:40 61:40 62:41 63:41 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:62 86:62 87:63 88:64 89:65 90:66 91:67 92:68 93:69 94:70 95:71 96:72 97:72 98:73 99:74 100:75 101:76 102:76 103:76
token_is_max_context: 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True
input_ids: 101 2091 146 1444 170 2440 2727 1104 3395 1197 1111 1142 136 102 1409 1128 1132 1280 1106 1129 1169 3381 1142 1111 1263 1858 5092 1128 1209 1444 1106 1129 2997 1169 3381 1122 117 1105 1112 1115 1209 1928 1199 2785 1344 3208 1128 112 173 1129 1618 1228 1136 8739 1128 15154 1315 1263 1196 1169 3381 119 146 112 173 5194 1172 1107 170 1374 1904 1196 1103 1322 1104 8739 1198 1106 1243 1172 18694 1146 1107 7288 1111 1169 3381 1122 1112 170 1544 2396 1104 8739 4882 2997 1169 3381 1156 1930 1928 182 13148 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000002
example_index: 2
doc_span_index: 0
tokens: [CLS] Is rare duck breast safe ? [SEP] Rare duck meat is safe to eat because it does NO ##T contain the same risk of Salmon ##ella as does chicken meat . P ##rima ##rily because ducks , as mentioned above , have not traditionally been raised in the same sq ##ual ##id conditions as " factory raised " chickens - salmon ##ella is a disease that is primarily transmitted through dirt / dirty uncle ##an conditions . Now , on the other hand , as more and more ducks are being raised in industrial conditions , they are also becoming more likely to contain strains of Salmon ##ella . [SEP]
token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:16 27:17 28:18 29:19 30:20 31:20 32:20 33:20 34:20 35:21 36:22 37:22 38:23 39:24 40:25 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:32 49:33 50:34 51:34 52:34 53:35 54:36 55:37 56:37 57:38 58:38 59:39 60:40 61:41 62:41 63:42 64:43 65:44 66:45 67:46 68:47 69:48 70:49 71:50 72:50 73:50 74:51 75:51 76:52 77:52 78:53 79:53 80:54 81:55 82:56 83:57 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:65 93:66 94:67 95:68 96:68 97:69 98:70 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:79 109:79
token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True
input_ids: 101 2181 4054 13520 7209 2914 136 102 25574 13520 6092 1110 2914 1106 3940 1272 1122 1674 24819 1942 4651 1103 1269 3187 1104 22144 7772 1112 1674 9323 6092 119 153 19123 11486 1272 24488 117 1112 3025 1807 117 1138 1136 7440 1151 2120 1107 1103 1269 4816 4746 2386 2975 1112 107 4790 2120 107 26199 118 17646 7772 1110 170 3653 1115 1110 3120 12086 1194 6786 120 7320 4906 1389 2975 119 1986 117 1113 1103 1168 1289 117 1112 1167 1105 1167 24488 1132 1217 2120 1107 3924 2975 117 1152 1132 1145 2479 1167 2620 1106 4651 21116 1104 22144 7772 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000003
example_index: 3
doc_span_index: 0
tokens: [CLS] Why would I prefer carbon steel ( r ##ust prone ) kitchen knife ? [SEP] Carbon steel is more mall ##ea ##ble and less br ##ittle than stainless steel . This means that it is easier to ho ##ne on a knife steel , to maintain an extremely sharp edge . Some folks feel that the benefit of that sharp edge – for example , in easily s ##licing tomato ##es , and other very fast pre ##p tasks – is worth the compromise of more per ##s ##nick ##ety maintenance . [SEP]
token_to_orig_map: 16:0 17:1 18:2 19:3 20:4 21:4 22:4 23:5 24:6 25:7 26:7 27:8 28:9 29:10 30:10 31:11 32:12 33:13 34:14 35:15 36:16 37:17 38:18 39:18 40:19 41:20 42:21 43:22 44:22 45:23 46:24 47:25 48:26 49:27 50:28 51:28 52:28 53:29 54:30 55:31 56:32 57:33 58:34 59:35 60:36 61:37 62:37 63:37 64:38 65:38 66:39 67:40 68:41 69:41 70:42 71:42 72:42 73:43 74:44 75:45 76:46 77:47 78:47 79:48 80:48 81:48 82:49 83:50 84:51 85:52 86:53 87:54 88:54 89:54 90:54 91:55 92:55
token_is_max_context: 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True
input_ids: 101 2009 1156 146 9353 6302 3649 113 187 8954 13557 114 3119 4937 136 102 23603 3649 1110 1167 8796 4490 2165 1105 1750 9304 26775 1190 21771 3649 119 1188 2086 1115 1122 1110 5477 1106 16358 1673 1113 170 4937 3649 117 1106 4731 1126 4450 4295 2652 119 1789 13918 1631 1115 1103 5257 1104 1115 4295 2652 782 1111 1859 117 1107 3253 188 22548 26422 1279 117 1105 1168 1304 2698 3073 1643 8249 782 1110 3869 1103 13018 1104 1167 1679 1116 14276 20656 5972 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000004
example_index: 4
doc_span_index: 0
tokens: [CLS] Why do I prefer carbon steel over stainless steel ? [SEP] Carbon steel is more mall ##ea ##ble and less br ##ittle than stainless steel . This means that it is easier to ho ##ne on a knife steel , to maintain an extremely sharp edge . Some folks feel that the benefit of that sharp edge – for example , in easily s ##licing tomato ##es , and other very fast pre ##p tasks – is worth the compromise of more per ##s ##nick ##ety maintenance . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:4 18:4 19:5 20:6 21:7 22:7 23:8 24:9 25:10 26:10 27:11 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:18 36:19 37:20 38:21 39:22 40:22 41:23 42:24 43:25 44:26 45:27 46:28 47:28 48:28 49:29 50:30 51:31 52:32 53:33 54:34 55:35 56:36 57:37 58:37 59:37 60:38 61:38 62:39 63:40 64:41 65:41 66:42 67:42 68:42 69:43 70:44 71:45 72:46 73:47 74:47 75:48 76:48 77:48 78:49 79:50 80:51 81:52 82:53 83:54 84:54 85:54 86:54 87:55 88:55
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True
input_ids: 101 2009 1202 146 9353 6302 3649 1166 21771 3649 136 102 23603 3649 1110 1167 8796 4490 2165 1105 1750 9304 26775 1190 21771 3649 119 1188 2086 1115 1122 1110 5477 1106 16358 1673 1113 170 4937 3649 117 1106 4731 1126 4450 4295 2652 119 1789 13918 1631 1115 1103 5257 1104 1115 4295 2652 782 1111 1859 117 1107 3253 188 22548 26422 1279 117 1105 1168 1304 2698 3073 1643 8249 782 1110 3869 1103 13018 1104 1167 1679 1116 14276 20656 5972 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000005
example_index: 5
doc_span_index: 0
tokens: [CLS] What extra care does carbon steel require ? [SEP] Carbon steel is more mall ##ea ##ble and less br ##ittle than stainless steel . This means that it is easier to ho ##ne on a knife steel , to maintain an extremely sharp edge . Some folks feel that the benefit of that sharp edge – for example , in easily s ##licing tomato ##es , and other very fast pre ##p tasks – is worth the compromise of more per ##s ##nick ##ety maintenance . [SEP]
token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:4 16:4 17:5 18:6 19:7 20:7 21:8 22:9 23:10 24:10 25:11 26:12 27:13 28:14 29:15 30:16 31:17 32:18 33:18 34:19 35:20 36:21 37:22 38:22 39:23 40:24 41:25 42:26 43:27 44:28 45:28 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:35 54:36 55:37 56:37 57:37 58:38 59:38 60:39 61:40 62:41 63:41 64:42 65:42 66:42 67:43 68:44 69:45 70:46 71:47 72:47 73:48 74:48 75:48 76:49 77:50 78:51 79:52 80:53 81:54 82:54 83:54 84:54 85:55 86:55
token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True
input_ids: 101 1327 3908 1920 1674 6302 3649 4752 136 102 23603 3649 1110 1167 8796 4490 2165 1105 1750 9304 26775 1190 21771 3649 119 1188 2086 1115 1122 1110 5477 1106 16358 1673 1113 170 4937 3649 117 1106 4731 1126 4450 4295 2652 119 1789 13918 1631 1115 1103 5257 1104 1115 4295 2652 782 1111 1859 117 1107 3253 188 22548 26422 1279 117 1105 1168 1304 2698 3073 1643 8249 782 1110 3869 1103 13018 1104 1167 1679 1116 14276 20656 5972 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000006
example_index: 6
doc_span_index: 0
tokens: [CLS] How do you prepare fresh f ##enne ##l for cooking ? [SEP] Sometimes the outer leaves are a bit leather ##y ( especially if the quality isn ’ t too god ) . When that ’ s the case I remove them first . Next , I remove the green stalk ##s – but Je ##f ##rom ##i is right , the tiny leaves are delicious . The kernel in the middle near the base of the f ##enne ##l bulb is very hard . I usually cut it out by ha ##lving the bulb along its length and making two in ##cision ##s with a sharp knife on either side of the kernel . I ch ##op the rest of the bulb so that it yields thin con ##centric slice ##s . [SEP]
token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:7 22:8 23:8 24:9 25:10 26:11 27:12 28:12 29:12 30:13 31:14 32:14 33:14 34:15 35:16 36:16 37:16 38:17 39:18 40:19 41:20 42:21 43:22 44:22 45:22 46:22 47:23 48:24 49:25 50:26 51:27 52:27 53:28 54:29 55:30 56:30 57:30 58:30 59:31 60:32 61:32 62:33 63:34 64:35 65:36 66:37 67:37 68:37 69:38 70:39 71:40 72:41 73:42 74:43 75:44 76:45 77:46 78:47 79:47 80:47 81:48 82:49 83:50 84:51 85:51 86:52 87:53 88:54 89:55 90:56 91:57 92:58 93:58 94:59 95:60 96:61 97:62 98:63 99:64 100:65 101:66 102:67 103:67 104:67 105:68 106:69 107:70 108:71 109:72 110:73 111:74 112:75 113:76 114:77 115:77 116:77 117:78 118:78 119:79 120:80 121:81 122:82 123:83 124:84 125:85 126:86 127:87 128:88 129:89 130:89 131:90 132:90 133:90
token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True
input_ids: 101 1731 1202 1128 7034 4489 175 26042 1233 1111 8739 136 102 5875 1103 6144 2972 1132 170 2113 5439 1183 113 2108 1191 1103 3068 2762 787 189 1315 5540 114 119 1332 1115 787 188 1103 1692 146 5782 1172 1148 119 5893 117 146 5782 1103 2448 27438 1116 782 1133 27901 2087 16071 1182 1110 1268 117 1103 4296 2972 1132 13108 119 1109 18670 1107 1103 2243 1485 1103 2259 1104 1103 175 26042 1233 23447 1110 1304 1662 119 146 1932 2195 1122 1149 1118 5871 25115 1103 23447 1373 1157 2251 1105 1543 1160 1107 16073 1116 1114 170 4295 4937 1113 1719 1334 1104 1103 18670 119 146 22572 4184 1103 1832 1104 1103 23447 1177 1115 1122 17376 4240 14255 24684 16346 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000007
example_index: 7
doc_span_index: 0
tokens: [CLS] What does roughly ch ##op mean ? [SEP] Sometimes the outer leaves are a bit leather ##y ( especially if the quality isn ’ t too god ) . When that ’ s the case I remove them first . Next , I remove the green stalk ##s – but Je ##f ##rom ##i is right , the tiny leaves are delicious . The kernel in the middle near the base of the f ##enne ##l bulb is very hard . I usually cut it out by ha ##lving the bulb along its length and making two in ##cision ##s with a sharp knife on either side of the kernel . I ch ##op the rest of the bulb so that it yields thin con ##centric slice ##s . [SEP]
token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:7 18:8 19:8 20:9 21:10 22:11 23:12 24:12 25:12 26:13 27:14 28:14 29:14 30:15 31:16 32:16 33:16 34:17 35:18 36:19 37:20 38:21 39:22 40:22 41:22 42:22 43:23 44:24 45:25 46:26 47:27 48:27 49:28 50:29 51:30 52:30 53:30 54:30 55:31 56:32 57:32 58:33 59:34 60:35 61:36 62:37 63:37 64:37 65:38 66:39 67:40 68:41 69:42 70:43 71:44 72:45 73:46 74:47 75:47 76:47 77:48 78:49 79:50 80:51 81:51 82:52 83:53 84:54 85:55 86:56 87:57 88:58 89:58 90:59 91:60 92:61 93:62 94:63 95:64 96:65 97:66 98:67 99:67 100:67 101:68 102:69 103:70 104:71 105:72 106:73 107:74 108:75 109:76 110:77 111:77 112:77 113:78 114:78 115:79 116:80 117:81 118:82 119:83 120:84 121:85 122:86 123:87 124:88 125:89 126:89 127:90 128:90 129:90
token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True
input_ids: 101 1327 1674 4986 22572 4184 1928 136 102 5875 1103 6144 2972 1132 170 2113 5439 1183 113 2108 1191 1103 3068 2762 787 189 1315 5540 114 119 1332 1115 787 188 1103 1692 146 5782 1172 1148 119 5893 117 146 5782 1103 2448 27438 1116 782 1133 27901 2087 16071 1182 1110 1268 117 1103 4296 2972 1132 13108 119 1109 18670 1107 1103 2243 1485 1103 2259 1104 1103 175 26042 1233 23447 1110 1304 1662 119 146 1932 2195 1122 1149 1118 5871 25115 1103 23447 1373 1157 2251 1105 1543 1160 1107 16073 1116 1114 170 4295 4937 1113 1719 1334 1104 1103 18670 119 146 22572 4184 1103 1832 1104 1103 23447 1177 1115 1122 17376 4240 14255 24684 16346 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000008
example_index: 8
doc_span_index: 0
tokens: [CLS] Is there a special too available for cracking open a p ##ista ##chi ##o ? [SEP] i usually use half of a previously - opened p ##ista ##chi ##o shell ! use the tip of it as a bit of lever : slip it into the opening of the one you ' re working on , and rotate it , and it will open it as easy as pie . the down ##side is that you will be able to eat many , many more p ##ista ##chi ##os this way . i usually end up with a mouth raw from all the salt , ha ##ha . [SEP]
token_to_orig_map: 17:0 18:1 19:2 20:3 21:4 22:5 23:6 24:6 25:6 26:7 27:7 28:7 29:7 30:8 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:18 43:19 44:20 45:21 46:22 47:23 48:24 49:25 50:26 51:27 52:27 53:27 54:28 55:29 56:29 57:30 58:31 59:32 60:32 61:33 62:34 63:35 64:36 65:37 66:38 67:39 68:40 69:41 70:41 71:42 72:43 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:52 84:53 85:54 86:55 87:55 88:55 89:55 90:56 91:57 92:57 93:58 94:59 95:60 96:61 97:62 98:63 99:64 100:65 101:66 102:67 103:68 104:69 105:69 106:70 107:70 108:70
token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True
input_ids: 101 2181 1175 170 1957 1315 1907 1111 17254 1501 170 185 11663 4313 1186 136 102 178 1932 1329 1544 1104 170 2331 118 1533 185 11663 4313 1186 5963 106 1329 1103 5580 1104 1122 1112 170 2113 1104 20097 131 7324 1122 1154 1103 2280 1104 1103 1141 1128 112 1231 1684 1113 117 1105 27905 1122 117 1105 1122 1209 1501 1122 1112 3123 1112 16288 119 1103 1205 5570 1110 1115 1128 1209 1129 1682 1106 3940 1242 117 1242 1167 185 11663 4313 2155 1142 1236 119 178 1932 1322 1146 1114 170 1779 7158 1121 1155 1103 6870 117 5871 2328 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000009
example_index: 9
doc_span_index: 0
tokens: [CLS] Do you have any other tips for opening p ##ista ##chi ##os ? [SEP] i usually use half of a previously - opened p ##ista ##chi ##o shell ! use the tip of it as a bit of lever : slip it into the opening of the one you ' re working on , and rotate it , and it will open it as easy as pie . the down ##side is that you will be able to eat many , many more p ##ista ##chi ##os this way . i usually end up with a mouth raw from all the salt , ha ##ha . [SEP]
token_to_orig_map: 15:0 16:1 17:2 18:3 19:4 20:5 21:6 22:6 23:6 24:7 25:7 26:7 27:7 28:8 29:8 30:9 31:10 32:11 33:12 34:13 35:14 36:15 37:16 38:17 39:18 40:18 41:19 42:20 43:21 44:22 45:23 46:24 47:25 48:26 49:27 50:27 51:27 52:28 53:29 54:29 55:30 56:31 57:32 58:32 59:33 60:34 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:41 69:42 70:43 71:43 72:44 73:45 74:46 75:47 76:48 77:49 78:50 79:51 80:52 81:52 82:53 83:54 84:55 85:55 86:55 87:55 88:56 89:57 90:57 91:58 92:59 93:60 94:61 95:62 96:63 97:64 98:65 99:66 100:67 101:68 102:69 103:69 104:70 105:70 106:70
token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True
input_ids: 101 2091 1128 1138 1251 1168 10538 1111 2280 185 11663 4313 2155 136 102 178 1932 1329 1544 1104 170 2331 118 1533 185 11663 4313 1186 5963 106 1329 1103 5580 1104 1122 1112 170 2113 1104 20097 131 7324 1122 1154 1103 2280 1104 1103 1141 1128 112 1231 1684 1113 117 1105 27905 1122 117 1105 1122 1209 1501 1122 1112 3123 1112 16288 119 1103 1205 5570 1110 1115 1128 1209 1129 1682 1106 3940 1242 117 1242 1167 185 11663 4313 2155 1142 1236 119 178 1932 1322 1146 1114 170 1779 7158 1121 1155 1103 6870 117 5871 2328 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000010
example_index: 10
doc_span_index: 0
tokens: [CLS] Why does my 1 tables ##poon of coffee grounds not equal 15 m ##l ? [SEP] Your scale is measuring weight , not volume . Some scales do have an option to " convert " to volume , but they have to do so based on density ; they don ' t actually know what ' s on top of them . So unless yours is really fancy , and has a bunch of den ##sities programmed into it , so that you can say " this is flour " and let it convert , it ' s probably just assuming everything is water , with a density of 1 ##g / m ##L . And this should be really easy to confirm . Just to ##ggle it from weight to volume . If it says 13 ##m ##L is 13 ##g , then that ' s what it ' s doing . So then it ' s telling you that your 2 . 5 tables ##poon ##s of coffee is 13 ##g , not 13 ##m ##L , because it ' s around 1 / 3 as dense as water . [SEP]
token_to_orig_map: 17:0 18:1 19:2 20:3 21:4 22:4 23:5 24:6 25:6 26:6 27:7 28:8 29:9 30:10 31:11 32:12 33:13 34:13 35:13 36:14 37:15 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:23 47:24 48:24 49:25 50:26 51:26 52:26 53:27 54:28 55:29 56:29 57:29 58:30 59:31 60:32 61:33 62:33 63:34 64:35 65:36 66:37 67:38 68:39 69:39 70:40 71:41 72:42 73:43 74:44 75:45 76:45 77:46 78:47 79:48 80:48 81:49 82:50 83:51 84:52 85:53 86:54 87:54 88:55 89:56 90:56 91:57 92:58 93:59 94:60 95:60 96:61 97:61 98:61 99:62 100:63 101:64 102:65 103:66 104:67 105:67 106:68 107:69 108:70 109:71 110:72 111:72 112:72 113:72 114:72 115:72 116:72 117:73 118:74 119:75 120:76 121:77 122:78 123:79 124:79 125:80 126:81 127:81 128:82 129:83 130:84 131:85 132:86 133:86 134:87 135:88 136:89 137:90 138:90 139:90 140:91 141:92 142:92 143:92 144:93 145:94 146:94 147:94 148:95 149:96 150:96 151:96 152:97 153:97 154:97 155:98 156:99 157:99 158:99 159:100 160:101 161:102 162:103 163:104 164:104 165:104 166:105 167:105 168:105 169:106 170:107 171:108 172:109 173:109 174:109 175:110 176:111 177:111 178:111 179:111 180:112 181:113 182:113 183:113 184:114 185:115 186:115 187:115 188:116 189:117 190:118 191:119 192:119
token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True
input_ids: 101 2009 1674 1139 122 7072 24877 1104 3538 4745 1136 4463 1405 182 1233 136 102 2353 3418 1110 10099 2841 117 1136 3884 119 1789 9777 1202 1138 1126 5146 1106 107 10454 107 1106 3884 117 1133 1152 1138 1106 1202 1177 1359 1113 3476 132 1152 1274 112 189 2140 1221 1184 112 188 1113 1499 1104 1172 119 1573 4895 6762 1110 1541 13305 117 1105 1144 170 9670 1104 10552 28060 18693 1154 1122 117 1177 1115 1128 1169 1474 107 1142 1110 15068 107 1105 1519 1122 10454 117 1122 112 188 1930 1198 11577 1917 1110 1447 117 1114 170 3476 1104 122 1403 120 182 2162 119 1262 1142 1431 1129 1541 3123 1106 12434 119 2066 1106 25186 1122 1121 2841 1106 3884 119 1409 1122 1867 1492 1306 2162 1110 1492 1403 117 1173 1115 112 188 1184 1122 112 188 1833 119 1573 1173 1122 112 188 3344 1128 1115 1240 123 119 126 7072 24877 1116 1104 3538 1110 1492 1403 117 1136 1492 1306 2162 117 1272 1122 112 188 1213 122 120 124 1112 9613 1112 1447 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000011
example_index: 11
doc_span_index: 0
tokens: [CLS] Why does my 2 1 / 2 tables ##poon measurement not equal 37 m ##l ? [SEP] Your scale is measuring weight , not volume . Some scales do have an option to " convert " to volume , but they have to do so based on density ; they don ' t actually know what ' s on top of them . So unless yours is really fancy , and has a bunch of den ##sities programmed into it , so that you can say " this is flour " and let it convert , it ' s probably just assuming everything is water , with a density of 1 ##g / m ##L . And this should be really easy to confirm . Just to ##ggle it from weight to volume . If it says 13 ##m ##L is 13 ##g , then that ' s what it ' s doing . So then it ' s telling you that your 2 . 5 tables ##poon ##s of coffee is 13 ##g , not 13 ##m ##L , because it ' s around 1 / 3 as dense as water . [SEP]
token_to_orig_map: 18:0 19:1 20:2 21:3 22:4 23:4 24:5 25:6 26:6 27:6 28:7 29:8 30:9 31:10 32:11 33:12 34:13 35:13 36:13 37:14 38:15 39:15 40:16 41:17 42:18 43:19 44:20 45:21 46:22 47:23 48:24 49:24 50:25 51:26 52:26 53:26 54:27 55:28 56:29 57:29 58:29 59:30 60:31 61:32 62:33 63:33 64:34 65:35 66:36 67:37 68:38 69:39 70:39 71:40 72:41 73:42 74:43 75:44 76:45 77:45 78:46 79:47 80:48 81:48 82:49 83:50 84:51 85:52 86:53 87:54 88:54 89:55 90:56 91:56 92:57 93:58 94:59 95:60 96:60 97:61 98:61 99:61 100:62 101:63 102:64 103:65 104:66 105:67 106:67 107:68 108:69 109:70 110:71 111:72 112:72 113:72 114:72 115:72 116:72 117:72 118:73 119:74 120:75 121:76 122:77 123:78 124:79 125:79 126:80 127:81 128:81 129:82 130:83 131:84 132:85 133:86 134:86 135:87 136:88 137:89 138:90 139:90 140:90 141:91 142:92 143:92 144:92 145:93 146:94 147:94 148:94 149:95 150:96 151:96 152:96 153:97 154:97 155:97 156:98 157:99 158:99 159:99 160:100 161:101 162:102 163:103 164:104 165:104 166:104 167:105 168:105 169:105 170:106 171:107 172:108 173:109 174:109 175:109 176:110 177:111 178:111 179:111 180:111 181:112 182:113 183:113 184:113 185:114 186:115 187:115 188:115 189:116 190:117 191:118 192:119 193:119
token_is_max_context: 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True
input_ids: 101 2009 1674 1139 123 122 120 123 7072 24877 11842 1136 4463 3413 182 1233 136 102 2353 3418 1110 10099 2841 117 1136 3884 119 1789 9777 1202 1138 1126 5146 1106 107 10454 107 1106 3884 117 1133 1152 1138 1106 1202 1177 1359 1113 3476 132 1152 1274 112 189 2140 1221 1184 112 188 1113 1499 1104 1172 119 1573 4895 6762 1110 1541 13305 117 1105 1144 170 9670 1104 10552 28060 18693 1154 1122 117 1177 1115 1128 1169 1474 107 1142 1110 15068 107 1105 1519 1122 10454 117 1122 112 188 1930 1198 11577 1917 1110 1447 117 1114 170 3476 1104 122 1403 120 182 2162 119 1262 1142 1431 1129 1541 3123 1106 12434 119 2066 1106 25186 1122 1121 2841 1106 3884 119 1409 1122 1867 1492 1306 2162 1110 1492 1403 117 1173 1115 112 188 1184 1122 112 188 1833 119 1573 1173 1122 112 188 3344 1128 1115 1240 123 119 126 7072 24877 1116 1104 3538 1110 1492 1403 117 1136 1492 1306 2162 117 1272 1122 112 188 1213 122 120 124 1112 9613 1112 1447 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000012
example_index: 12
doc_span_index: 0
tokens: [CLS] How can I tell if my chocolate is tempered ? [SEP] If it has a shiny / reflective surface and doesn ' t melt or b ##loom ( much ) at room temperature or hand temperature , then it ' s already tempered . Virtual ##ly every packaged chocolate is already tempered . Un ##tem ##pered chocolate generally needs to be re ##f ##rig ##erated for longer - term storage , so if a package doesn ' t specify re ##f ##rig ##eration ( and I ' ve never seen one that does ) , you can assume that it is tempered . [SEP]
token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:4 18:4 19:5 20:6 21:7 22:7 23:7 24:8 25:9 26:10 27:10 28:11 29:11 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:17 38:18 39:19 40:19 41:19 42:20 43:21 44:21 45:22 46:22 47:23 48:24 49:25 50:26 51:27 52:28 53:28 54:28 55:28 56:28 57:29 58:30 59:31 60:32 61:33 62:34 63:34 64:34 65:34 66:35 67:36 68:36 69:36 70:37 71:37 72:38 73:39 74:40 75:41 76:42 77:42 78:42 79:43 80:44 81:44 82:44 83:44 84:45 85:45 86:46 87:46 88:46 89:47 90:48 91:49 92:50 93:51 94:51 95:51 96:52 97:53 98:54 99:55 100:56 101:57 102:58 103:58
token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True
input_ids: 101 1731 1169 146 1587 1191 1139 8888 1110 26030 136 102 1409 1122 1144 170 13388 120 24449 2473 1105 2144 112 189 16399 1137 171 13853 113 1277 114 1120 1395 4143 1137 1289 4143 117 1173 1122 112 188 1640 26030 119 18486 1193 1451 24946 8888 1110 1640 26030 119 12118 18408 19808 8888 2412 2993 1106 1129 1231 2087 17305 20725 1111 2039 118 1858 5092 117 1177 1191 170 7305 2144 112 189 22829 1231 2087 17305 17166 113 1105 146 112 1396 1309 1562 1141 1115 1674 114 117 1128 1169 7568 1115 1122 1110 26030 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000013
example_index: 13
doc_span_index: 0
tokens: [CLS] Which types are not tempered ? [SEP] If it has a shiny / reflective surface and doesn ' t melt or b ##loom ( much ) at room temperature or hand temperature , then it ' s already tempered . Virtual ##ly every packaged chocolate is already tempered . Un ##tem ##pered chocolate generally needs to be re ##f ##rig ##erated for longer - term storage , so if a package doesn ' t specify re ##f ##rig ##eration ( and I ' ve never seen one that does ) , you can assume that it is tempered . [SEP]
token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:4 14:4 15:5 16:6 17:7 18:7 19:7 20:8 21:9 22:10 23:10 24:11 25:11 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:17 34:18 35:19 36:19 37:19 38:20 39:21 40:21 41:22 42:22 43:23 44:24 45:25 46:26 47:27 48:28 49:28 50:28 51:28 52:28 53:29 54:30 55:31 56:32 57:33 58:34 59:34 60:34 61:34 62:35 63:36 64:36 65:36 66:37 67:37 68:38 69:39 70:40 71:41 72:42 73:42 74:42 75:43 76:44 77:44 78:44 79:44 80:45 81:45 82:46 83:46 84:46 85:47 86:48 87:49 88:50 89:51 90:51 91:51 92:52 93:53 94:54 95:55 96:56 97:57 98:58 99:58
token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True
input_ids: 101 5979 3322 1132 1136 26030 136 102 1409 1122 1144 170 13388 120 24449 2473 1105 2144 112 189 16399 1137 171 13853 113 1277 114 1120 1395 4143 1137 1289 4143 117 1173 1122 112 188 1640 26030 119 18486 1193 1451 24946 8888 1110 1640 26030 119 12118 18408 19808 8888 2412 2993 1106 1129 1231 2087 17305 20725 1111 2039 118 1858 5092 117 1177 1191 170 7305 2144 112 189 22829 1231 2087 17305 17166 113 1105 146 112 1396 1309 1562 1141 1115 1674 114 117 1128 1169 7568 1115 1122 1110 26030 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000014
example_index: 14
doc_span_index: 0
tokens: [CLS] Does it affect the chocolate at all ? [SEP] If it has a shiny / reflective surface and doesn ' t melt or b ##loom ( much ) at room temperature or hand temperature , then it ' s already tempered . Virtual ##ly every packaged chocolate is already tempered . Un ##tem ##pered chocolate generally needs to be re ##f ##rig ##erated for longer - term storage , so if a package doesn ' t specify re ##f ##rig ##eration ( and I ' ve never seen one that does ) , you can assume that it is tempered . [SEP]
token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:4 16:4 17:5 18:6 19:7 20:7 21:7 22:8 23:9 24:10 25:10 26:11 27:11 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:17 36:18 37:19 38:19 39:19 40:20 41:21 42:21 43:22 44:22 45:23 46:24 47:25 48:26 49:27 50:28 51:28 52:28 53:28 54:28 55:29 56:30 57:31 58:32 59:33 60:34 61:34 62:34 63:34 64:35 65:36 66:36 67:36 68:37 69:37 70:38 71:39 72:40 73:41 74:42 75:42 76:42 77:43 78:44 79:44 80:44 81:44 82:45 83:45 84:46 85:46 86:46 87:47 88:48 89:49 90:50 91:51 92:51 93:51 94:52 95:53 96:54 97:55 98:56 99:57 100:58 101:58
token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True
input_ids: 101 7187 1122 6975 1103 8888 1120 1155 136 102 1409 1122 1144 170 13388 120 24449 2473 1105 2144 112 189 16399 1137 171 13853 113 1277 114 1120 1395 4143 1137 1289 4143 117 1173 1122 112 188 1640 26030 119 18486 1193 1451 24946 8888 1110 1640 26030 119 12118 18408 19808 8888 2412 2993 1106 1129 1231 2087 17305 20725 1111 2039 118 1858 5092 117 1177 1191 170 7305 2144 112 189 22829 1231 2087 17305 17166 113 1105 146 112 1396 1309 1562 1141 1115 1674 114 117 1128 1169 7568 1115 1122 1110 26030 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000015
example_index: 15
doc_span_index: 0
tokens: [CLS] Which non penetrating method is recommended to check chicken breasts for done - ne ##ss when pan fried [SEP] There isn ' t one . The only reliable way to determine done ##ness of a chicken breast is to use a the ##rm ##ometer . If you didn ' t have a the ##rm ##ometer then you would have to cut open the breast to confirm . Outside of those the only other method is experience . e . g . knowing that it takes 5 minutes per side to cook a breast of X size , in Y pan , on Z stove , at M heat . Given that you own a the ##rm ##ometer , it ' s kind of silly to ask for another way . Use it . [SEP]
token_to_orig_map: 20:0 21:1 22:1 23:1 24:2 25:2 26:2 27:3 28:4 29:5 30:6 31:7 32:8 33:8 34:9 35:10 36:11 37:12 38:13 39:14 40:15 41:16 42:17 43:17 44:17 45:17 46:18 47:19 48:20 49:20 50:20 51:21 52:22 53:23 54:23 55:23 56:24 57:25 58:26 59:27 60:28 61:29 62:30 63:31 64:32 65:33 66:34 67:34 68:35 69:36 70:37 71:38 72:39 73:40 74:41 75:42 76:43 77:43 78:44 79:44 80:44 81:44 82:45 83:46 84:47 85:48 86:49 87:50 88:51 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:60 99:61 100:62 101:62 102:63 103:64 104:65 105:65 106:66 107:67 108:68 109:68 110:68 111:69 112:70 113:71 114:72 115:73 116:73 117:73 118:73 119:74 120:74 121:74 122:75 123:76 124:77 125:78 126:79 127:80 128:81 129:82 130:82 131:83 132:84 133:84
token_is_max_context: 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True
input_ids: 101 5979 1664 25395 3442 1110 6315 1106 4031 9323 13016 1111 1694 118 24928 3954 1165 13316 15688 102 1247 2762 112 189 1141 119 1109 1178 10682 1236 1106 4959 1694 1757 1104 170 9323 7209 1110 1106 1329 170 1103 9019 20182 119 1409 1128 1238 112 189 1138 170 1103 9019 20182 1173 1128 1156 1138 1106 2195 1501 1103 7209 1106 12434 119 9572 1104 1343 1103 1178 1168 3442 1110 2541 119 174 119 176 119 3650 1115 1122 2274 126 1904 1679 1334 1106 9834 170 7209 1104 161 2060 117 1107 162 13316 117 1113 163 18362 117 1120 150 3208 119 10470 1115 1128 1319 170 1103 9019 20182 117 1122 112 188 1912 1104 10729 1106 2367 1111 1330 1236 119 11696 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000016
example_index: 16
doc_span_index: 0
tokens: [CLS] Is there a way to check done ##ness without using a the ##rm ##ometer ? [SEP] There isn ' t one . The only reliable way to determine done ##ness of a chicken breast is to use a the ##rm ##ometer . If you didn ' t have a the ##rm ##ometer then you would have to cut open the breast to confirm . Outside of those the only other method is experience . e . g . knowing that it takes 5 minutes per side to cook a breast of X size , in Y pan , on Z stove , at M heat . Given that you own a the ##rm ##ometer , it ' s kind of silly to ask for another way . Use it . [SEP]
token_to_orig_map: 17:0 18:1 19:1 20:1 21:2 22:2 23:2 24:3 25:4 26:5 27:6 28:7 29:8 30:8 31:9 32:10 33:11 34:12 35:13 36:14 37:15 38:16 39:17 40:17 41:17 42:17 43:18 44:19 45:20 46:20 47:20 48:21 49:22 50:23 51:23 52:23 53:24 54:25 55:26 56:27 57:28 58:29 59:30 60:31 61:32 62:33 63:34 64:34 65:35 66:36 67:37 68:38 69:39 70:40 71:41 72:42 73:43 74:43 75:44 76:44 77:44 78:44 79:45 80:46 81:47 82:48 83:49 84:50 85:51 86:52 87:53 88:54 89:55 90:56 91:57 92:58 93:59 94:59 95:60 96:61 97:62 98:62 99:63 100:64 101:65 102:65 103:66 104:67 105:68 106:68 107:68 108:69 109:70 110:71 111:72 112:73 113:73 114:73 115:73 116:74 117:74 118:74 119:75 120:76 121:77 122:78 123:79 124:80 125:81 126:82 127:82 128:83 129:84 130:84
token_is_max_context: 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True
input_ids: 101 2181 1175 170 1236 1106 4031 1694 1757 1443 1606 170 1103 9019 20182 136 102 1247 2762 112 189 1141 119 1109 1178 10682 1236 1106 4959 1694 1757 1104 170 9323 7209 1110 1106 1329 170 1103 9019 20182 119 1409 1128 1238 112 189 1138 170 1103 9019 20182 1173 1128 1156 1138 1106 2195 1501 1103 7209 1106 12434 119 9572 1104 1343 1103 1178 1168 3442 1110 2541 119 174 119 176 119 3650 1115 1122 2274 126 1904 1679 1334 1106 9834 170 7209 1104 161 2060 117 1107 162 13316 117 1113 163 18362 117 1120 150 3208 119 10470 1115 1128 1319 170 1103 9019 20182 117 1122 112 188 1912 1104 10729 1106 2367 1111 1330 1236 119 11696 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000017
example_index: 17
doc_span_index: 0
tokens: [CLS] What ' s the best way to prevent the chicken from becoming over ##don ##e ? [SEP] There isn ' t one . The only reliable way to determine done ##ness of a chicken breast is to use a the ##rm ##ometer . If you didn ' t have a the ##rm ##ometer then you would have to cut open the breast to confirm . Outside of those the only other method is experience . e . g . knowing that it takes 5 minutes per side to cook a breast of X size , in Y pan , on Z stove , at M heat . Given that you own a the ##rm ##ometer , it ' s kind of silly to ask for another way . Use it . [SEP]
token_to_orig_map: 18:0 19:1 20:1 21:1 22:2 23:2 24:2 25:3 26:4 27:5 28:6 29:7 30:8 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:17 42:17 43:17 44:18 45:19 46:20 47:20 48:20 49:21 50:22 51:23 52:23 53:23 54:24 55:25 56:26 57:27 58:28 59:29 60:30 61:31 62:32 63:33 64:34 65:34 66:35 67:36 68:37 69:38 70:39 71:40 72:41 73:42 74:43 75:43 76:44 77:44 78:44 79:44 80:45 81:46 82:47 83:48 84:49 85:50 86:51 87:52 88:53 89:54 90:55 91:56 92:57 93:58 94:59 95:59 96:60 97:61 98:62 99:62 100:63 101:64 102:65 103:65 104:66 105:67 106:68 107:68 108:68 109:69 110:70 111:71 112:72 113:73 114:73 115:73 116:73 117:74 118:74 119:74 120:75 121:76 122:77 123:78 124:79 125:80 126:81 127:82 128:82 129:83 130:84 131:84
token_is_max_context: 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True
input_ids: 101 1327 112 188 1103 1436 1236 1106 3843 1103 9323 1121 2479 1166 3842 1162 136 102 1247 2762 112 189 1141 119 1109 1178 10682 1236 1106 4959 1694 1757 1104 170 9323 7209 1110 1106 1329 170 1103 9019 20182 119 1409 1128 1238 112 189 1138 170 1103 9019 20182 1173 1128 1156 1138 1106 2195 1501 1103 7209 1106 12434 119 9572 1104 1343 1103 1178 1168 3442 1110 2541 119 174 119 176 119 3650 1115 1122 2274 126 1904 1679 1334 1106 9834 170 7209 1104 161 2060 117 1107 162 13316 117 1113 163 18362 117 1120 150 3208 119 10470 1115 1128 1319 170 1103 9019 20182 117 1122 112 188 1912 1104 10729 1106 2367 1111 1330 1236 119 11696 1122 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000018
example_index: 18
doc_span_index: 0
tokens: [CLS] How do I best g ##rill an art ##ich ##oke ? [SEP] I trim the stem and remove the outer leaves till they snap to get to the fresh inner core and steam them the night or morning before g ##rill ##ing so they are cold and moist . I prefer steaming because I want all of the nutrients to remain in the art ##ich ##oke . I cut them in half for the g ##rill , remove the choke and brush them with grapes ##eed oil where they come into contact with the g ##rill . First , facing down g ##rill them till they feel hot on top then ; flip them over to keep the y ##um ##my inner side tender . fill the cavity with garlic butter and . . . lemon if you wish . I prefer the brown color to the lemon flavor . I cook them till the butter melt ##s . I like mine barely smoke ##y because art ##ich ##oke ##s take on the smoke too easily and will taste burned . You can ' t taste the flavor of the art ##ich ##oke if it gets too smoke ##y . [SEP]
token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:27 42:27 43:28 44:29 45:30 46:31 47:32 48:33 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:48 65:48 66:48 67:48 68:49 69:50 70:51 71:52 72:53 73:54 74:55 75:56 76:56 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:64 87:65 88:66 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:73 97:73 98:74 99:74 100:75 101:76 102:77 103:77 104:78 105:79 106:80 107:81 108:82 109:83 110:84 111:85 112:85 113:86 114:87 115:88 116:89 117:90 118:91 119:92 120:92 121:92 122:93 123:94 124:95 125:95 126:96 127:97 128:98 129:99 130:100 131:101 132:102 133:102 134:102 135:102 136:103 137:104 138:105 139:106 140:106 141:107 142:108 143:109 144:110 145:111 146:112 147:113 148:114 149:115 150:115 151:116 152:117 153:118 154:119 155:120 156:121 157:122 158:122 159:122 160:123 161:124 162:125 163:126 164:127 165:127 166:128 167:129 168:129 169:129 170:129 171:130 172:131 173:132 174:133 175:134 176:135 177:136 178:137 179:138 180:139 181:139 182:140 183:141 184:141 185:141 186:142 187:143 188:144 189:145 190:146 191:147 192:147 193:147 194:148 195:149 196:150 197:151 198:152 199:152 200:152
token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True
input_ids: 101 1731 1202 146 1436 176 11071 1126 1893 7255 9143 136 102 146 13373 1103 8175 1105 5782 1103 6144 2972 6174 1152 11152 1106 1243 1106 1103 4489 5047 4160 1105 5543 1172 1103 1480 1137 2106 1196 176 11071 1158 1177 1152 1132 2504 1105 11758 119 146 9353 23026 1272 146 1328 1155 1104 1103 22667 1106 3118 1107 1103 1893 7255 9143 119 146 2195 1172 1107 1544 1111 1103 176 11071 117 5782 1103 18603 1105 8415 1172 1114 19573 11394 2949 1187 1152 1435 1154 3232 1114 1103 176 11071 119 1752 117 4749 1205 176 11071 1172 6174 1152 1631 2633 1113 1499 1173 132 12785 1172 1166 1106 1712 1103 194 1818 4527 5047 1334 8886 119 5475 1103 19421 1114 24861 13742 1105 119 119 119 22782 1191 1128 3683 119 146 9353 1103 3058 2942 1106 1103 22782 16852 119 146 9834 1172 6174 1103 13742 16399 1116 119 146 1176 2317 3742 5427 1183 1272 1893 7255 9143 1116 1321 1113 1103 5427 1315 3253 1105 1209 5080 4562 119 1192 1169 112 189 5080 1103 16852 1104 1103 1893 7255 9143 1191 1122 3370 1315 5427 1183 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
*** Example ***
unique_id: 1000000019
example_index: 19
doc_span_index: 0
tokens: [CLS] Are there other ways to cook it ? [SEP] I trim the stem and remove the outer leaves till they snap to get to the fresh inner core and steam them the night or morning before g ##rill ##ing so they are cold and moist . I prefer steaming because I want all of the nutrients to remain in the art ##ich ##oke . I cut them in half for the g ##rill , remove the choke and brush them with grapes ##eed oil where they come into contact with the g ##rill . First , facing down g ##rill them till they feel hot on top then ; flip them over to keep the y ##um ##my inner side tender . fill the cavity with garlic butter and . . . lemon if you wish . I prefer the brown color to the lemon flavor . I cook them till the butter melt ##s . I like mine barely smoke ##y because art ##ich ##oke ##s take on the smoke too easily and will taste burned . You can ' t taste the flavor of the art ##ich ##oke if it gets too smoke ##y . [SEP]
token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:16 27:17 28:18 29:19 30:20 31:21 32:22 33:23 34:24 35:25 36:26 37:27 38:27 39:27 40:28 41:29 42:30 43:31 44:32 45:33 46:33 47:34 48:35 49:36 50:37 51:38 52:39 53:40 54:41 55:42 56:43 57:44 58:45 59:46 60:47 61:48 62:48 63:48 64:48 65:49 66:50 67:51 68:52 69:53 70:54 71:55 72:56 73:56 74:56 75:57 76:58 77:59 78:60 79:61 80:62 81:63 82:64 83:64 84:65 85:66 86:67 87:68 88:69 89:70 90:71 91:72 92:73 93:73 94:73 95:74 96:74 97:75 98:76 99:77 100:77 101:78 102:79 103:80 104:81 105:82 106:83 107:84 108:85 109:85 110:86 111:87 112:88 113:89 114:90 115:91 116:92 117:92 118:92 119:93 120:94 121:95 122:95 123:96 124:97 125:98 126:99 127:100 128:101 129:102 130:102 131:102 132:102 133:103 134:104 135:105 136:106 137:106 138:107 139:108 140:109 141:110 142:111 143:112 144:113 145:114 146:115 147:115 148:116 149:117 150:118 151:119 152:120 153:121 154:122 155:122 156:122 157:123 158:124 159:125 160:126 161:127 162:127 163:128 164:129 165:129 166:129 167:129 168:130 169:131 170:132 171:133 172:134 173:135 174:136 175:137 176:138 177:139 178:139 179:140 180:141 181:141 182:141 183:142 184:143 185:144 186:145 187:146 188:147 189:147 190:147 191:148 192:149 193:150 194:151 195:152 196:152 197:152
token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True
input_ids: 101 2372 1175 1168 3242 1106 9834 1122 136 102 146 13373 1103 8175 1105 5782 1103 6144 2972 6174 1152 11152 1106 1243 1106 1103 4489 5047 4160 1105 5543 1172 1103 1480 1137 2106 1196 176 11071 1158 1177 1152 1132 2504 1105 11758 119 146 9353 23026 1272 146 1328 1155 1104 1103 22667 1106 3118 1107 1103 1893 7255 9143 119 146 2195 1172 1107 1544 1111 1103 176 11071 117 5782 1103 18603 1105 8415 1172 1114 19573 11394 2949 1187 1152 1435 1154 3232 1114 1103 176 11071 119 1752 117 4749 1205 176 11071 1172 6174 1152 1631 2633 1113 1499 1173 132 12785 1172 1166 1106 1712 1103 194 1818 4527 5047 1334 8886 119 5475 1103 19421 1114 24861 13742 1105 119 119 119 22782 1191 1128 3683 119 146 9353 1103 3058 2942 1106 1103 22782 16852 119 146 9834 1172 6174 1103 13742 16399 1116 119 146 1176 2317 3742 5427 1183 1272 1893 7255 9143 1116 1321 1113 1103 5427 1315 3253 1105 1209 5080 4562 119 1192 1169 112 189 5080 1103 16852 1104 1103 1893 7255 9143 1191 1122 3370 1315 5427 1183 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
***** Test *****
  Num orig examples = 1263
  Num split examples = 1265
  Batch size = 8
Running test: 0 / 159
Running test: 10 / 159
Running test: 20 / 159
Running test: 30 / 159
Running test: 40 / 159
Running test: 50 / 159
Running test: 60 / 159
Running test: 70 / 159
Running test: 80 / 159
Running test: 90 / 159
Running test: 100 / 159
Running test: 110 / 159
Running test: 120 / 159
Running test: 130 / 159
Running test: 140 / 159
Running test: 150 / 159
